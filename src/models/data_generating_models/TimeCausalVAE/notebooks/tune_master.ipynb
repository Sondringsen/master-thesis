{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Causal VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/3t/5vvh8l5x48s7tyvbx4b6v9xr0000gn/T/ipykernel_7635/2888592871.py\", line 18, in <module>\n",
      "    from evaluations.hyperparameter import ModelEvaluator\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/../src/evaluations/hyperparameter.py\", line 11, in <module>\n",
      "    from evaluations.eval_distances import SWD, SignatureMMD\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/../src/evaluations/eval_distances.py\", line 3, in <module>\n",
      "    from ot import sliced_wasserstein_distance\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/__init__.py\", line 21, in <module>\n",
      "    from . import lp\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/lp/__init__.py\", line 20, in <module>\n",
      "    from .dmmot import dmmot_monge_1dgrid_loss, dmmot_monge_1dgrid_optimize\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/lp/dmmot.py\", line 12, in <module>\n",
      "    from ..backend import get_backend\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/backend.py\", line 145, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/__init__.py\", line 45, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\", line 46, in <module>\n",
      "    from tensorflow.python import pywrap_tfe\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/pywrap_tfe.py\", line 25, in <module>\n",
      "    from tensorflow.python._pywrap_tfe import *\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Dev/master-thesis/.venv/lib/python3.12/site-packages/numpy/core/_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/3t/5vvh8l5x48s7tyvbx4b6v9xr0000gn/T/ipykernel_7635/2888592871.py\", line 18, in <module>\n",
      "    from evaluations.hyperparameter import ModelEvaluator\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/../src/evaluations/hyperparameter.py\", line 11, in <module>\n",
      "    from evaluations.eval_distances import SWD, SignatureMMD\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/../src/evaluations/eval_distances.py\", line 3, in <module>\n",
      "    from ot import sliced_wasserstein_distance\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/__init__.py\", line 21, in <module>\n",
      "    from . import lp\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/lp/__init__.py\", line 20, in <module>\n",
      "    from .dmmot import dmmot_monge_1dgrid_loss, dmmot_monge_1dgrid_optimize\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/lp/dmmot.py\", line 12, in <module>\n",
      "    from ..backend import get_backend\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/backend.py\", line 145, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/__init__.py\", line 45, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\", line 49, in <module>\n",
      "    from tensorflow.python.client import pywrap_tf_session\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/client/pywrap_tf_session.py\", line 19, in <module>\n",
      "    from tensorflow.python.client._pywrap_tf_session import *\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Dev/master-thesis/.venv/lib/python3.12/site-packages/numpy/core/_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/3t/5vvh8l5x48s7tyvbx4b6v9xr0000gn/T/ipykernel_7635/2888592871.py\", line 18, in <module>\n",
      "    from evaluations.hyperparameter import ModelEvaluator\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/../src/evaluations/hyperparameter.py\", line 11, in <module>\n",
      "    from evaluations.eval_distances import SWD, SignatureMMD\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/../src/evaluations/eval_distances.py\", line 3, in <module>\n",
      "    from ot import sliced_wasserstein_distance\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/__init__.py\", line 21, in <module>\n",
      "    from . import lp\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/lp/__init__.py\", line 20, in <module>\n",
      "    from .dmmot import dmmot_monge_1dgrid_loss, dmmot_monge_1dgrid_optimize\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/lp/dmmot.py\", line 12, in <module>\n",
      "    from ..backend import get_backend\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/backend.py\", line 145, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/__init__.py\", line 45, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\", line 50, in <module>\n",
      "    from tensorflow.python.eager import context\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py\", line 37, in <module>\n",
      "    from tensorflow.python.eager import execute\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
      "    from tensorflow.python.framework import dtypes\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/framework/dtypes.py\", line 21, in <module>\n",
      "    import ml_dtypes\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ml_dtypes/__init__.py\", line 32, in <module>\n",
      "    from ml_dtypes._finfo import finfo\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ml_dtypes/_finfo.py\", line 19, in <module>\n",
      "    from ml_dtypes._ml_dtypes_ext import bfloat16\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Dev/master-thesis/.venv/lib/python3.12/site-packages/numpy/core/_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/3t/5vvh8l5x48s7tyvbx4b6v9xr0000gn/T/ipykernel_7635/2888592871.py\", line 18, in <module>\n",
      "    from evaluations.hyperparameter import ModelEvaluator\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/../src/evaluations/hyperparameter.py\", line 11, in <module>\n",
      "    from evaluations.eval_distances import SWD, SignatureMMD\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/../src/evaluations/eval_distances.py\", line 3, in <module>\n",
      "    from ot import sliced_wasserstein_distance\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/__init__.py\", line 21, in <module>\n",
      "    from . import lp\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/lp/__init__.py\", line 20, in <module>\n",
      "    from .dmmot import dmmot_monge_1dgrid_loss, dmmot_monge_1dgrid_optimize\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/lp/dmmot.py\", line 12, in <module>\n",
      "    from ..backend import get_backend\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ot/backend.py\", line 145, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/__init__.py\", line 45, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\", line 50, in <module>\n",
      "    from tensorflow.python.eager import context\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py\", line 37, in <module>\n",
      "    from tensorflow.python.eager import execute\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
      "    from tensorflow.python.framework import dtypes\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/framework/dtypes.py\", line 21, in <module>\n",
      "    import ml_dtypes\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ml_dtypes/__init__.py\", line 32, in <module>\n",
      "    from ml_dtypes._finfo import finfo\n",
      "  File \"/Users/sondrerogde/Dev/master-thesis/.venv/lib/python3.12/site-packages/ml_dtypes/_finfo.py\", line 19, in <module>\n",
      "    from ml_dtypes._ml_dtypes_ext import bfloat16\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_UFUNC_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _UFUNC_API not found"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import yaml\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../../../..')\n",
    "# sys.path.append('../../../')\n",
    "\n",
    "from tsvae.utils.logger_utils import get_console_logger\n",
    "logger = get_console_logger(__name__)\n",
    "from os import path as pt\n",
    "from experiments.experiment_utils import get_output_dir, update_config\n",
    "from tsvae.dataset.data_pipeline import DataPipeline\n",
    "from tsvae.models.network_pipeline import NetworkPipeline\n",
    "from tsvae.utils.random_utils import set_seed\n",
    "from tsvae.trainers.base_trainer_config import BaseTrainerConfig\n",
    "from tsvae.trainers.training_pipeline import TrainingPipeline\n",
    "from evaluations.hyperparameter import ModelEvaluator\n",
    "from os import path as pt\n",
    "import pandas as pd\n",
    "\n",
    "from data_processing.post_processing import post_processing\n",
    "from data_processing.config import post_processing_config\n",
    "from models.DeepHedger import hedging\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCVAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msarogde\u001b[0m (\u001b[33msarogde-ntnu\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/sondrerogde/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"52ea61320bbc9ee2b773e909700366e65977cd0f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "        'name': 'loss',\n",
    "        'goal': 'minimize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.0001,\n",
    "            'max': 0.02\n",
    "        },\n",
    "        'E_hidden_dim': {\n",
    "            'values': [8, 16, 32]\n",
    "        },\n",
    "        'E_num_layers': {\n",
    "            'values': [1, 2, 3]\n",
    "        },\n",
    "        'D_hidden_dim': {\n",
    "            'values': [8, 16, 32]\n",
    "        },\n",
    "        'D_num_layers': {\n",
    "            'values': [1, 2, 3]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep_id = wandb.sweep(sweep_config, project=\"tcvae_hyperopt\")\n",
    "sweep_id = \"xrvotxdn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(config): \n",
    "    base_output_dir = '..' \n",
    "\n",
    "    new_config = {\n",
    "        'epochs' : 100, 'wandb': False, 'comment': 'test',\n",
    "        \"D_hidden_dim\": config.D_hidden_dim,\n",
    "        \"D_num_layers\": config.D_num_layers,\n",
    "        \"E_hidden_dim\": config.E_hidden_dim,\n",
    "        \"E_num_layers\": config.E_num_layers,\n",
    "        \"learning_rate\": config.learning_rate\n",
    "    }\n",
    "    exp_config_path = '../configs/Master/betacvae.yaml'\n",
    "\n",
    "    with open(exp_config_path) as file:\n",
    "        exp_config = dict(yaml.safe_load(file))\n",
    "\n",
    "    exp_config = update_config(exp_config, new_config)\n",
    "\n",
    "\n",
    "    exp_config.base_output_dir = base_output_dir\n",
    "    exp_config.output_dir = get_output_dir(exp_config)\n",
    "    logger.info(f\"Experiment results saved to {exp_config.output_dir}\")\n",
    "\n",
    "    logger.info(f\"Saving experiment config to {exp_config.output_dir}\")\n",
    "    config_file_path = pt.join(exp_config.output_dir, \"exp_config.yaml\")\n",
    "    with open(config_file_path, \"w\") as outfile:\n",
    "        yaml.dump(exp_config, outfile, default_flow_style=False)\n",
    "    # logger.info(exp_config)\n",
    "\n",
    "    # Generating data\n",
    "    logger.info(f\"Setting ramdom seed: {exp_config.seed}\")\n",
    "    set_seed(exp_config.seed)\n",
    "\n",
    "    data_pipeline = DataPipeline()\n",
    "    train_dataset, eval_dataset = data_pipeline(exp_config)\n",
    "\n",
    "    network_pipeline = NetworkPipeline()\n",
    "    model = network_pipeline(exp_config)\n",
    "\n",
    "    training_config = BaseTrainerConfig(\n",
    "    output_dir=exp_config.output_dir,\n",
    "    learning_rate=exp_config.lr,\n",
    "    per_device_train_batch_size=exp_config.train_batch_size,\n",
    "    per_device_eval_batch_size=exp_config.eval_batch_size,\n",
    "    optimizer_cls=exp_config.optimizer,\n",
    "    optimizer_params=None,\n",
    "    scheduler_cls=None,\n",
    "    scheduler_params=None,\n",
    "    steps_saving=exp_config.steps_saving,\n",
    "    steps_predict=exp_config.steps_predict,\n",
    "    seed=exp_config.seed,\n",
    "    num_epochs=exp_config.epochs,\n",
    "    wandb_callback=exp_config.wandb,\n",
    "    wandb_output_dir=exp_config.base_output_dir + \"/wandb\")\n",
    "\n",
    "\n",
    "    # Train TCVAE\n",
    "    train_pipeline = TrainingPipeline(model=model, training_config=training_config, exp_config=exp_config)\n",
    "\n",
    "    trainer = train_pipeline(\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        device_name=exp_config.device_name,\n",
    "    )\n",
    "\n",
    "    train_pipeline.train(log_output=False)\n",
    "\n",
    "    # Generate data\n",
    "    model_dir = pt.join(trainer.training_dir, 'final_model')\n",
    "    model_evaluator = ModelEvaluator(model_dir)\n",
    "    output_dir = model_evaluator.hyper_model_dir\n",
    "    model = model_evaluator.model\n",
    "\n",
    "    df_tot_fake = pd.DataFrame()\n",
    "    # 100 times 1000 corresponds to M = 100.000\n",
    "    for i in range(100):\n",
    "        test_data, gen_data, recon_data = model_evaluator.load_data(seed = i, n_sample_test=1000)\n",
    "        ds = model_evaluator.data_ppl.base_dataset\n",
    "\n",
    "        real_data = test_data\n",
    "        recon_data = recon_data\n",
    "        fake_data = gen_data\n",
    "\n",
    "        df_sub_fake = pd.DataFrame(gen_data.detach().squeeze(-1).numpy())\n",
    "        df_tot_fake = pd.concat([df_tot_fake, df_sub_fake], axis=0)\n",
    "\n",
    "    # Post-processing\n",
    "    df_post_processed = post_processing(df_tot_fake, **post_processing_config)\n",
    "    \n",
    "    # Hedging\n",
    "    val_loss = hedging(df_post_processed)\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def main():\n",
    "    wandb.init()\n",
    "    val_loss = objective(wandb.config)\n",
    "    wandb.log({\"val_loss\": val_loss,  \"loss\": val_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s7uwraje with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0013260189821117962\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250325_195556-s7uwraje</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/s7uwraje' target=\"_blank\">olive-sweep-11</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/s7uwraje' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/s7uwraje</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_19-55-57. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  60%|██████    | 3/5 [00:00<00:00, 13.09batch/s]total loss: 3.39\n",
      "recon: 3.05\n",
      "reg: 8.48\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  7.62batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:01,  3.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 5.502\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 15.17batch/s]total loss: 1.24\n",
      "recon: 1.09\n",
      "reg: 3.94\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 10.13batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  4.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 2.0241\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 16.57batch/s]total loss: 0.67\n",
      "recon: 0.69\n",
      "reg: -0.31\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  9.83batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  4.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.4656\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 13.42batch/s]total loss: 0.73\n",
      "recon: 0.73\n",
      "reg: -0.01\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00,  9.32batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  4.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2247\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 12.44batch/s]total loss: 0.97\n",
      "recon: 0.94\n",
      "reg: 0.79\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:01<00:00,  3.85batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:03,  1.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0301\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  60%|██████    | 3/5 [00:00<00:00, 13.47batch/s]total loss: 1.01\n",
      "recon: 0.87\n",
      "reg: 3.62\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00,  9.55batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  5.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 14.89batch/s]total loss: 0.91\n",
      "recon: 0.92\n",
      "reg: -0.24\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00,  6.54batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:01,  2.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0394\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 15.94batch/s]total loss: 0.76\n",
      "recon: 0.74\n",
      "reg: 0.33\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 10.32batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  4.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9547\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 13.87batch/s]total loss: 1.02\n",
      "recon: 0.86\n",
      "reg: 3.91\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  7.54batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:01,  2.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0045\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 14.76batch/s]total loss: 0.84\n",
      "recon: 0.74\n",
      "reg: 2.48\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  8.54batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:01,  3.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9274\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 13.10batch/s]total loss: 0.90\n",
      "recon: 0.76\n",
      "reg: 3.71\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00,  7.85batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:01,  3.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9302\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  60%|██████    | 3/5 [00:00<00:00, 12.77batch/s]total loss: 0.71\n",
      "recon: 0.62\n",
      "reg: 2.25\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  7.95batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:01,  3.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 13.44batch/s]total loss: 1.02\n",
      "recon: 0.99\n",
      "reg: 0.75\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00,  8.11batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:01,  3.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00,  9.51batch/s]total loss: 0.52\n",
      "recon: 0.46\n",
      "reg: 1.28\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00,  6.76batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:01,  3.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8116\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 11.53batch/s]total loss: 0.67\n",
      "recon: 0.66\n",
      "reg: 0.30\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  8.05batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  4.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8181\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00,  8.35batch/s]total loss: 0.88\n",
      "recon: 0.89\n",
      "reg: -0.33\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00,  6.33batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8724\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 12.97batch/s]total loss: 0.87\n",
      "recon: 0.80\n",
      "reg: 1.58\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00,  8.29batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:01,  3.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8683\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00,  8.46batch/s]total loss: 0.75\n",
      "recon: 0.61\n",
      "reg: 3.50\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00,  6.64batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:01,  3.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8354\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 13.48batch/s]total loss: 0.36\n",
      "recon: 0.46\n",
      "reg: -2.41\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00,  9.18batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  4.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  60%|██████    | 3/5 [00:00<00:00, 12.26batch/s]total loss: 0.99\n",
      "recon: 1.01\n",
      "reg: -0.51\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00,  8.88batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  4.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 15.93batch/s]total loss: 1.26\n",
      "recon: 1.19\n",
      "reg: 1.85\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 10.15batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  4.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9281\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 15.93batch/s]total loss: 0.56\n",
      "recon: 0.64\n",
      "reg: -1.92\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 10.26batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  4.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7837\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 14.70batch/s]total loss: 0.93\n",
      "recon: 0.88\n",
      "reg: 1.09\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  9.80batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  4.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8634\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 13.81batch/s]total loss: 1.02\n",
      "recon: 1.00\n",
      "reg: 0.37\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00,  9.30batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9308\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 15.91batch/s]total loss: 0.86\n",
      "recon: 0.81\n",
      "reg: 1.34\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00,  8.74batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:01,  3.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8554\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 14.03batch/s]total loss: 1.24\n",
      "recon: 1.10\n",
      "reg: 3.32\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 10.05batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  5.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9187\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 16.21batch/s]total loss: 0.89\n",
      "recon: 0.71\n",
      "reg: 4.62\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 10.98batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  5.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8652\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 16.96batch/s]total loss: 0.59\n",
      "recon: 0.54\n",
      "reg: 1.27\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00, 10.04batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  5.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8567\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 16.54batch/s]total loss: 0.99\n",
      "recon: 0.96\n",
      "reg: 0.89\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 10.92batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  5.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9652\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  60%|██████    | 3/5 [00:00<00:00, 13.19batch/s]total loss: 0.72\n",
      "recon: 0.65\n",
      "reg: 1.81\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  5.86batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:02,  1.91batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8574\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 16.86batch/s]total loss: 0.71\n",
      "recon: 0.73\n",
      "reg: -0.66\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00,  9.55batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:01,  3.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8597\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 14.14batch/s]total loss: 1.01\n",
      "recon: 1.03\n",
      "reg: -0.54\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  9.85batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  5.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0198\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 16.24batch/s]total loss: 0.62\n",
      "recon: 0.64\n",
      "reg: -0.50\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00, 10.61batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  5.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8643\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 15.35batch/s]total loss: 0.96\n",
      "recon: 1.00\n",
      "reg: -0.93\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00, 10.63batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  5.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.882\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 16.48batch/s]total loss: 1.32\n",
      "recon: 1.25\n",
      "reg: 1.65\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00, 11.01batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  5.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9388\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  60%|██████    | 3/5 [00:00<00:00, 14.26batch/s]total loss: 0.58\n",
      "recon: 0.63\n",
      "reg: -1.15\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  9.79batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  5.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 16.07batch/s]total loss: 0.67\n",
      "recon: 0.70\n",
      "reg: -0.76\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 10.74batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  5.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8219\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  60%|██████    | 3/5 [00:00<00:00, 13.99batch/s]total loss: 0.74\n",
      "recon: 0.69\n",
      "reg: 1.29\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 10.18batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  5.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8624\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  60%|██████    | 3/5 [00:00<00:00, 13.74batch/s]total loss: 0.88\n",
      "recon: 0.80\n",
      "reg: 2.07\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  9.71batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  5.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8684\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 14.05batch/s]total loss: 1.34\n",
      "recon: 1.27\n",
      "reg: 1.72\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00,  8.98batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:01,  3.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9478\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 16.34batch/s]total loss: 1.09\n",
      "recon: 0.93\n",
      "reg: 3.95\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 10.94batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  5.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9012\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  60%|██████    | 3/5 [00:00<00:00, 11.84batch/s]total loss: 1.31\n",
      "recon: 1.33\n",
      "reg: -0.47\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  8.91batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  5.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9442\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 16.97batch/s]total loss: 0.94\n",
      "recon: 0.93\n",
      "reg: 0.13\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 10.51batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8538\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 16.93batch/s]total loss: 0.79\n",
      "recon: 0.81\n",
      "reg: -0.35\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00,  9.76batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8189\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 17.05batch/s]total loss: 1.01\n",
      "recon: 0.95\n",
      "reg: 1.34\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  9.43batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:01,  3.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9508\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 17.18batch/s]total loss: 0.97\n",
      "recon: 0.87\n",
      "reg: 2.44\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00, 10.27batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  4.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.882\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 16.96batch/s]total loss: 0.97\n",
      "recon: 0.97\n",
      "reg: -0.22\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 11.21batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  5.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 16.49batch/s]total loss: 1.01\n",
      "recon: 0.99\n",
      "reg: 0.48\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  9.97batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 17.20batch/s]total loss: 0.37\n",
      "recon: 0.56\n",
      "reg: -4.68\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 11.24batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  5.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7594\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 16.80batch/s]total loss: 1.06\n",
      "recon: 1.06\n",
      "reg: 0.04\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00,  9.83batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  4.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9591\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 16.76batch/s]total loss: 1.01\n",
      "recon: 0.94\n",
      "reg: 1.59\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 10.96batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  5.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9319\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 16.00batch/s]total loss: 0.73\n",
      "recon: 0.73\n",
      "reg: 0.02\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  9.47batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  4.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8339\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 17.25batch/s]total loss: 0.61\n",
      "recon: 0.60\n",
      "reg: 0.31\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 11.12batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  5.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.786\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 16.24batch/s]total loss: 0.66\n",
      "recon: 0.78\n",
      "reg: -3.01\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00,  9.83batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  4.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.785\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 16.99batch/s]total loss: 1.00\n",
      "recon: 1.04\n",
      "reg: -1.12\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 11.09batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8609\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 17.20batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.59\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00,  9.99batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8129\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 17.35batch/s]total loss: 0.89\n",
      "recon: 0.73\n",
      "reg: 3.89\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 10.18batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  4.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8354\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 13.95batch/s]total loss: 0.87\n",
      "recon: 0.92\n",
      "reg: -1.38\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  8.85batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  4.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8296\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00,  9.58batch/s]total loss: 0.72\n",
      "recon: 0.65\n",
      "reg: 1.83\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00,  7.38batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  4.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8077\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 12.68batch/s]total loss: 0.25\n",
      "recon: 0.39\n",
      "reg: -3.38\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:01<00:00,  5.00batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:02,  1.50batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7093\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 13.38batch/s]total loss: 0.57\n",
      "recon: 0.55\n",
      "reg: 0.57\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  8.05batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:01,  3.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7739\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 15.31batch/s]total loss: 0.92\n",
      "recon: 0.94\n",
      "reg: -0.48\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00,  8.40batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  4.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8327\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 14.64batch/s]total loss: 0.62\n",
      "recon: 0.70\n",
      "reg: -1.86\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  8.68batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  4.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7682\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 15.18batch/s]total loss: 1.12\n",
      "recon: 0.99\n",
      "reg: 3.12\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00, 10.33batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  5.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8862\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 16.12batch/s]total loss: 0.76\n",
      "recon: 0.81\n",
      "reg: -1.15\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00,  9.77batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  4.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8046\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 16.58batch/s]total loss: 1.30\n",
      "recon: 1.22\n",
      "reg: 1.87\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 10.64batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.968\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 15.70batch/s]total loss: 0.84\n",
      "recon: 0.80\n",
      "reg: 1.03\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00,  9.27batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  4.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9377\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 16.69batch/s]total loss: 0.94\n",
      "recon: 0.84\n",
      "reg: 2.46\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00, 10.76batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  5.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9217\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 15.34batch/s]total loss: 0.87\n",
      "recon: 0.82\n",
      "reg: 1.15\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  9.42batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  4.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8888\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 16.98batch/s]total loss: 0.96\n",
      "recon: 1.08\n",
      "reg: -3.01\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 10.80batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  4.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8602\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 13.75batch/s]total loss: 0.61\n",
      "recon: 0.70\n",
      "reg: -2.12\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00,  9.78batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  5.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7999\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00,  7.83batch/s]total loss: 0.56\n",
      "recon: 0.55\n",
      "reg: 0.37\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  6.86batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  4.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8028\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  60%|██████    | 3/5 [00:00<00:00, 14.05batch/s]total loss: 0.78\n",
      "recon: 0.78\n",
      "reg: 0.14\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  9.89batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  5.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8244\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 15.22batch/s]total loss: 0.43\n",
      "recon: 0.39\n",
      "reg: 0.86\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 10.13batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.759\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 12.33batch/s]total loss: 0.73\n",
      "recon: 0.72\n",
      "reg: 0.24\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00,  9.14batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8094\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 16.43batch/s]total loss: 0.90\n",
      "recon: 0.91\n",
      "reg: -0.17\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 10.54batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.846\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  60%|██████    | 3/5 [00:00<00:00, 13.32batch/s]total loss: 1.05\n",
      "recon: 0.99\n",
      "reg: 1.41\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  8.46batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:01,  3.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8897\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 14.35batch/s]total loss: 0.66\n",
      "recon: 0.70\n",
      "reg: -0.98\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 10.03batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  5.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8329\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 15.55batch/s]total loss: 0.30\n",
      "recon: 0.38\n",
      "reg: -1.95\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 10.19batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  5.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7439\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 16.58batch/s]total loss: 0.77\n",
      "recon: 0.62\n",
      "reg: 3.64\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  9.97batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  4.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8231\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 15.92batch/s]total loss: 0.73\n",
      "recon: 0.75\n",
      "reg: -0.37\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 10.61batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  5.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8238\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 16.51batch/s]total loss: 0.47\n",
      "recon: 0.42\n",
      "reg: 1.18\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  9.83batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7858\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00,  6.28batch/s]total loss: 0.75\n",
      "recon: 0.72\n",
      "reg: 0.77\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  5.20batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  4.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8169\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 15.86batch/s]total loss: 0.91\n",
      "recon: 0.90\n",
      "reg: 0.29\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  7.68batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:01,  2.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8383\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 14.70batch/s]total loss: 0.93\n",
      "recon: 0.84\n",
      "reg: 2.12\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  9.17batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  4.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8308\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 13.78batch/s]total loss: 0.93\n",
      "recon: 0.79\n",
      "reg: 3.49\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  8.40batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8502\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 14.22batch/s]total loss: 0.69\n",
      "recon: 0.79\n",
      "reg: -2.44\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  9.80batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7972\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  60%|██████    | 3/5 [00:00<00:00, 13.07batch/s]total loss: 1.17\n",
      "recon: 1.10\n",
      "reg: 1.82\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  9.47batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  5.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8923\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 17.08batch/s]total loss: 0.90\n",
      "recon: 0.90\n",
      "reg: 0.05\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00, 10.26batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  60%|██████    | 3/5 [00:00<00:00, 13.54batch/s]total loss: 0.69\n",
      "recon: 0.64\n",
      "reg: 1.39\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  8.06batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  3.26batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7854\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  60%|██████    | 3/5 [00:00<00:00, 12.35batch/s]total loss: 1.10\n",
      "recon: 1.01\n",
      "reg: 2.23\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  6.38batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:01,  2.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8854\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 10.11batch/s]total loss: 0.64\n",
      "recon: 0.61\n",
      "reg: 0.70\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  7.21batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:01,  3.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7927\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00,  9.71batch/s]total loss: 0.71\n",
      "recon: 0.65\n",
      "reg: 1.50\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  7.51batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  4.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8174\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  60%|██████    | 3/5 [00:00<00:00, 12.73batch/s]total loss: 0.73\n",
      "recon: 0.66\n",
      "reg: 1.63\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  8.93batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7938\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 11.31batch/s]total loss: 0.78\n",
      "recon: 0.83\n",
      "reg: -1.23\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  7.22batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:01,  3.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.809\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 14.17batch/s]total loss: 1.76\n",
      "recon: 1.64\n",
      "reg: 2.81\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  6.35batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:01,  2.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0133\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00,  6.72batch/s]total loss: 0.90\n",
      "recon: 0.90\n",
      "reg: -0.10\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  5.05batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:01,  2.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8384\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 14.11batch/s]total loss: 0.95\n",
      "recon: 0.84\n",
      "reg: 2.72\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  6.63batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:01,  2.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8542\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 12.32batch/s]total loss: 1.66\n",
      "recon: 1.62\n",
      "reg: 1.17\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00,  8.55batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9985\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 14.42batch/s]total loss: 0.64\n",
      "recon: 0.61\n",
      "reg: 0.64\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  5.25batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:02,  1.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8108\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_19-55-57/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.983650371432, Time: 101.37s\n",
      "Epoch 200, Training Loss: 0.252045606263, Time: 191.67s\n",
      "Epoch 300, Training Loss: 0.137952044280, Time: 281.89s\n",
      "Epoch 400, Training Loss: 0.096558448044, Time: 376.74s\n",
      "Epoch 500, Training Loss: 0.080851446989, Time: 470.06s\n",
      "Epoch 600, Training Loss: 0.072261238571, Time: 565.24s\n",
      "Epoch 700, Training Loss: 0.068731246493, Time: 662.25s\n",
      "Epoch 800, Training Loss: 0.069999134355, Time: 759.46s\n",
      "Epoch 900, Training Loss: 0.061809237787, Time: 856.34s\n",
      "Epoch 1000, Training Loss: 0.058339852385, Time: 953.25s\n",
      "Validation Loss: 0.187753636949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac82081f6f442d0a0289ae8c837b0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.18775</td></tr><tr><td>val_loss</td><td>0.18775</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">olive-sweep-11</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/s7uwraje' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/s7uwraje</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250325_195556-s7uwraje/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ga8jixbm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0013767490581082136\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250325_201319-ga8jixbm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/ga8jixbm' target=\"_blank\">comfy-sweep-12</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/ga8jixbm' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/ga8jixbm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_20-13-20. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 13.46batch/s]total loss: 4.54\n",
      "recon: 4.25\n",
      "reg: 7.01\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  7.76batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:01,  3.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.4454\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 16.37batch/s]total loss: 1.09\n",
      "recon: 1.05\n",
      "reg: 1.10\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00,  9.25batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:01,  3.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.5912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  60%|██████    | 3/5 [00:00<00:00, 14.00batch/s]total loss: 1.23\n",
      "recon: 1.27\n",
      "reg: -1.13\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00, 10.11batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  5.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2307\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 17.67batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.76\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 10.36batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  4.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 16.93batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.45\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00, 10.58batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9394\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 18.03batch/s]total loss: 0.81\n",
      "recon: 0.71\n",
      "reg: 2.51\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 11.17batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 17.37batch/s]total loss: 0.67\n",
      "recon: 0.70\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 10.20batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  4.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 16.18batch/s]total loss: 0.71\n",
      "recon: 0.71\n",
      "reg: -0.09\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 10.58batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  5.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 17.69batch/s]total loss: 1.02\n",
      "recon: 0.89\n",
      "reg: 3.25\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  9.81batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:01,  3.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9044\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 17.18batch/s]total loss: 0.65\n",
      "recon: 0.57\n",
      "reg: 2.05\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00, 10.26batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 16.64batch/s]total loss: 1.09\n",
      "recon: 0.94\n",
      "reg: 3.71\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 10.36batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9274\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 17.37batch/s]total loss: 0.93\n",
      "recon: 0.85\n",
      "reg: 1.84\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00, 10.91batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  4.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 17.31batch/s]total loss: 1.01\n",
      "recon: 0.97\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 10.79batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  5.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 16.41batch/s]total loss: 0.65\n",
      "recon: 0.65\n",
      "reg: -0.11\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 10.50batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 17.27batch/s]total loss: 0.75\n",
      "recon: 0.75\n",
      "reg: 0.04\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00, 10.96batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  5.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8417\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 16.47batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.13\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 10.56batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  60%|██████    | 3/5 [00:00<00:00, 14.45batch/s]total loss: 0.85\n",
      "recon: 0.76\n",
      "reg: 2.07\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00, 10.00batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  5.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00, 16.46batch/s]total loss: 0.74\n",
      "recon: 0.63\n",
      "reg: 2.86\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00, 10.58batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  4.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8258\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 17.10batch/s]total loss: 0.37\n",
      "recon: 0.48\n",
      "reg: -2.77\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 10.72batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  4.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 16.32batch/s]total loss: 1.04\n",
      "recon: 1.06\n",
      "reg: -0.72\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 10.55batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8823\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 17.02batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.33\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 10.98batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  5.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9097\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 16.26batch/s]total loss: 0.53\n",
      "recon: 0.63\n",
      "reg: -2.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 10.42batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  4.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7636\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  60%|██████    | 3/5 [00:00<00:00, 13.35batch/s]total loss: 0.93\n",
      "recon: 0.91\n",
      "reg: 0.48\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  9.31batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8492\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 16.88batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.33\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 10.70batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  60%|██████    | 3/5 [00:00<00:00, 12.37batch/s]total loss: 0.86\n",
      "recon: 0.82\n",
      "reg: 1.08\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00,  8.62batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  4.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8431\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 15.30batch/s]total loss: 1.19\n",
      "recon: 1.07\n",
      "reg: 3.22\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00,  8.86batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:01,  3.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9047\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 16.50batch/s]total loss: 0.98\n",
      "recon: 0.80\n",
      "reg: 4.48\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 10.57batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  4.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 17.36batch/s]total loss: 0.76\n",
      "recon: 0.70\n",
      "reg: 1.32\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00, 10.85batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  4.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8853\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 13.70batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.90\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00,  9.74batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:00<00:00, 16.70batch/s]total loss: 0.65\n",
      "recon: 0.58\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  7.79batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  2.79batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 17.17batch/s]total loss: 1.03\n",
      "recon: 1.05\n",
      "reg: -0.60\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 10.87batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9293\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 14.91batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.74\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  9.70batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 16.64batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.58\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00, 10.08batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  4.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8369\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 15.51batch/s]total loss: 0.66\n",
      "recon: 0.70\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  9.68batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  4.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 16.05batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.13\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00, 10.54batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  5.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9186\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 17.26batch/s]total loss: 0.56\n",
      "recon: 0.63\n",
      "reg: -1.68\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00, 10.62batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  4.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 17.34batch/s]total loss: 0.71\n",
      "recon: 0.75\n",
      "reg: -0.86\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 10.86batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8243\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  60%|██████    | 3/5 [00:00<00:00, 14.26batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.79\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00,  9.59batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8526\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 17.08batch/s]total loss: 0.87\n",
      "recon: 0.81\n",
      "reg: 1.67\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00, 10.97batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  5.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8549\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 16.51batch/s]total loss: 1.35\n",
      "recon: 1.29\n",
      "reg: 1.42\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00,  9.87batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  4.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 16.52batch/s]total loss: 1.17\n",
      "recon: 1.03\n",
      "reg: 3.66\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 10.48batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  4.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.96\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 17.41batch/s]total loss: 1.27\n",
      "recon: 1.29\n",
      "reg: -0.54\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00, 10.75batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  4.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 16.94batch/s]total loss: 0.97\n",
      "recon: 0.96\n",
      "reg: 0.04\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 10.54batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8667\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 15.44batch/s]total loss: 0.88\n",
      "recon: 0.86\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 10.01batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  4.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  60%|██████    | 3/5 [00:00<00:00, 12.68batch/s]total loss: 0.92\n",
      "recon: 0.87\n",
      "reg: 1.15\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  9.06batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  4.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 16.28batch/s]total loss: 0.92\n",
      "recon: 0.84\n",
      "reg: 2.00\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00,  9.25batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:01,  3.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 16.06batch/s]total loss: 0.92\n",
      "recon: 0.94\n",
      "reg: -0.45\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 10.40batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  4.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 16.60batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.89\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00, 10.62batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  4.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 17.43batch/s]total loss: 0.34\n",
      "recon: 0.53\n",
      "reg: -4.81\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 10.32batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7391\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 14.85batch/s]total loss: 1.03\n",
      "recon: 1.02\n",
      "reg: 0.36\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00,  6.70batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:01,  2.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 17.23batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.50\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 10.61batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 17.02batch/s]total loss: 0.78\n",
      "recon: 0.78\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  9.46batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:01,  3.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 18.09batch/s]total loss: 0.60\n",
      "recon: 0.58\n",
      "reg: 0.51\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 10.96batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7782\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 17.33batch/s]total loss: 0.69\n",
      "recon: 0.80\n",
      "reg: -2.77\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 10.82batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 15.61batch/s]total loss: 1.01\n",
      "recon: 1.06\n",
      "reg: -1.18\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  9.33batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 16.91batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.50\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 10.27batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 16.76batch/s]total loss: 0.86\n",
      "recon: 0.70\n",
      "reg: 3.93\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 10.36batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  4.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8203\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  60%|██████    | 3/5 [00:00<00:00, 13.68batch/s]total loss: 0.88\n",
      "recon: 0.95\n",
      "reg: -1.75\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  9.14batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  4.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 16.43batch/s]total loss: 0.70\n",
      "recon: 0.62\n",
      "reg: 1.82\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 10.26batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.794\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 16.87batch/s]total loss: 0.26\n",
      "recon: 0.40\n",
      "reg: -3.61\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  8.13batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  2.95batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.6987\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 16.49batch/s]total loss: 0.59\n",
      "recon: 0.57\n",
      "reg: 0.43\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 10.52batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7719\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 17.14batch/s]total loss: 0.96\n",
      "recon: 0.99\n",
      "reg: -0.90\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 10.82batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  4.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8422\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 16.30batch/s]total loss: 0.66\n",
      "recon: 0.73\n",
      "reg: -1.79\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  9.69batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  5.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 17.69batch/s]total loss: 1.19\n",
      "recon: 1.06\n",
      "reg: 3.29\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00, 10.84batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  4.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9232\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 17.06batch/s]total loss: 0.77\n",
      "recon: 0.81\n",
      "reg: -0.83\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 10.22batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  4.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8216\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 15.72batch/s]total loss: 1.34\n",
      "recon: 1.26\n",
      "reg: 1.98\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 10.24batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  4.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 17.21batch/s]total loss: 0.73\n",
      "recon: 0.70\n",
      "reg: 0.57\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00,  9.90batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  4.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 14.85batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.27\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  9.74batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8691\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  60%|██████    | 3/5 [00:00<00:00, 12.64batch/s]total loss: 0.82\n",
      "recon: 0.81\n",
      "reg: 0.11\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  8.83batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  4.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8416\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 15.75batch/s]total loss: 0.98\n",
      "recon: 1.08\n",
      "reg: -2.70\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:01<00:00,  4.28batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:03,  1.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8468\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 12.25batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.86\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00,  6.03batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:01,  2.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.79\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  60%|██████    | 3/5 [00:00<00:00, 10.87batch/s]total loss: 0.56\n",
      "recon: 0.57\n",
      "reg: -0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  8.38batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  4.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 15.25batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.67\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00, 10.12batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  4.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8143\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 17.41batch/s]total loss: 0.39\n",
      "recon: 0.38\n",
      "reg: 0.29\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00,  9.96batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  4.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7498\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 16.42batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 10.36batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7909\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 16.80batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.07\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 10.64batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.83\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  80%|████████  | 4/5 [00:00<00:00, 16.74batch/s]total loss: 1.07\n",
      "recon: 1.02\n",
      "reg: 1.30\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  9.76batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 15.93batch/s]total loss: 0.61\n",
      "recon: 0.64\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00,  6.48batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:01,  2.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 15.48batch/s]total loss: 0.31\n",
      "recon: 0.40\n",
      "reg: -2.21\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 10.14batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 13.66batch/s]total loss: 0.79\n",
      "recon: 0.64\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  9.36batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8183\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 16.78batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.51\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 10.70batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  4.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 16.88batch/s]total loss: 0.51\n",
      "recon: 0.46\n",
      "reg: 1.29\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  9.78batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 17.78batch/s]total loss: 0.76\n",
      "recon: 0.72\n",
      "reg: 0.88\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00, 10.73batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8033\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 17.39batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.35\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  8.06batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:01,  2.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8392\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  60%|██████    | 3/5 [00:00<00:00, 13.81batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.35\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  9.62batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  4.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8333\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 17.12batch/s]total loss: 0.94\n",
      "recon: 0.82\n",
      "reg: 2.90\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 10.76batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 17.70batch/s]total loss: 0.71\n",
      "recon: 0.78\n",
      "reg: -1.62\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:01,  3.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 15.79batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.77\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  9.61batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8986\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 13.84batch/s]total loss: 0.91\n",
      "recon: 0.92\n",
      "reg: -0.23\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  9.33batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8309\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  60%|██████    | 3/5 [00:00<00:00, 13.59batch/s]total loss: 0.65\n",
      "recon: 0.61\n",
      "reg: 0.89\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  7.84batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  3.14batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 15.83batch/s]total loss: 1.08\n",
      "recon: 0.99\n",
      "reg: 2.14\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00, 10.34batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8833\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 14.08batch/s]total loss: 0.63\n",
      "recon: 0.60\n",
      "reg: 0.78\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  9.89batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  5.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7938\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 16.33batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.84\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00, 10.31batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 16.81batch/s]total loss: 0.70\n",
      "recon: 0.63\n",
      "reg: 1.61\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00, 10.91batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  5.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  60%|██████    | 3/5 [00:00<00:00, 13.99batch/s]total loss: 0.78\n",
      "recon: 0.83\n",
      "reg: -1.19\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  9.59batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8094\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00,  6.76batch/s]total loss: 1.65\n",
      "recon: 1.55\n",
      "reg: 2.45\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  6.49batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  4.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9859\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 16.47batch/s]total loss: 0.91\n",
      "recon: 0.89\n",
      "reg: 0.35\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  9.54batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:01,  3.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 17.24batch/s]total loss: 0.92\n",
      "recon: 0.82\n",
      "reg: 2.52\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00, 10.87batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8423\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 16.42batch/s]total loss: 1.58\n",
      "recon: 1.54\n",
      "reg: 0.99\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 10.42batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  60%|██████    | 3/5 [00:00<00:00, 14.11batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.73\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  9.55batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  4.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8236\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_20-13-20/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.114875004534, Time: 105.14s\n",
      "Epoch 200, Training Loss: 0.041040038015, Time: 208.79s\n",
      "Epoch 300, Training Loss: 0.014057180213, Time: 306.90s\n",
      "Epoch 400, Training Loss: 0.009489276013, Time: 404.67s\n",
      "Epoch 500, Training Loss: 0.005714449228, Time: 504.39s\n",
      "Epoch 600, Training Loss: 0.003244221902, Time: 600.75s\n",
      "Epoch 700, Training Loss: 0.001277019807, Time: 695.72s\n",
      "Epoch 800, Training Loss: 0.000573103592, Time: 796.39s\n",
      "Epoch 900, Training Loss: 0.000360323455, Time: 903.30s\n",
      "Epoch 1000, Training Loss: 0.000390910856, Time: 998.05s\n",
      "Validation Loss: 0.000205482999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d24f25dcef43409d8dab2f6c4f697c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00021</td></tr><tr><td>val_loss</td><td>0.00021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comfy-sweep-12</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/ga8jixbm' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/ga8jixbm</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250325_201319-ga8jixbm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 860awzkr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008916165210054205\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250325_203206-860awzkr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/860awzkr' target=\"_blank\">cerulean-sweep-13</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/860awzkr' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/860awzkr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_20-32-07. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 14.81batch/s]total loss: 4.54\n",
      "recon: 4.25\n",
      "reg: 7.01\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  9.58batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:00,  4.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.4454\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 16.49batch/s]total loss: 1.09\n",
      "recon: 1.05\n",
      "reg: 1.10\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 11.12batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  5.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.5912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 16.28batch/s]total loss: 1.23\n",
      "recon: 1.27\n",
      "reg: -1.13\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00, 11.07batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  5.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2307\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 16.27batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.76\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 10.87batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  5.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 17.40batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.45\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00, 11.19batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  5.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9394\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  60%|██████    | 3/5 [00:00<00:00, 14.40batch/s]total loss: 0.81\n",
      "recon: 0.71\n",
      "reg: 2.51\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 10.51batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  5.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 18.23batch/s]total loss: 0.67\n",
      "recon: 0.70\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 11.39batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  5.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 17.54batch/s]total loss: 0.71\n",
      "recon: 0.71\n",
      "reg: -0.09\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 11.49batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  5.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  60%|██████    | 3/5 [00:00<00:00, 15.14batch/s]total loss: 1.02\n",
      "recon: 0.89\n",
      "reg: 3.25\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 10.17batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  5.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9044\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 18.65batch/s]total loss: 0.65\n",
      "recon: 0.57\n",
      "reg: 2.05\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00, 11.46batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  5.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 17.93batch/s]total loss: 1.09\n",
      "recon: 0.94\n",
      "reg: 3.71\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 11.75batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  5.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9274\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 15.63batch/s]total loss: 0.93\n",
      "recon: 0.85\n",
      "reg: 1.84\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00, 10.50batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  5.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 16.47batch/s]total loss: 1.01\n",
      "recon: 0.97\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 11.34batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  5.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 17.85batch/s]total loss: 0.65\n",
      "recon: 0.65\n",
      "reg: -0.11\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 11.77batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  5.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 15.54batch/s]total loss: 0.75\n",
      "recon: 0.75\n",
      "reg: 0.04\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00, 10.54batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  5.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8417\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 18.21batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.13\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 11.24batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 17.73batch/s]total loss: 0.85\n",
      "recon: 0.76\n",
      "reg: 2.07\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00, 11.49batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  5.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  60%|██████    | 3/5 [00:00<00:00, 14.18batch/s]total loss: 0.74\n",
      "recon: 0.63\n",
      "reg: 2.86\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00, 10.20batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  5.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8258\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 17.80batch/s]total loss: 0.37\n",
      "recon: 0.48\n",
      "reg: -2.77\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 11.14batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  5.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 17.14batch/s]total loss: 1.04\n",
      "recon: 1.06\n",
      "reg: -0.72\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 11.65batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8823\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  60%|██████    | 3/5 [00:00<00:00, 14.61batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.33\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 10.36batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  5.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9097\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 17.60batch/s]total loss: 0.53\n",
      "recon: 0.63\n",
      "reg: -2.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00,  9.51batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:01,  3.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7636\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 18.13batch/s]total loss: 0.93\n",
      "recon: 0.91\n",
      "reg: 0.48\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00, 11.43batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  5.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8492\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 18.24batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.33\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 10.63batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  5.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 17.71batch/s]total loss: 0.86\n",
      "recon: 0.82\n",
      "reg: 1.08\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 11.27batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  5.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8431\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 17.72batch/s]total loss: 1.19\n",
      "recon: 1.07\n",
      "reg: 3.22\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 11.58batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  5.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9047\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 17.08batch/s]total loss: 0.98\n",
      "recon: 0.80\n",
      "reg: 4.48\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 10.20batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  4.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 18.18batch/s]total loss: 0.76\n",
      "recon: 0.70\n",
      "reg: 1.32\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00, 11.41batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  5.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8853\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 18.51batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.90\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 11.62batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  5.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:00<00:00, 18.25batch/s]total loss: 0.65\n",
      "recon: 0.58\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  8.23batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  2.82batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 17.63batch/s]total loss: 1.03\n",
      "recon: 1.05\n",
      "reg: -0.60\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 11.50batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  5.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9293\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 17.34batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.74\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00, 10.96batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 17.05batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.58\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00, 10.14batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  4.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8369\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 16.50batch/s]total loss: 0.66\n",
      "recon: 0.70\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00, 10.92batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  5.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 16.22batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.13\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00, 11.01batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  5.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9186\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 10.74batch/s]total loss: 0.56\n",
      "recon: 0.63\n",
      "reg: -1.68\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  8.56batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 17.48batch/s]total loss: 0.71\n",
      "recon: 0.75\n",
      "reg: -0.86\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 11.32batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  5.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8243\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 15.43batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.79\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 10.57batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  5.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8526\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  60%|██████    | 3/5 [00:00<00:00, 14.41batch/s]total loss: 0.87\n",
      "recon: 0.81\n",
      "reg: 1.67\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  9.99batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8549\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 17.01batch/s]total loss: 1.35\n",
      "recon: 1.29\n",
      "reg: 1.42\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 11.24batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  5.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 18.13batch/s]total loss: 1.17\n",
      "recon: 1.03\n",
      "reg: 3.66\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 11.40batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  5.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.96\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 16.02batch/s]total loss: 1.27\n",
      "recon: 1.29\n",
      "reg: -0.54\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00, 10.91batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  5.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 17.16batch/s]total loss: 0.97\n",
      "recon: 0.96\n",
      "reg: 0.04\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 11.36batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  5.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8667\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 17.99batch/s]total loss: 0.88\n",
      "recon: 0.86\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 11.20batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  4.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 15.83batch/s]total loss: 0.92\n",
      "recon: 0.87\n",
      "reg: 1.15\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00, 10.46batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  5.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 17.81batch/s]total loss: 0.92\n",
      "recon: 0.84\n",
      "reg: 2.00\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00, 11.21batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  5.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 16.88batch/s]total loss: 0.92\n",
      "recon: 0.94\n",
      "reg: -0.45\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 11.21batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  5.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 17.79batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.89\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00, 11.50batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  5.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 18.31batch/s]total loss: 0.34\n",
      "recon: 0.53\n",
      "reg: -4.81\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 11.34batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  5.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7391\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 18.52batch/s]total loss: 1.03\n",
      "recon: 1.02\n",
      "reg: 0.36\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 10.24batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  4.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 18.33batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.50\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 11.55batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  5.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 17.02batch/s]total loss: 0.78\n",
      "recon: 0.78\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00, 10.97batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  5.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 17.86batch/s]total loss: 0.60\n",
      "recon: 0.58\n",
      "reg: 0.51\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 10.05batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  4.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7782\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 18.07batch/s]total loss: 0.69\n",
      "recon: 0.80\n",
      "reg: -2.77\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 11.61batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  5.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 18.33batch/s]total loss: 1.01\n",
      "recon: 1.06\n",
      "reg: -1.18\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 10.98batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  4.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 15.76batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.50\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 10.42batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  5.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 18.01batch/s]total loss: 0.86\n",
      "recon: 0.70\n",
      "reg: 3.93\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 11.50batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  5.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8203\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  60%|██████    | 3/5 [00:00<00:00, 11.57batch/s]total loss: 0.88\n",
      "recon: 0.95\n",
      "reg: -1.75\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  9.28batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  5.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  60%|██████    | 3/5 [00:00<00:00, 14.59batch/s]total loss: 0.70\n",
      "recon: 0.62\n",
      "reg: 1.82\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 10.35batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  5.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.794\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 17.66batch/s]total loss: 0.26\n",
      "recon: 0.40\n",
      "reg: -3.61\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  9.16batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  3.39batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.6987\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 17.18batch/s]total loss: 0.59\n",
      "recon: 0.57\n",
      "reg: 0.43\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  9.90batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7719\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 17.32batch/s]total loss: 0.96\n",
      "recon: 0.99\n",
      "reg: -0.90\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 11.13batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  5.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8422\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 16.67batch/s]total loss: 0.66\n",
      "recon: 0.73\n",
      "reg: -1.79\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00, 10.92batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  5.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 18.57batch/s]total loss: 1.19\n",
      "recon: 1.06\n",
      "reg: 3.29\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00, 10.46batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  4.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9232\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 16.65batch/s]total loss: 0.77\n",
      "recon: 0.81\n",
      "reg: -0.83\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 11.04batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  5.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8216\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 18.32batch/s]total loss: 1.34\n",
      "recon: 1.26\n",
      "reg: 1.98\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 11.27batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  4.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  60%|██████    | 3/5 [00:00<00:00, 15.42batch/s]total loss: 0.73\n",
      "recon: 0.70\n",
      "reg: 0.57\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 10.79batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  5.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 18.10batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.27\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00, 11.61batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  5.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8691\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 18.57batch/s]total loss: 0.82\n",
      "recon: 0.81\n",
      "reg: 0.11\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00, 12.21batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  5.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8416\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 15.29batch/s]total loss: 0.98\n",
      "recon: 1.08\n",
      "reg: -2.70\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 10.44batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  5.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8468\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 18.34batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.86\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 11.28batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.79\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 18.39batch/s]total loss: 0.56\n",
      "recon: 0.57\n",
      "reg: -0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00, 10.43batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  4.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 18.35batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.67\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00, 11.61batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  5.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8143\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 18.14batch/s]total loss: 0.39\n",
      "recon: 0.38\n",
      "reg: 0.29\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 11.40batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  5.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7498\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 15.16batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 10.94batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  5.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7909\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 18.38batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.07\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 11.71batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  5.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.83\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  80%|████████  | 4/5 [00:00<00:00, 18.00batch/s]total loss: 1.07\n",
      "recon: 1.02\n",
      "reg: 1.30\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00, 11.56batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  5.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  60%|██████    | 3/5 [00:00<00:00, 15.12batch/s]total loss: 0.61\n",
      "recon: 0.64\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 10.91batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  5.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 18.41batch/s]total loss: 0.31\n",
      "recon: 0.40\n",
      "reg: -2.21\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 11.97batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  5.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 18.15batch/s]total loss: 0.79\n",
      "recon: 0.64\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 11.22batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8183\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  60%|██████    | 3/5 [00:00<00:00, 14.49batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.51\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 10.04batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  4.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 18.06batch/s]total loss: 0.51\n",
      "recon: 0.46\n",
      "reg: 1.29\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00, 11.39batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  5.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 18.30batch/s]total loss: 0.76\n",
      "recon: 0.72\n",
      "reg: 0.88\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00, 11.54batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  5.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8033\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 16.21batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.35\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00, 10.55batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8392\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 17.97batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.35\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 11.42batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  5.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8333\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 18.07batch/s]total loss: 0.94\n",
      "recon: 0.82\n",
      "reg: 2.90\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 10.42batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 17.74batch/s]total loss: 0.71\n",
      "recon: 0.78\n",
      "reg: -1.62\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 11.43batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  5.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 17.98batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.77\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00, 11.63batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  5.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8986\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 17.12batch/s]total loss: 0.91\n",
      "recon: 0.92\n",
      "reg: -0.23\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00, 10.13batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8309\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 17.66batch/s]total loss: 0.65\n",
      "recon: 0.61\n",
      "reg: 0.89\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  8.97batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  3.25batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 16.52batch/s]total loss: 1.08\n",
      "recon: 0.99\n",
      "reg: 2.14\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  9.87batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  4.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8833\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 17.28batch/s]total loss: 0.63\n",
      "recon: 0.60\n",
      "reg: 0.78\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00, 11.11batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  5.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7938\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 17.17batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.84\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00, 10.71batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  60%|██████    | 3/5 [00:00<00:00, 14.33batch/s]total loss: 0.70\n",
      "recon: 0.63\n",
      "reg: 1.61\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  9.54batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 17.18batch/s]total loss: 0.78\n",
      "recon: 0.83\n",
      "reg: -1.19\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 11.17batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  5.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8094\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 17.78batch/s]total loss: 1.65\n",
      "recon: 1.55\n",
      "reg: 2.45\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00, 11.00batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9859\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  60%|██████    | 3/5 [00:00<00:00, 12.08batch/s]total loss: 0.91\n",
      "recon: 0.89\n",
      "reg: 0.35\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  9.32batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 13.81batch/s]total loss: 0.92\n",
      "recon: 0.82\n",
      "reg: 2.52\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  9.84batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8423\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 17.21batch/s]total loss: 1.58\n",
      "recon: 1.54\n",
      "reg: 0.99\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 11.15batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  5.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  60%|██████    | 3/5 [00:00<00:00, 14.46batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.73\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00, 10.17batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  5.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8236\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_20-32-07/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.114875004534, Time: 96.19s\n",
      "Epoch 200, Training Loss: 0.041040038015, Time: 198.54s\n",
      "Epoch 300, Training Loss: 0.014057180213, Time: 301.20s\n",
      "Epoch 400, Training Loss: 0.009489276013, Time: 400.63s\n",
      "Epoch 500, Training Loss: 0.005714449228, Time: 501.73s\n",
      "Epoch 600, Training Loss: 0.003244221902, Time: 603.65s\n",
      "Epoch 700, Training Loss: 0.001277019807, Time: 706.19s\n",
      "Epoch 800, Training Loss: 0.000573103592, Time: 806.26s\n",
      "Epoch 900, Training Loss: 0.000360323455, Time: 906.49s\n",
      "Epoch 1000, Training Loss: 0.000390910856, Time: 1011.88s\n",
      "Validation Loss: 0.000205482999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00021</td></tr><tr><td>val_loss</td><td>0.00021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cerulean-sweep-13</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/860awzkr' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/860awzkr</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250325_203206-860awzkr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9k53ga40 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004922139968356739\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250325_205008-9k53ga40</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/9k53ga40' target=\"_blank\">zesty-sweep-14</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/9k53ga40' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/9k53ga40</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_20-50-09. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 15.23batch/s]total loss: 4.54\n",
      "recon: 4.25\n",
      "reg: 7.01\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  9.34batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:00,  4.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.4454\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 16.09batch/s]total loss: 1.09\n",
      "recon: 1.05\n",
      "reg: 1.10\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 10.02batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  4.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.5912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 17.32batch/s]total loss: 1.23\n",
      "recon: 1.27\n",
      "reg: -1.13\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00, 11.17batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  5.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2307\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 17.06batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.76\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 10.90batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  5.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 17.39batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.45\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00, 11.23batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  5.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9394\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 15.87batch/s]total loss: 0.81\n",
      "recon: 0.71\n",
      "reg: 2.51\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00,  9.76batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  5.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 16.93batch/s]total loss: 0.67\n",
      "recon: 0.70\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 10.67batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 17.68batch/s]total loss: 0.71\n",
      "recon: 0.71\n",
      "reg: -0.09\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 11.16batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  5.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 15.30batch/s]total loss: 1.02\n",
      "recon: 0.89\n",
      "reg: 3.25\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 10.33batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  5.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9044\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 17.30batch/s]total loss: 0.65\n",
      "recon: 0.57\n",
      "reg: 2.05\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00, 11.16batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  5.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 18.11batch/s]total loss: 1.09\n",
      "recon: 0.94\n",
      "reg: 3.71\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00,  8.93batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:01,  3.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9274\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  60%|██████    | 3/5 [00:00<00:00, 12.68batch/s]total loss: 0.93\n",
      "recon: 0.85\n",
      "reg: 1.84\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  9.47batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  5.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 17.49batch/s]total loss: 1.01\n",
      "recon: 0.97\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 10.92batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 16.35batch/s]total loss: 0.65\n",
      "recon: 0.65\n",
      "reg: -0.11\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 10.61batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  5.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  60%|██████    | 3/5 [00:00<00:00, 13.85batch/s]total loss: 0.75\n",
      "recon: 0.75\n",
      "reg: 0.04\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  9.84batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  5.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8417\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 17.19batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.13\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 10.99batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  5.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 15.80batch/s]total loss: 0.85\n",
      "recon: 0.76\n",
      "reg: 2.07\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00,  9.70batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  4.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  60%|██████    | 3/5 [00:00<00:00, 14.98batch/s]total loss: 0.74\n",
      "recon: 0.63\n",
      "reg: 2.86\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00, 10.08batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  5.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8258\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 17.49batch/s]total loss: 0.37\n",
      "recon: 0.48\n",
      "reg: -2.77\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 11.11batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  5.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 17.22batch/s]total loss: 1.04\n",
      "recon: 1.06\n",
      "reg: -0.72\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 11.15batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8823\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  60%|██████    | 3/5 [00:00<00:00, 14.62batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.33\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 10.16batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  5.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9097\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 17.81batch/s]total loss: 0.53\n",
      "recon: 0.63\n",
      "reg: -2.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 11.30batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  5.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7636\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 17.13batch/s]total loss: 0.93\n",
      "recon: 0.91\n",
      "reg: 0.48\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00, 10.67batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  4.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8492\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  60%|██████    | 3/5 [00:00<00:00, 14.23batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.33\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00,  9.65batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 17.11batch/s]total loss: 0.86\n",
      "recon: 0.82\n",
      "reg: 1.08\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 10.98batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  5.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8431\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 17.76batch/s]total loss: 1.19\n",
      "recon: 1.07\n",
      "reg: 3.22\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 11.21batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  5.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9047\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 17.45batch/s]total loss: 0.98\n",
      "recon: 0.80\n",
      "reg: 4.48\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 10.04batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  5.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 15.67batch/s]total loss: 0.76\n",
      "recon: 0.70\n",
      "reg: 1.32\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00, 10.46batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  5.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8853\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 17.44batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.90\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 10.24batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  4.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  60%|██████    | 3/5 [00:00<00:00, 13.58batch/s]total loss: 0.65\n",
      "recon: 0.58\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  7.96batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  3.22batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 17.01batch/s]total loss: 1.03\n",
      "recon: 1.05\n",
      "reg: -0.60\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 10.85batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  5.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9293\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 17.08batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.74\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00, 11.14batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  60%|██████    | 3/5 [00:00<00:00, 14.46batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.58\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  9.61batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  4.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8369\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 16.06batch/s]total loss: 0.66\n",
      "recon: 0.70\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00, 10.32batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  4.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 16.08batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.13\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00, 10.56batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  5.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9186\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 16.77batch/s]total loss: 0.56\n",
      "recon: 0.63\n",
      "reg: -1.68\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00, 10.58batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  4.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 15.35batch/s]total loss: 0.71\n",
      "recon: 0.75\n",
      "reg: -0.86\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00,  9.89batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  4.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8243\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 16.63batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.79\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 10.68batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8526\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  60%|██████    | 3/5 [00:00<00:00, 13.13batch/s]total loss: 0.87\n",
      "recon: 0.81\n",
      "reg: 1.67\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  9.49batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  5.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8549\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 15.84batch/s]total loss: 1.35\n",
      "recon: 1.29\n",
      "reg: 1.42\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 10.33batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  4.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 17.10batch/s]total loss: 1.17\n",
      "recon: 1.03\n",
      "reg: 3.66\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 10.43batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  4.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.96\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  60%|██████    | 3/5 [00:00<00:00, 14.21batch/s]total loss: 1.27\n",
      "recon: 1.29\n",
      "reg: -0.54\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  9.68batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 17.09batch/s]total loss: 0.97\n",
      "recon: 0.96\n",
      "reg: 0.04\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 10.51batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  4.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8667\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 17.24batch/s]total loss: 0.88\n",
      "recon: 0.86\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 10.95batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  5.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 16.15batch/s]total loss: 0.92\n",
      "recon: 0.87\n",
      "reg: 1.15\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00, 10.17batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 17.58batch/s]total loss: 0.92\n",
      "recon: 0.84\n",
      "reg: 2.00\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00, 10.87batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 16.59batch/s]total loss: 0.92\n",
      "recon: 0.94\n",
      "reg: -0.45\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  9.64batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:01,  3.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 17.06batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.89\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00, 10.91batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  5.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 16.88batch/s]total loss: 0.34\n",
      "recon: 0.53\n",
      "reg: -4.81\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 10.59batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  5.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7391\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 17.36batch/s]total loss: 1.03\n",
      "recon: 1.02\n",
      "reg: 0.36\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 10.18batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  5.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 16.86batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.50\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 10.63batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 12.47batch/s]total loss: 0.78\n",
      "recon: 0.78\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  8.84batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  5.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  60%|██████    | 3/5 [00:00<00:00, 14.25batch/s]total loss: 0.60\n",
      "recon: 0.58\n",
      "reg: 0.51\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00,  9.67batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  5.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7782\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 16.75batch/s]total loss: 0.69\n",
      "recon: 0.80\n",
      "reg: -2.77\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 10.77batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  5.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 16.98batch/s]total loss: 1.01\n",
      "recon: 1.06\n",
      "reg: -1.18\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 10.49batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 16.68batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.50\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 10.02batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 15.58batch/s]total loss: 0.86\n",
      "recon: 0.70\n",
      "reg: 3.93\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 10.24batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8203\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 16.84batch/s]total loss: 0.88\n",
      "recon: 0.95\n",
      "reg: -1.75\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:01,  3.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 16.31batch/s]total loss: 0.70\n",
      "recon: 0.62\n",
      "reg: 1.82\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 10.19batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  4.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.794\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 16.29batch/s]total loss: 0.26\n",
      "recon: 0.40\n",
      "reg: -3.61\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  8.33batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  3.02batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.6987\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 17.33batch/s]total loss: 0.59\n",
      "recon: 0.57\n",
      "reg: 0.43\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  9.49batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7719\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 17.36batch/s]total loss: 0.96\n",
      "recon: 0.99\n",
      "reg: -0.90\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 11.02batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  5.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8422\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 17.18batch/s]total loss: 0.66\n",
      "recon: 0.73\n",
      "reg: -1.79\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00, 10.62batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  60%|██████    | 3/5 [00:00<00:00, 13.16batch/s]total loss: 1.19\n",
      "recon: 1.06\n",
      "reg: 3.29\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  9.38batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9232\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 16.96batch/s]total loss: 0.77\n",
      "recon: 0.81\n",
      "reg: -0.83\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 10.07batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  4.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8216\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 17.37batch/s]total loss: 1.34\n",
      "recon: 1.26\n",
      "reg: 1.98\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 10.84batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  60%|██████    | 3/5 [00:00<00:00, 14.01batch/s]total loss: 0.73\n",
      "recon: 0.70\n",
      "reg: 0.57\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00,  9.78batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  4.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 16.28batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.27\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00, 10.41batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8691\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 17.22batch/s]total loss: 0.82\n",
      "recon: 0.81\n",
      "reg: 0.11\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00, 11.11batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  5.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8416\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  60%|██████    | 3/5 [00:00<00:00, 14.61batch/s]total loss: 0.98\n",
      "recon: 1.08\n",
      "reg: -2.70\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00,  9.82batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  4.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8468\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 17.11batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.86\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 10.64batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  5.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.79\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 17.08batch/s]total loss: 0.56\n",
      "recon: 0.57\n",
      "reg: -0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  9.59batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:01,  3.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 17.21batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.67\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00, 10.46batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8143\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 17.30batch/s]total loss: 0.39\n",
      "recon: 0.38\n",
      "reg: 0.29\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 10.84batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  4.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7498\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 17.45batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00,  9.50batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  4.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7909\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 16.97batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.07\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 11.21batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  5.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.83\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  80%|████████  | 4/5 [00:00<00:00, 17.32batch/s]total loss: 1.07\n",
      "recon: 1.02\n",
      "reg: 1.30\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00, 11.09batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  5.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  60%|██████    | 3/5 [00:00<00:00, 13.84batch/s]total loss: 0.61\n",
      "recon: 0.64\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00,  9.84batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  5.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 17.03batch/s]total loss: 0.31\n",
      "recon: 0.40\n",
      "reg: -2.21\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 11.18batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  5.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 17.59batch/s]total loss: 0.79\n",
      "recon: 0.64\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  9.54batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:01,  3.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8183\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 17.43batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.51\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 10.60batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 17.46batch/s]total loss: 0.51\n",
      "recon: 0.46\n",
      "reg: 1.29\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00, 11.01batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 14.29batch/s]total loss: 0.76\n",
      "recon: 0.72\n",
      "reg: 0.88\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00, 10.05batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  5.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8033\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 18.23batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.35\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00, 11.15batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  4.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8392\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 16.91batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.35\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  9.81batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  4.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8333\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 16.49batch/s]total loss: 0.94\n",
      "recon: 0.82\n",
      "reg: 2.90\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 10.77batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  5.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 17.47batch/s]total loss: 0.71\n",
      "recon: 0.78\n",
      "reg: -1.62\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 10.98batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  60%|██████    | 3/5 [00:00<00:00, 14.55batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.77\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  9.93batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  5.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8986\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  60%|██████    | 3/5 [00:00<00:00, 13.04batch/s]total loss: 0.91\n",
      "recon: 0.92\n",
      "reg: -0.23\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  9.66batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  5.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8309\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 17.17batch/s]total loss: 0.65\n",
      "recon: 0.61\n",
      "reg: 0.89\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  7.02batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.21batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 16.05batch/s]total loss: 1.08\n",
      "recon: 0.99\n",
      "reg: 2.14\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00, 10.27batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  4.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8833\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 17.64batch/s]total loss: 0.63\n",
      "recon: 0.60\n",
      "reg: 0.78\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00, 11.15batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  5.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7938\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  60%|██████    | 3/5 [00:00<00:00, 14.49batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.84\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  9.83batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 16.73batch/s]total loss: 0.70\n",
      "recon: 0.63\n",
      "reg: 1.61\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  9.74batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 15.86batch/s]total loss: 0.78\n",
      "recon: 0.83\n",
      "reg: -1.19\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  9.32batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8094\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 17.45batch/s]total loss: 1.65\n",
      "recon: 1.55\n",
      "reg: 2.45\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00, 10.68batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9859\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 16.14batch/s]total loss: 0.91\n",
      "recon: 0.89\n",
      "reg: 0.35\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00, 10.28batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  4.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  60%|██████    | 3/5 [00:00<00:00, 13.61batch/s]total loss: 0.92\n",
      "recon: 0.82\n",
      "reg: 2.52\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  9.23batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  4.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8423\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 17.11batch/s]total loss: 1.58\n",
      "recon: 1.54\n",
      "reg: 0.99\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 10.02batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 17.23batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.73\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  9.88batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  4.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8236\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_20-50-09/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.114875004534, Time: 102.66s\n",
      "Epoch 200, Training Loss: 0.041040038015, Time: 215.15s\n",
      "Epoch 300, Training Loss: 0.014057180213, Time: 323.01s\n",
      "Epoch 400, Training Loss: 0.009489276013, Time: 430.18s\n",
      "Epoch 500, Training Loss: 0.005714449228, Time: 538.37s\n",
      "Epoch 600, Training Loss: 0.003244221902, Time: 646.65s\n",
      "Epoch 700, Training Loss: 0.001277019807, Time: 752.28s\n",
      "Epoch 800, Training Loss: 0.000573103592, Time: 860.17s\n",
      "Epoch 900, Training Loss: 0.000360323455, Time: 975.40s\n",
      "Epoch 1000, Training Loss: 0.000390910856, Time: 1080.41s\n",
      "Validation Loss: 0.000205482999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00021</td></tr><tr><td>val_loss</td><td>0.00021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zesty-sweep-14</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/9k53ga40' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/9k53ga40</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250325_205008-9k53ga40/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wknlqu0u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0011219200173283787\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250325_210928-wknlqu0u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/wknlqu0u' target=\"_blank\">playful-sweep-15</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/wknlqu0u' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/wknlqu0u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_21-09-29. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 16.70batch/s]total loss: 4.22\n",
      "recon: 3.77\n",
      "reg: 11.31\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  9.36batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:01,  3.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 5.8681\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 17.85batch/s]total loss: 1.65\n",
      "recon: 1.54\n",
      "reg: 2.77\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00,  9.19batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:01,  3.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 2.0765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  60%|██████    | 3/5 [00:00<00:00,  7.46batch/s]total loss: 1.12\n",
      "recon: 1.00\n",
      "reg: 3.06\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  5.76batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:01,  3.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.3569\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  60%|██████    | 3/5 [00:00<00:00, 13.91batch/s]total loss: 0.75\n",
      "recon: 0.73\n",
      "reg: 0.54\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00,  8.96batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:01,  3.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.3297\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 15.33batch/s]total loss: 0.75\n",
      "recon: 0.72\n",
      "reg: 0.86\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00, 10.81batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  5.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9718\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 15.23batch/s]total loss: 0.86\n",
      "recon: 0.67\n",
      "reg: 4.65\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00,  9.29batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  5.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  60%|██████    | 3/5 [00:00<00:00, 14.02batch/s]total loss: 0.58\n",
      "recon: 0.62\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 10.33batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  5.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8504\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 15.67batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.41\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 10.59batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  5.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8605\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 15.65batch/s]total loss: 1.01\n",
      "recon: 0.83\n",
      "reg: 4.63\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 10.85batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  5.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8974\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 13.97batch/s]total loss: 0.63\n",
      "recon: 0.53\n",
      "reg: 2.50\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00, 10.33batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  6.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8088\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 14.86batch/s]total loss: 0.84\n",
      "recon: 0.68\n",
      "reg: 4.15\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 10.89batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  5.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8563\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  60%|██████    | 3/5 [00:00<00:00, 11.22batch/s]total loss: 0.83\n",
      "recon: 0.70\n",
      "reg: 3.16\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  9.76batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  6.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0289\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 14.95batch/s]total loss: 0.90\n",
      "recon: 0.87\n",
      "reg: 0.61\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 10.84batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  6.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  60%|██████    | 3/5 [00:00<00:00, 12.32batch/s]total loss: 0.50\n",
      "recon: 0.48\n",
      "reg: 0.51\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00,  9.91batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  5.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8685\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  60%|██████    | 3/5 [00:00<00:00, 16.29batch/s]total loss: 0.73\n",
      "recon: 0.74\n",
      "reg: -0.29\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00, 12.13batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  6.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.945\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 13.12batch/s]total loss: 0.84\n",
      "recon: 0.88\n",
      "reg: -0.84\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00,  8.88batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9212\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  60%|██████    | 3/5 [00:00<00:00, 15.78batch/s]total loss: 1.04\n",
      "recon: 0.98\n",
      "reg: 1.45\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00, 11.78batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  6.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9489\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  60%|██████    | 3/5 [00:00<00:00, 21.48batch/s]total loss: 0.80\n",
      "recon: 0.66\n",
      "reg: 3.54\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00, 11.60batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  5.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  60%|██████    | 3/5 [00:00<00:00, 20.52batch/s]total loss: 0.41\n",
      "recon: 0.50\n",
      "reg: -2.36\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 10.07batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  4.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7855\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  60%|██████    | 3/5 [00:00<00:00, 21.37batch/s]total loss: 1.01\n",
      "recon: 1.02\n",
      "reg: -0.26\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 11.31batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9014\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 15.38batch/s]total loss: 1.25\n",
      "recon: 1.16\n",
      "reg: 2.12\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 11.13batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  5.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9263\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 22.58batch/s]total loss: 0.56\n",
      "recon: 0.64\n",
      "reg: -2.12\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 12.36batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  5.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.792\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00, 19.81batch/s]total loss: 0.90\n",
      "recon: 0.86\n",
      "reg: 0.97\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00, 10.74batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  5.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8642\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 22.53batch/s]total loss: 1.04\n",
      "recon: 1.03\n",
      "reg: 0.46\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 10.87batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  60%|██████    | 3/5 [00:00<00:00, 20.86batch/s]total loss: 0.85\n",
      "recon: 0.80\n",
      "reg: 1.07\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 12.39batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  5.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8486\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 18.24batch/s]total loss: 1.23\n",
      "recon: 1.09\n",
      "reg: 3.67\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 11.90batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  5.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 23.99batch/s]total loss: 0.90\n",
      "recon: 0.72\n",
      "reg: 4.61\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 12.33batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  5.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8568\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  60%|██████    | 3/5 [00:00<00:00, 12.20batch/s]total loss: 0.67\n",
      "recon: 0.62\n",
      "reg: 1.08\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  9.69batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  5.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8687\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 23.95batch/s]total loss: 0.96\n",
      "recon: 0.90\n",
      "reg: 1.38\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 11.64batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  5.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8994\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:00<00:00, 18.43batch/s]total loss: 0.66\n",
      "recon: 0.59\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  5.50batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:02,  1.50batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.821\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 12.45batch/s]total loss: 0.99\n",
      "recon: 1.01\n",
      "reg: -0.54\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00,  7.71batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:01,  3.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9282\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 14.40batch/s]total loss: 0.90\n",
      "recon: 0.92\n",
      "reg: -0.43\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  8.08batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9571\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 17.05batch/s]total loss: 0.69\n",
      "recon: 0.72\n",
      "reg: -0.65\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00, 11.18batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  5.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  60%|██████    | 3/5 [00:00<00:00, 17.06batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00, 11.17batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  5.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8364\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  60%|██████    | 3/5 [00:00<00:00, 12.89batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.17\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  9.80batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  5.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9152\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 16.48batch/s]total loss: 0.61\n",
      "recon: 0.66\n",
      "reg: -1.35\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00, 11.08batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  5.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 16.28batch/s]total loss: 0.67\n",
      "recon: 0.71\n",
      "reg: -0.88\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 10.83batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  5.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8229\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  60%|██████    | 3/5 [00:00<00:00, 12.76batch/s]total loss: 0.75\n",
      "recon: 0.71\n",
      "reg: 1.01\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00,  9.64batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  5.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8788\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 16.58batch/s]total loss: 0.86\n",
      "recon: 0.79\n",
      "reg: 1.79\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00, 11.14batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  5.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8673\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 17.42batch/s]total loss: 1.31\n",
      "recon: 1.27\n",
      "reg: 1.05\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 10.23batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  5.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 12.72batch/s]total loss: 1.20\n",
      "recon: 1.07\n",
      "reg: 3.32\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00,  9.01batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  5.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9633\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00, 23.41batch/s]total loss: 1.30\n",
      "recon: 1.31\n",
      "reg: -0.36\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00, 12.83batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  6.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9496\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 17.13batch/s]total loss: 0.93\n",
      "recon: 0.93\n",
      "reg: 0.17\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 11.40batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  5.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 15.31batch/s]total loss: 0.94\n",
      "recon: 0.92\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00,  9.27batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  6.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8562\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 17.54batch/s]total loss: 0.93\n",
      "recon: 0.88\n",
      "reg: 1.24\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00, 11.94batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  5.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 13.79batch/s]total loss: 0.97\n",
      "recon: 0.88\n",
      "reg: 2.09\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00, 10.01batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  5.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8641\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  60%|██████    | 3/5 [00:00<00:00, 14.06batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.15\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 10.53batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  5.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8433\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 16.18batch/s]total loss: 1.01\n",
      "recon: 0.98\n",
      "reg: 0.77\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00, 11.20batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  5.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 17.34batch/s]total loss: 0.34\n",
      "recon: 0.52\n",
      "reg: -4.56\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00,  9.51batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:01,  3.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 14.12batch/s]total loss: 1.08\n",
      "recon: 1.06\n",
      "reg: 0.47\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 10.73batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  6.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9505\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  60%|██████    | 3/5 [00:00<00:00, 17.11batch/s]total loss: 1.03\n",
      "recon: 0.97\n",
      "reg: 1.44\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 12.01batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  6.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9209\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  60%|██████    | 3/5 [00:00<00:00, 20.79batch/s]total loss: 0.71\n",
      "recon: 0.72\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00, 11.30batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  5.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8215\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 15.39batch/s]total loss: 0.61\n",
      "recon: 0.59\n",
      "reg: 0.44\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 10.83batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  5.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.779\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  60%|██████    | 3/5 [00:00<00:00, 20.63batch/s]total loss: 0.64\n",
      "recon: 0.76\n",
      "reg: -2.85\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 11.68batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  5.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7735\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 18.83batch/s]total loss: 0.98\n",
      "recon: 1.03\n",
      "reg: -1.16\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 11.41batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 20.40batch/s]total loss: 0.81\n",
      "recon: 0.78\n",
      "reg: 0.95\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 10.16batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8081\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 19.28batch/s]total loss: 0.88\n",
      "recon: 0.72\n",
      "reg: 3.95\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 10.71batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  4.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8261\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  60%|██████    | 3/5 [00:00<00:00, 20.97batch/s]total loss: 0.86\n",
      "recon: 0.93\n",
      "reg: -1.69\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00, 10.59batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:01,  3.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8217\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 23.49batch/s]total loss: 0.74\n",
      "recon: 0.65\n",
      "reg: 2.22\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 10.52batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:01,  3.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8079\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 19.76batch/s]total loss: 0.30\n",
      "recon: 0.42\n",
      "reg: -2.93\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  9.39batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  3.28batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.714\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  60%|██████    | 3/5 [00:00<00:00, 14.81batch/s]total loss: 0.57\n",
      "recon: 0.56\n",
      "reg: 0.40\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 10.59batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  5.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7736\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 23.39batch/s]total loss: 0.92\n",
      "recon: 0.96\n",
      "reg: -0.93\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 11.34batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8327\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 17.86batch/s]total loss: 0.62\n",
      "recon: 0.68\n",
      "reg: -1.56\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  9.56batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:01,  3.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7675\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 17.22batch/s]total loss: 1.13\n",
      "recon: 1.00\n",
      "reg: 3.27\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00, 12.12batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  6.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8851\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  60%|██████    | 3/5 [00:00<00:00, 14.71batch/s]total loss: 0.75\n",
      "recon: 0.79\n",
      "reg: -0.97\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 10.62batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  5.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7985\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 17.36batch/s]total loss: 1.36\n",
      "recon: 1.28\n",
      "reg: 2.04\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 10.51batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  5.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9811\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 16.03batch/s]total loss: 0.80\n",
      "recon: 0.78\n",
      "reg: 0.62\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 10.93batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  5.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9199\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  60%|██████    | 3/5 [00:00<00:00, 14.09batch/s]total loss: 0.96\n",
      "recon: 0.86\n",
      "reg: 2.54\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00, 10.70batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  5.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9219\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  60%|██████    | 3/5 [00:00<00:00, 13.33batch/s]total loss: 0.86\n",
      "recon: 0.83\n",
      "reg: 0.78\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00, 10.14batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  5.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8767\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 20.02batch/s]total loss: 0.94\n",
      "recon: 1.05\n",
      "reg: -2.69\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 10.93batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  5.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  60%|██████    | 3/5 [00:00<00:00, 13.85batch/s]total loss: 0.60\n",
      "recon: 0.70\n",
      "reg: -2.41\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 10.57batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  5.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7882\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 15.57batch/s]total loss: 0.58\n",
      "recon: 0.57\n",
      "reg: 0.32\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00, 11.06batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  5.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.799\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 13.74batch/s]total loss: 0.73\n",
      "recon: 0.74\n",
      "reg: -0.11\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  9.79batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  5.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8149\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 18.36batch/s]total loss: 0.38\n",
      "recon: 0.38\n",
      "reg: 0.15\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 10.61batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  4.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.753\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 16.46batch/s]total loss: 0.71\n",
      "recon: 0.69\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 11.35batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  5.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.795\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 16.86batch/s]total loss: 0.83\n",
      "recon: 0.84\n",
      "reg: -0.28\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 11.35batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  5.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8184\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  60%|██████    | 3/5 [00:00<00:00, 12.87batch/s]total loss: 1.08\n",
      "recon: 1.03\n",
      "reg: 1.25\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  9.53batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8889\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  60%|██████    | 3/5 [00:00<00:00, 18.40batch/s]total loss: 0.58\n",
      "recon: 0.61\n",
      "reg: -0.67\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 11.98batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  5.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7991\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 19.10batch/s]total loss: 0.37\n",
      "recon: 0.47\n",
      "reg: -2.28\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 10.89batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  5.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7713\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 14.06batch/s]total loss: 0.75\n",
      "recon: 0.62\n",
      "reg: 3.28\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 10.16batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  5.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8041\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  60%|██████    | 3/5 [00:00<00:00, 20.75batch/s]total loss: 0.73\n",
      "recon: 0.75\n",
      "reg: -0.57\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 10.98batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  5.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7942\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 18.79batch/s]total loss: 0.50\n",
      "recon: 0.45\n",
      "reg: 1.35\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00, 10.76batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  60%|██████    | 3/5 [00:00<00:00, 20.57batch/s]total loss: 0.76\n",
      "recon: 0.73\n",
      "reg: 0.81\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00, 12.17batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  5.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 19.31batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.12\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00, 11.38batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  60%|██████    | 3/5 [00:00<00:00, 20.80batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.13\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  9.52batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:01,  3.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8398\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 17.41batch/s]total loss: 0.97\n",
      "recon: 0.86\n",
      "reg: 2.88\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  9.87batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8718\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 23.34batch/s]total loss: 0.64\n",
      "recon: 0.73\n",
      "reg: -2.26\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 11.42batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  60%|██████    | 3/5 [00:00<00:00, 12.48batch/s]total loss: 1.19\n",
      "recon: 1.11\n",
      "reg: 1.96\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  9.22batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9163\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  60%|██████    | 3/5 [00:00<00:00, 21.08batch/s]total loss: 0.93\n",
      "recon: 0.92\n",
      "reg: 0.26\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00, 10.83batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8425\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  60%|██████    | 3/5 [00:00<00:00, 20.65batch/s]total loss: 0.65\n",
      "recon: 0.60\n",
      "reg: 1.23\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  7.61batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.31batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7892\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  60%|██████    | 3/5 [00:00<00:00, 20.46batch/s]total loss: 1.10\n",
      "recon: 1.01\n",
      "reg: 2.28\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00, 10.17batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  5.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8862\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 17.15batch/s]total loss: 0.61\n",
      "recon: 0.58\n",
      "reg: 0.67\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00, 11.16batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  5.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7965\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 17.31batch/s]total loss: 0.78\n",
      "recon: 0.71\n",
      "reg: 1.69\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  9.62batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  4.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00, 21.49batch/s]total loss: 0.71\n",
      "recon: 0.65\n",
      "reg: 1.51\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00, 10.86batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 22.02batch/s]total loss: 0.81\n",
      "recon: 0.86\n",
      "reg: -1.24\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 10.39batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 19.29batch/s]total loss: 1.77\n",
      "recon: 1.65\n",
      "reg: 2.95\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00, 10.85batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 17.31batch/s]total loss: 0.87\n",
      "recon: 0.87\n",
      "reg: 0.02\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00, 10.25batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  4.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8254\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 16.51batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.28\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  9.67batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  4.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8351\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  60%|██████    | 3/5 [00:00<00:00, 20.87batch/s]total loss: 1.59\n",
      "recon: 1.55\n",
      "reg: 1.00\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 10.67batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:01,  3.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9762\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 19.31batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.61\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00, 10.32batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:01,  3.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8294\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_21-09-29/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.255701720901, Time: 110.75s\n",
      "Epoch 200, Training Loss: 0.131409470923, Time: 219.65s\n",
      "Epoch 300, Training Loss: 0.067633039749, Time: 332.16s\n",
      "Epoch 400, Training Loss: 0.039594843505, Time: 441.86s\n",
      "Epoch 500, Training Loss: 0.012818424488, Time: 549.97s\n",
      "Epoch 600, Training Loss: 0.007906403818, Time: 661.36s\n",
      "Epoch 700, Training Loss: 0.006631630821, Time: 772.64s\n",
      "Epoch 800, Training Loss: 0.003244960273, Time: 881.65s\n",
      "Epoch 900, Training Loss: 0.002754969009, Time: 990.69s\n",
      "Epoch 1000, Training Loss: 0.002386060804, Time: 1098.16s\n",
      "Validation Loss: 0.070456305779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.07046</td></tr><tr><td>val_loss</td><td>0.07046</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">playful-sweep-15</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/wknlqu0u' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/wknlqu0u</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250325_210928-wknlqu0u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pk640b0f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008579169973617123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250325_212857-pk640b0f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/pk640b0f' target=\"_blank\">dark-sweep-16</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/pk640b0f' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/pk640b0f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_21-28-58. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 15.32batch/s]total loss: 3.52\n",
      "recon: 3.39\n",
      "reg: 3.22\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  9.18batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:01,  3.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.113\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 15.91batch/s]total loss: 1.41\n",
      "recon: 1.43\n",
      "reg: -0.39\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00,  8.97batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:01,  3.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.7152\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  60%|██████    | 3/5 [00:00<00:00, 11.28batch/s]total loss: 1.46\n",
      "recon: 1.47\n",
      "reg: -0.20\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  9.13batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.4075\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 16.14batch/s]total loss: 0.78\n",
      "recon: 0.80\n",
      "reg: -0.54\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 10.35batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.136\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 19.14batch/s]total loss: 0.92\n",
      "recon: 0.93\n",
      "reg: -0.17\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00, 10.69batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  4.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.1085\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 16.25batch/s]total loss: 0.87\n",
      "recon: 0.76\n",
      "reg: 2.82\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 10.24batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9488\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 17.99batch/s]total loss: 0.59\n",
      "recon: 0.64\n",
      "reg: -1.16\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 10.25batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  4.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 17.94batch/s]total loss: 0.66\n",
      "recon: 0.68\n",
      "reg: -0.56\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 11.06batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 16.72batch/s]total loss: 1.02\n",
      "recon: 0.87\n",
      "reg: 3.73\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  9.66batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  5.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8897\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 11.84batch/s]total loss: 0.64\n",
      "recon: 0.55\n",
      "reg: 2.41\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  8.92batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  5.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8002\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 15.81batch/s]total loss: 0.88\n",
      "recon: 0.74\n",
      "reg: 3.43\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 10.38batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8524\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 15.98batch/s]total loss: 0.79\n",
      "recon: 0.73\n",
      "reg: 1.45\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  9.71batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9133\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 13.26batch/s]total loss: 0.97\n",
      "recon: 0.95\n",
      "reg: 0.65\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00,  8.25batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:01,  3.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 17.22batch/s]total loss: 0.62\n",
      "recon: 0.60\n",
      "reg: 0.54\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00,  8.36batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:01,  3.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8548\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00, 11.80batch/s]total loss: 0.69\n",
      "recon: 0.71\n",
      "reg: -0.62\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  7.65batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  4.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8112\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 17.55batch/s]total loss: 0.90\n",
      "recon: 0.96\n",
      "reg: -1.63\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00,  9.07batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8893\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 18.66batch/s]total loss: 0.85\n",
      "recon: 0.80\n",
      "reg: 1.14\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00,  8.75batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:01,  2.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8653\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00, 14.85batch/s]total loss: 0.74\n",
      "recon: 0.62\n",
      "reg: 2.75\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00,  9.45batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  4.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8074\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 18.44batch/s]total loss: 0.36\n",
      "recon: 0.47\n",
      "reg: -2.62\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 10.69batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7452\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 19.29batch/s]total loss: 0.96\n",
      "recon: 1.00\n",
      "reg: -1.08\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 11.51batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.86\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 18.57batch/s]total loss: 1.20\n",
      "recon: 1.17\n",
      "reg: 0.90\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 10.12batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9011\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 16.95batch/s]total loss: 0.50\n",
      "recon: 0.61\n",
      "reg: -2.59\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 10.85batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  4.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7565\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 17.93batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.48\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00, 11.05batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  4.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8462\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 18.11batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.40\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 10.18batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.894\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 16.78batch/s]total loss: 0.85\n",
      "recon: 0.79\n",
      "reg: 1.35\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 10.83batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  5.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8311\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 15.95batch/s]total loss: 1.19\n",
      "recon: 1.06\n",
      "reg: 3.29\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 10.55batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  4.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8946\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 17.35batch/s]total loss: 0.90\n",
      "recon: 0.74\n",
      "reg: 4.08\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00,  9.37batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:01,  3.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 16.87batch/s]total loss: 0.70\n",
      "recon: 0.66\n",
      "reg: 1.00\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  9.37batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  4.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.864\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 18.81batch/s]total loss: 0.93\n",
      "recon: 0.91\n",
      "reg: 0.55\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 11.24batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8697\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:00<00:00, 17.18batch/s]total loss: 0.62\n",
      "recon: 0.55\n",
      "reg: 1.61\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  7.75batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  2.60batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7933\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 17.36batch/s]total loss: 0.85\n",
      "recon: 0.89\n",
      "reg: -0.90\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 10.45batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8734\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 10.66batch/s]total loss: 0.93\n",
      "recon: 0.95\n",
      "reg: -0.59\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  8.21batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9791\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 18.30batch/s]total loss: 0.68\n",
      "recon: 0.70\n",
      "reg: -0.66\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  8.96batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  5.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8666\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 16.02batch/s]total loss: 0.86\n",
      "recon: 0.90\n",
      "reg: -0.86\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  9.61batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  4.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8538\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 15.43batch/s]total loss: 1.25\n",
      "recon: 1.21\n",
      "reg: 1.00\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00, 10.32batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9208\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 17.09batch/s]total loss: 0.55\n",
      "recon: 0.63\n",
      "reg: -1.82\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  9.26batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  4.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7856\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 16.35batch/s]total loss: 0.66\n",
      "recon: 0.71\n",
      "reg: -1.30\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 10.16batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  4.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.81\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 15.62batch/s]total loss: 0.75\n",
      "recon: 0.69\n",
      "reg: 1.47\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00,  9.85batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8649\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 13.23batch/s]total loss: 0.86\n",
      "recon: 0.78\n",
      "reg: 1.90\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  8.86batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:01,  3.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8641\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 18.50batch/s]total loss: 1.33\n",
      "recon: 1.26\n",
      "reg: 1.57\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 10.15batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  4.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9361\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 18.18batch/s]total loss: 1.17\n",
      "recon: 1.01\n",
      "reg: 4.03\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00,  8.23batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:01,  2.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9425\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 15.62batch/s]total loss: 1.31\n",
      "recon: 1.33\n",
      "reg: -0.67\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  8.88batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:01,  3.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.946\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 19.26batch/s]total loss: 0.94\n",
      "recon: 0.93\n",
      "reg: 0.32\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 10.14batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:01,  3.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8463\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 18.28batch/s]total loss: 0.85\n",
      "recon: 0.86\n",
      "reg: -0.18\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 10.35batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  4.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8288\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 17.43batch/s]total loss: 0.98\n",
      "recon: 0.93\n",
      "reg: 1.41\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  8.16batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:01,  2.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9344\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 16.58batch/s]total loss: 1.01\n",
      "recon: 0.91\n",
      "reg: 2.51\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00,  9.25batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:01,  3.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8881\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 17.37batch/s]total loss: 0.94\n",
      "recon: 0.95\n",
      "reg: -0.25\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 11.12batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  5.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8579\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  60%|██████    | 3/5 [00:00<00:00, 13.01batch/s]total loss: 1.01\n",
      "recon: 0.98\n",
      "reg: 0.76\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  9.34batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8695\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 14.49batch/s]total loss: 0.32\n",
      "recon: 0.53\n",
      "reg: -5.03\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00,  9.63batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  4.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7364\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 17.03batch/s]total loss: 1.04\n",
      "recon: 1.04\n",
      "reg: -0.04\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00,  9.62batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:01,  3.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9178\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 18.77batch/s]total loss: 0.97\n",
      "recon: 0.91\n",
      "reg: 1.45\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 11.41batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8954\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 16.01batch/s]total loss: 0.76\n",
      "recon: 0.76\n",
      "reg: -0.08\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00, 10.76batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  5.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8197\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 17.06batch/s]total loss: 0.57\n",
      "recon: 0.57\n",
      "reg: -0.05\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00,  9.46batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:01,  3.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7725\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 18.48batch/s]total loss: 0.68\n",
      "recon: 0.79\n",
      "reg: -2.69\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 11.22batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 17.23batch/s]total loss: 0.97\n",
      "recon: 1.02\n",
      "reg: -1.22\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  7.39batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:01,  2.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8524\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  60%|██████    | 3/5 [00:00<00:00, 14.63batch/s]total loss: 0.82\n",
      "recon: 0.79\n",
      "reg: 0.88\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00,  9.96batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8182\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 16.94batch/s]total loss: 0.87\n",
      "recon: 0.71\n",
      "reg: 4.06\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 10.37batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 16.69batch/s]total loss: 0.88\n",
      "recon: 0.93\n",
      "reg: -1.26\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00, 10.72batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8345\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  60%|██████    | 3/5 [00:00<00:00, 14.74batch/s]total loss: 0.74\n",
      "recon: 0.65\n",
      "reg: 2.15\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00,  9.75batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  4.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8068\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 18.68batch/s]total loss: 0.28\n",
      "recon: 0.40\n",
      "reg: -3.05\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  8.36batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  2.90batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7045\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 16.18batch/s]total loss: 0.60\n",
      "recon: 0.57\n",
      "reg: 0.92\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  9.66batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7759\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 18.12batch/s]total loss: 0.89\n",
      "recon: 0.94\n",
      "reg: -1.21\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 10.68batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  4.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8237\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 17.38batch/s]total loss: 0.64\n",
      "recon: 0.71\n",
      "reg: -1.91\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00, 10.23batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  4.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7629\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  60%|██████    | 3/5 [00:00<00:00, 14.79batch/s]total loss: 1.16\n",
      "recon: 1.03\n",
      "reg: 3.11\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  9.04batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  4.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9071\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 17.20batch/s]total loss: 0.76\n",
      "recon: 0.81\n",
      "reg: -1.21\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 10.41batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  4.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8143\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 18.20batch/s]total loss: 1.42\n",
      "recon: 1.32\n",
      "reg: 2.45\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 10.05batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:01,  3.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0071\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 17.47batch/s]total loss: 0.76\n",
      "recon: 0.73\n",
      "reg: 0.84\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 10.91batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8655\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 17.67batch/s]total loss: 0.90\n",
      "recon: 0.81\n",
      "reg: 2.14\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00, 10.31batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  4.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8864\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 15.67batch/s]total loss: 0.83\n",
      "recon: 0.81\n",
      "reg: 0.56\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  9.33batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:01,  3.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8605\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 18.13batch/s]total loss: 0.94\n",
      "recon: 1.05\n",
      "reg: -2.88\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 11.17batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8438\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 16.83batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.70\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 10.57batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  4.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  60%|██████    | 3/5 [00:00<00:00, 12.21batch/s]total loss: 0.60\n",
      "recon: 0.59\n",
      "reg: 0.06\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  9.43batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  5.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.817\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 14.94batch/s]total loss: 0.75\n",
      "recon: 0.77\n",
      "reg: -0.52\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00, 10.17batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  4.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8247\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 17.39batch/s]total loss: 0.39\n",
      "recon: 0.37\n",
      "reg: 0.49\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00,  9.25batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:01,  3.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7559\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 16.77batch/s]total loss: 0.72\n",
      "recon: 0.70\n",
      "reg: 0.44\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 10.65batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  5.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8028\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 16.62batch/s]total loss: 0.87\n",
      "recon: 0.87\n",
      "reg: -0.10\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 10.77batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  4.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8308\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  80%|████████  | 4/5 [00:00<00:00, 10.66batch/s]total loss: 1.08\n",
      "recon: 1.03\n",
      "reg: 1.17\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  8.08batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  4.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8978\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 17.85batch/s]total loss: 0.63\n",
      "recon: 0.66\n",
      "reg: -0.76\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 10.82batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  4.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8253\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 17.45batch/s]total loss: 0.32\n",
      "recon: 0.41\n",
      "reg: -2.23\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00,  8.33batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:01,  2.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7626\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  60%|██████    | 3/5 [00:00<00:00, 14.11batch/s]total loss: 0.76\n",
      "recon: 0.62\n",
      "reg: 3.38\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  9.80batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  4.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 14.90batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.73\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 10.30batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  5.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 12.14batch/s]total loss: 0.52\n",
      "recon: 0.47\n",
      "reg: 1.19\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  8.53batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7594\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 17.65batch/s]total loss: 0.76\n",
      "recon: 0.73\n",
      "reg: 0.72\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00, 10.42batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  4.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.805\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 17.00batch/s]total loss: 0.91\n",
      "recon: 0.91\n",
      "reg: 0.04\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00, 10.18batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  4.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  60%|██████    | 3/5 [00:00<00:00, 14.56batch/s]total loss: 0.95\n",
      "recon: 0.86\n",
      "reg: 2.38\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 10.04batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  5.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8402\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 15.53batch/s]total loss: 0.94\n",
      "recon: 0.83\n",
      "reg: 2.70\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 10.44batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  5.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8615\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 17.44batch/s]total loss: 0.68\n",
      "recon: 0.77\n",
      "reg: -2.15\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  9.96batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8091\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 15.24batch/s]total loss: 1.15\n",
      "recon: 1.08\n",
      "reg: 1.87\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  9.92batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8877\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 18.08batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.05\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00, 10.97batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8304\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 13.22batch/s]total loss: 0.66\n",
      "recon: 0.62\n",
      "reg: 1.01\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  7.78batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  3.11batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7778\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 16.19batch/s]total loss: 1.08\n",
      "recon: 1.00\n",
      "reg: 2.07\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  9.78batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  4.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 18.71batch/s]total loss: 0.61\n",
      "recon: 0.59\n",
      "reg: 0.53\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  9.63batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:01,  3.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7918\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 16.03batch/s]total loss: 0.77\n",
      "recon: 0.69\n",
      "reg: 2.16\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00, 10.04batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  4.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8414\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 16.33batch/s]total loss: 0.71\n",
      "recon: 0.65\n",
      "reg: 1.38\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00, 10.22batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7946\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 13.17batch/s]total loss: 0.79\n",
      "recon: 0.84\n",
      "reg: -1.06\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  9.37batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 16.19batch/s]total loss: 1.73\n",
      "recon: 1.60\n",
      "reg: 3.08\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00, 10.77batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  5.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0039\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 17.89batch/s]total loss: 0.89\n",
      "recon: 0.90\n",
      "reg: -0.08\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  9.89batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:01,  3.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8473\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  60%|██████    | 3/5 [00:00<00:00, 13.70batch/s]total loss: 0.88\n",
      "recon: 0.79\n",
      "reg: 2.39\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  9.35batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  4.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8479\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 16.47batch/s]total loss: 1.65\n",
      "recon: 1.60\n",
      "reg: 1.22\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 10.45batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.001\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 16.96batch/s]total loss: 0.63\n",
      "recon: 0.61\n",
      "reg: 0.49\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00, 10.00batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  4.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8166\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_21-28-58/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.218730259943, Time: 111.61s\n",
      "Epoch 200, Training Loss: 0.070926699968, Time: 224.79s\n",
      "Epoch 300, Training Loss: 0.036841147431, Time: 334.52s\n",
      "Epoch 400, Training Loss: 0.031677664848, Time: 447.98s\n",
      "Epoch 500, Training Loss: 0.023271050683, Time: 563.51s\n",
      "Epoch 600, Training Loss: 0.023218240566, Time: 672.41s\n",
      "Epoch 700, Training Loss: 0.020471376009, Time: 787.47s\n",
      "Epoch 800, Training Loss: 0.018500855133, Time: 904.21s\n",
      "Epoch 900, Training Loss: 0.017616800221, Time: 1012.49s\n",
      "Epoch 1000, Training Loss: 0.017212281970, Time: 1120.15s\n",
      "Validation Loss: 0.016211510928\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.01621</td></tr><tr><td>val_loss</td><td>0.01621</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dark-sweep-16</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/pk640b0f' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/pk640b0f</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250325_212857-pk640b0f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k1jnbjzc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0015635818665397595\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250325_214854-k1jnbjzc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/k1jnbjzc' target=\"_blank\">colorful-sweep-17</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/k1jnbjzc' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/k1jnbjzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_21-48-55. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 15.33batch/s]total loss: 4.54\n",
      "recon: 4.25\n",
      "reg: 7.01\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  8.08batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:01,  3.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.4454\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 15.51batch/s]total loss: 1.09\n",
      "recon: 1.05\n",
      "reg: 1.10\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00,  9.97batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  4.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.5912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 12.98batch/s]total loss: 1.23\n",
      "recon: 1.27\n",
      "reg: -1.13\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  8.99batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  4.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2307\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 15.60batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.76\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00,  9.20batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:01,  3.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 15.57batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.45\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00, 10.38batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  4.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9394\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 16.20batch/s]total loss: 0.81\n",
      "recon: 0.71\n",
      "reg: 2.51\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00,  8.94batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:01,  3.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 11.26batch/s]total loss: 0.67\n",
      "recon: 0.70\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00,  5.92batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:01,  3.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 16.89batch/s]total loss: 0.71\n",
      "recon: 0.71\n",
      "reg: -0.09\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00,  7.11batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:01,  2.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 15.58batch/s]total loss: 1.02\n",
      "recon: 0.89\n",
      "reg: 3.25\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  9.25batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:01,  3.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9044\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 15.62batch/s]total loss: 0.65\n",
      "recon: 0.57\n",
      "reg: 2.05\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  9.73batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  4.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 16.50batch/s]total loss: 1.09\n",
      "recon: 0.94\n",
      "reg: 3.71\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 10.60batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9274\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00,  7.89batch/s]total loss: 0.93\n",
      "recon: 0.85\n",
      "reg: 1.84\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  6.64batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:01,  3.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00,  8.37batch/s]total loss: 1.01\n",
      "recon: 0.97\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00,  6.22batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  4.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 15.74batch/s]total loss: 0.65\n",
      "recon: 0.65\n",
      "reg: -0.11\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 10.16batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 15.01batch/s]total loss: 0.75\n",
      "recon: 0.75\n",
      "reg: 0.04\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  9.93batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8417\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 15.60batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.13\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00,  9.55batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 15.99batch/s]total loss: 0.85\n",
      "recon: 0.76\n",
      "reg: 2.07\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00, 10.03batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  4.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00, 15.38batch/s]total loss: 0.74\n",
      "recon: 0.63\n",
      "reg: 2.86\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00, 10.05batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8258\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 16.85batch/s]total loss: 0.37\n",
      "recon: 0.48\n",
      "reg: -2.77\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00,  9.51batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:01,  3.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 15.25batch/s]total loss: 1.04\n",
      "recon: 1.06\n",
      "reg: -0.72\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 10.48batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8823\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 15.65batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.33\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 10.26batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9097\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 11.57batch/s]total loss: 0.53\n",
      "recon: 0.63\n",
      "reg: -2.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00,  8.39batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  4.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7636\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 12.34batch/s]total loss: 0.93\n",
      "recon: 0.91\n",
      "reg: 0.48\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  8.37batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  4.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8492\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 15.36batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.33\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 10.24batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 16.23batch/s]total loss: 0.86\n",
      "recon: 0.82\n",
      "reg: 1.08\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 10.44batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8431\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  60%|██████    | 3/5 [00:00<00:00, 13.79batch/s]total loss: 1.19\n",
      "recon: 1.07\n",
      "reg: 3.22\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00,  9.58batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  4.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9047\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 15.90batch/s]total loss: 0.98\n",
      "recon: 0.80\n",
      "reg: 4.48\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 10.09batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 12.28batch/s]total loss: 0.76\n",
      "recon: 0.70\n",
      "reg: 1.32\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  8.79batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  4.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8853\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 16.76batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.90\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00,  9.67batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  4.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:00<00:00, 12.10batch/s]total loss: 0.65\n",
      "recon: 0.58\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  7.47batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  3.15batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 11.44batch/s]total loss: 1.03\n",
      "recon: 1.05\n",
      "reg: -0.60\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00,  8.85batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9293\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 13.33batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.74\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  9.07batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 15.88batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.58\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00, 10.37batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8369\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 15.90batch/s]total loss: 0.66\n",
      "recon: 0.70\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  9.67batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  4.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  60%|██████    | 3/5 [00:00<00:00,  7.80batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.13\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  7.34batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  4.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9186\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 16.38batch/s]total loss: 0.56\n",
      "recon: 0.63\n",
      "reg: -1.68\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00, 10.09batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  4.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 15.47batch/s]total loss: 0.71\n",
      "recon: 0.75\n",
      "reg: -0.86\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 10.21batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  4.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8243\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 15.68batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.79\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 10.43batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  5.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8526\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 14.56batch/s]total loss: 0.87\n",
      "recon: 0.81\n",
      "reg: 1.67\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  9.53batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  4.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8549\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 11.03batch/s]total loss: 1.35\n",
      "recon: 1.29\n",
      "reg: 1.42\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00,  8.40batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  4.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 16.63batch/s]total loss: 1.17\n",
      "recon: 1.03\n",
      "reg: 3.66\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 10.50batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  4.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.96\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 15.17batch/s]total loss: 1.27\n",
      "recon: 1.29\n",
      "reg: -0.54\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  9.82batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  4.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 16.07batch/s]total loss: 0.97\n",
      "recon: 0.96\n",
      "reg: 0.04\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00,  8.63batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  4.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8667\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00,  7.70batch/s]total loss: 0.88\n",
      "recon: 0.86\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00,  6.95batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 16.13batch/s]total loss: 0.92\n",
      "recon: 0.87\n",
      "reg: 1.15\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00, 10.75batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  5.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 10.36batch/s]total loss: 0.92\n",
      "recon: 0.84\n",
      "reg: 2.00\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00,  7.93batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  5.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 14.74batch/s]total loss: 0.92\n",
      "recon: 0.94\n",
      "reg: -0.45\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  9.26batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  4.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 10.28batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.89\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  6.52batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:01,  2.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 15.85batch/s]total loss: 0.34\n",
      "recon: 0.53\n",
      "reg: -4.81\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00,  8.86batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:01,  3.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7391\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 15.96batch/s]total loss: 1.03\n",
      "recon: 1.02\n",
      "reg: 0.36\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 10.50batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  5.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 11.44batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.50\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00,  8.26batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  4.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 16.12batch/s]total loss: 0.78\n",
      "recon: 0.78\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  9.22batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:01,  3.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 12.88batch/s]total loss: 0.60\n",
      "recon: 0.58\n",
      "reg: 0.51\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00,  6.91batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:01,  3.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7782\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 13.19batch/s]total loss: 0.69\n",
      "recon: 0.80\n",
      "reg: -2.77\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00,  8.90batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  4.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 15.66batch/s]total loss: 1.01\n",
      "recon: 1.06\n",
      "reg: -1.18\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  9.42batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 15.28batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.50\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00,  9.80batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 16.01batch/s]total loss: 0.86\n",
      "recon: 0.70\n",
      "reg: 3.93\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 10.45batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  5.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8203\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 15.89batch/s]total loss: 0.88\n",
      "recon: 0.95\n",
      "reg: -1.75\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  9.29batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:01,  3.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 15.35batch/s]total loss: 0.70\n",
      "recon: 0.62\n",
      "reg: 1.82\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 10.26batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  5.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.794\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 16.56batch/s]total loss: 0.26\n",
      "recon: 0.40\n",
      "reg: -3.61\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  8.26batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  3.01batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.6987\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 16.03batch/s]total loss: 0.59\n",
      "recon: 0.57\n",
      "reg: 0.43\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  9.98batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7719\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 15.57batch/s]total loss: 0.96\n",
      "recon: 0.99\n",
      "reg: -0.90\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00,  9.82batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  4.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8422\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 15.83batch/s]total loss: 0.66\n",
      "recon: 0.73\n",
      "reg: -1.79\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  8.15batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:01,  3.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 15.13batch/s]total loss: 1.19\n",
      "recon: 1.06\n",
      "reg: 3.29\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  9.86batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  4.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9232\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 16.08batch/s]total loss: 0.77\n",
      "recon: 0.81\n",
      "reg: -0.83\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00,  9.88batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8216\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  60%|██████    | 3/5 [00:00<00:00, 13.28batch/s]total loss: 1.34\n",
      "recon: 1.26\n",
      "reg: 1.98\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00,  8.67batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  4.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 15.93batch/s]total loss: 0.73\n",
      "recon: 0.70\n",
      "reg: 0.57\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 10.32batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  4.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 14.08batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.27\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  9.39batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  4.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8691\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  60%|██████    | 3/5 [00:00<00:00, 11.64batch/s]total loss: 0.82\n",
      "recon: 0.81\n",
      "reg: 0.11\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  8.88batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8416\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 16.47batch/s]total loss: 0.98\n",
      "recon: 1.08\n",
      "reg: -2.70\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 10.44batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8468\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 16.44batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.86\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00,  9.87batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  4.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.79\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 16.06batch/s]total loss: 0.56\n",
      "recon: 0.57\n",
      "reg: -0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00, 10.63batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  5.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 14.45batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.67\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00, 10.12batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  5.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8143\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 15.97batch/s]total loss: 0.39\n",
      "recon: 0.38\n",
      "reg: 0.29\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00,  9.19batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  4.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7498\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 16.28batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 10.31batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7909\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 16.15batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.07\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 10.26batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.83\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  60%|██████    | 3/5 [00:00<00:00, 14.08batch/s]total loss: 1.07\n",
      "recon: 1.02\n",
      "reg: 1.30\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  9.78batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 15.01batch/s]total loss: 0.61\n",
      "recon: 0.64\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00,  9.55batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  4.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 16.95batch/s]total loss: 0.31\n",
      "recon: 0.40\n",
      "reg: -2.21\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00,  9.94batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  4.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 13.10batch/s]total loss: 0.79\n",
      "recon: 0.64\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  9.59batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  5.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8183\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 16.09batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.51\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 10.53batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 16.13batch/s]total loss: 0.51\n",
      "recon: 0.46\n",
      "reg: 1.29\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  9.87batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 14.69batch/s]total loss: 0.76\n",
      "recon: 0.72\n",
      "reg: 0.88\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  9.99batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8033\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 15.69batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.35\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  9.83batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  4.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8392\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 15.93batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.35\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 10.49batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  5.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8333\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 14.73batch/s]total loss: 0.94\n",
      "recon: 0.82\n",
      "reg: 2.90\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  8.77batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:01,  3.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 17.78batch/s]total loss: 0.71\n",
      "recon: 0.78\n",
      "reg: -1.62\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 10.19batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 13.63batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.77\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  8.79batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8986\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  60%|██████    | 3/5 [00:00<00:00, 11.85batch/s]total loss: 0.91\n",
      "recon: 0.92\n",
      "reg: -0.23\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  8.47batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8309\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 16.87batch/s]total loss: 0.65\n",
      "recon: 0.61\n",
      "reg: 0.89\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  7.34batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.46batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  60%|██████    | 3/5 [00:00<00:00, 14.00batch/s]total loss: 1.08\n",
      "recon: 0.99\n",
      "reg: 2.14\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  4.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8833\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 16.68batch/s]total loss: 0.63\n",
      "recon: 0.60\n",
      "reg: 0.78\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00, 10.11batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  4.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7938\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 15.89batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.84\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  7.70batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:01,  3.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 14.01batch/s]total loss: 0.70\n",
      "recon: 0.63\n",
      "reg: 1.61\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  9.87batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 15.53batch/s]total loss: 0.78\n",
      "recon: 0.83\n",
      "reg: -1.19\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 10.42batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  5.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8094\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  60%|██████    | 3/5 [00:00<00:00, 13.93batch/s]total loss: 1.65\n",
      "recon: 1.55\n",
      "reg: 2.45\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  9.84batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  5.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9859\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 16.61batch/s]total loss: 0.91\n",
      "recon: 0.89\n",
      "reg: 0.35\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00, 10.13batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  4.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 15.31batch/s]total loss: 0.92\n",
      "recon: 0.82\n",
      "reg: 2.52\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  9.35batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8423\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 16.69batch/s]total loss: 1.58\n",
      "recon: 1.54\n",
      "reg: 0.99\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 10.67batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 10.71batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.73\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  8.70batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  5.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8236\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_21-48-55/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.114875004534, Time: 107.52s\n",
      "Epoch 200, Training Loss: 0.041040038015, Time: 209.40s\n",
      "Epoch 300, Training Loss: 0.014057180213, Time: 308.67s\n",
      "Epoch 400, Training Loss: 0.009489276013, Time: 409.16s\n",
      "Epoch 500, Training Loss: 0.005714449228, Time: 520.95s\n",
      "Epoch 600, Training Loss: 0.003244221902, Time: 630.24s\n",
      "Epoch 700, Training Loss: 0.001277019807, Time: 743.24s\n",
      "Epoch 800, Training Loss: 0.000573103592, Time: 850.67s\n",
      "Epoch 900, Training Loss: 0.000360323455, Time: 964.99s\n",
      "Epoch 1000, Training Loss: 0.000390910856, Time: 1134.79s\n",
      "Validation Loss: 0.000205482999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00021</td></tr><tr><td>val_loss</td><td>0.00021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">colorful-sweep-17</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/k1jnbjzc' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/k1jnbjzc</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250325_214854-k1jnbjzc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mvefn1or with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009861641305841534\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250325_220906-mvefn1or</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/mvefn1or' target=\"_blank\">cosmic-sweep-18</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/mvefn1or' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/mvefn1or</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_22-09-07. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 16.48batch/s]total loss: 4.54\n",
      "recon: 4.25\n",
      "reg: 7.01\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  8.86batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:01,  3.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.4454\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 16.31batch/s]total loss: 1.09\n",
      "recon: 1.05\n",
      "reg: 1.10\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00,  8.54batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:01,  3.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.5912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00,  7.82batch/s]total loss: 1.23\n",
      "recon: 1.27\n",
      "reg: -1.13\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  6.09batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:01,  3.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2307\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00,  6.41batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.76\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00,  5.36batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:01,  3.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00, 12.81batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.45\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  6.60batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:01,  3.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9394\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 13.50batch/s]total loss: 0.81\n",
      "recon: 0.71\n",
      "reg: 2.51\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00,  7.79batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:01,  3.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00,  5.10batch/s]total loss: 0.67\n",
      "recon: 0.70\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:01<00:00,  4.35batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:01,  2.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 15.03batch/s]total loss: 0.71\n",
      "recon: 0.71\n",
      "reg: -0.09\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00,  9.78batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  4.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 10.41batch/s]total loss: 1.02\n",
      "recon: 0.89\n",
      "reg: 3.25\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  6.09batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:01,  2.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9044\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  6.65batch/s]total loss: 0.65\n",
      "recon: 0.57\n",
      "reg: 2.05\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:01<00:00,  4.57batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:01,  2.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 11.15batch/s]total loss: 1.09\n",
      "recon: 0.94\n",
      "reg: 3.71\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00,  6.15batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:01,  3.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9274\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00,  7.10batch/s]total loss: 0.93\n",
      "recon: 0.85\n",
      "reg: 1.84\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  5.43batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:01,  2.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00,  6.58batch/s]total loss: 1.01\n",
      "recon: 0.97\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:01<00:00,  4.77batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:01,  2.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 16.64batch/s]total loss: 0.65\n",
      "recon: 0.65\n",
      "reg: -0.11\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00,  8.91batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:01,  3.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  7.25batch/s]total loss: 0.75\n",
      "recon: 0.75\n",
      "reg: 0.04\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  5.10batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:01,  2.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8417\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00,  6.37batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.13\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00,  5.30batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:01,  2.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 15.20batch/s]total loss: 0.85\n",
      "recon: 0.76\n",
      "reg: 2.07\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00,  9.67batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  4.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  60%|██████    | 3/5 [00:00<00:00, 13.91batch/s]total loss: 0.74\n",
      "recon: 0.63\n",
      "reg: 2.86\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00,  7.78batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:01,  3.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8258\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 14.54batch/s]total loss: 0.37\n",
      "recon: 0.48\n",
      "reg: -2.77\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00,  9.54batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  4.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 10.41batch/s]total loss: 1.04\n",
      "recon: 1.06\n",
      "reg: -0.72\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00,  8.55batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8823\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 14.98batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.33\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00,  9.09batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:01,  3.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9097\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 14.46batch/s]total loss: 0.53\n",
      "recon: 0.63\n",
      "reg: -2.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 10.04batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  5.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7636\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 14.78batch/s]total loss: 0.93\n",
      "recon: 0.91\n",
      "reg: 0.48\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  8.83batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:01,  3.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8492\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  60%|██████    | 3/5 [00:00<00:00, 12.69batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.33\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00,  9.06batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 13.89batch/s]total loss: 0.86\n",
      "recon: 0.82\n",
      "reg: 1.08\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00,  9.63batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8431\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 12.92batch/s]total loss: 1.19\n",
      "recon: 1.07\n",
      "reg: 3.22\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00,  9.19batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9047\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 15.47batch/s]total loss: 0.98\n",
      "recon: 0.80\n",
      "reg: 4.48\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00,  6.56batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:01,  2.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 10.07batch/s]total loss: 0.76\n",
      "recon: 0.70\n",
      "reg: 1.32\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  7.48batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  4.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8853\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 14.04batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.90\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00,  9.16batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  4.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:01<00:00,  3.51batch/s]total loss: 0.65\n",
      "recon: 0.58\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:01<00:00,  3.51batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  2.58batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 16.04batch/s]total loss: 1.03\n",
      "recon: 1.05\n",
      "reg: -0.60\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00,  9.38batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:01,  3.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9293\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 13.87batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.74\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  6.71batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:01,  2.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 14.74batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.58\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  8.28batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:01,  3.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8369\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 16.45batch/s]total loss: 0.66\n",
      "recon: 0.70\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  9.42batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:01,  3.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  60%|██████    | 3/5 [00:00<00:00, 14.02batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.13\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  9.55batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9186\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00, 10.76batch/s]total loss: 0.56\n",
      "recon: 0.63\n",
      "reg: -1.68\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  5.75batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:01,  3.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 16.23batch/s]total loss: 0.71\n",
      "recon: 0.75\n",
      "reg: -0.86\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 10.49batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  4.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8243\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 15.23batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.79\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00,  9.92batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  4.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8526\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  60%|██████    | 3/5 [00:00<00:00, 12.76batch/s]total loss: 0.87\n",
      "recon: 0.81\n",
      "reg: 1.67\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  9.17batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  4.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8549\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 15.23batch/s]total loss: 1.35\n",
      "recon: 1.29\n",
      "reg: 1.42\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00,  9.65batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 14.82batch/s]total loss: 1.17\n",
      "recon: 1.03\n",
      "reg: 3.66\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00,  9.98batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  4.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.96\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  60%|██████    | 3/5 [00:00<00:00, 13.37batch/s]total loss: 1.27\n",
      "recon: 1.29\n",
      "reg: -0.54\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  9.28batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  4.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 15.38batch/s]total loss: 0.97\n",
      "recon: 0.96\n",
      "reg: 0.04\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  4.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8667\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 16.32batch/s]total loss: 0.88\n",
      "recon: 0.86\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 10.35batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  4.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 14.28batch/s]total loss: 0.92\n",
      "recon: 0.87\n",
      "reg: 1.15\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  4.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 14.80batch/s]total loss: 0.92\n",
      "recon: 0.84\n",
      "reg: 2.00\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00,  9.42batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  4.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 16.46batch/s]total loss: 0.92\n",
      "recon: 0.94\n",
      "reg: -0.45\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  9.30batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:01,  3.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 16.04batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.89\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00, 10.21batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 16.50batch/s]total loss: 0.34\n",
      "recon: 0.53\n",
      "reg: -4.81\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 10.43batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7391\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 14.87batch/s]total loss: 1.03\n",
      "recon: 1.02\n",
      "reg: 0.36\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00,  8.67batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:01,  3.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 16.79batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.50\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 10.23batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  4.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 12.78batch/s]total loss: 0.78\n",
      "recon: 0.78\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  9.18batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  60%|██████    | 3/5 [00:00<00:00,  6.00batch/s]total loss: 0.60\n",
      "recon: 0.58\n",
      "reg: 0.51\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00,  6.49batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  5.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7782\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 15.14batch/s]total loss: 0.69\n",
      "recon: 0.80\n",
      "reg: -2.77\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00,  9.45batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  4.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 15.31batch/s]total loss: 1.01\n",
      "recon: 1.06\n",
      "reg: -1.18\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  9.89batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  4.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  60%|██████    | 3/5 [00:00<00:00, 13.01batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.50\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00,  9.21batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 16.07batch/s]total loss: 0.86\n",
      "recon: 0.70\n",
      "reg: 3.93\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 10.38batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  4.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8203\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 16.47batch/s]total loss: 0.88\n",
      "recon: 0.95\n",
      "reg: -1.75\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  9.45batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:01,  3.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 16.20batch/s]total loss: 0.70\n",
      "recon: 0.62\n",
      "reg: 1.82\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 10.21batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  4.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.794\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 16.61batch/s]total loss: 0.26\n",
      "recon: 0.40\n",
      "reg: -3.61\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  8.26batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  2.96batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.6987\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  60%|██████    | 3/5 [00:00<00:00, 13.41batch/s]total loss: 0.59\n",
      "recon: 0.57\n",
      "reg: 0.43\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  8.83batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7719\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 17.12batch/s]total loss: 0.96\n",
      "recon: 0.99\n",
      "reg: -0.90\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 10.30batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  4.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8422\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 15.78batch/s]total loss: 0.66\n",
      "recon: 0.73\n",
      "reg: -1.79\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  9.11batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:01,  3.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 15.65batch/s]total loss: 1.19\n",
      "recon: 1.06\n",
      "reg: 3.29\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  9.29batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:01,  3.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9232\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 16.86batch/s]total loss: 0.77\n",
      "recon: 0.81\n",
      "reg: -0.83\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00,  8.78batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8216\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 13.59batch/s]total loss: 1.34\n",
      "recon: 1.26\n",
      "reg: 1.98\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00,  8.79batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 14.06batch/s]total loss: 0.73\n",
      "recon: 0.70\n",
      "reg: 0.57\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00,  8.50batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:01,  3.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 11.65batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.27\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  7.76batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:01,  3.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8691\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 16.46batch/s]total loss: 0.82\n",
      "recon: 0.81\n",
      "reg: 0.11\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  9.75batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  4.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8416\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 15.77batch/s]total loss: 0.98\n",
      "recon: 1.08\n",
      "reg: -2.70\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00,  9.13batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:01,  3.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8468\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 16.75batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.86\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00,  9.58batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:01,  3.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.79\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 16.46batch/s]total loss: 0.56\n",
      "recon: 0.57\n",
      "reg: -0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  9.63batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  4.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 15.11batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.67\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  9.88batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8143\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  60%|██████    | 3/5 [00:00<00:00,  9.76batch/s]total loss: 0.39\n",
      "recon: 0.38\n",
      "reg: 0.29\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00,  8.18batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  5.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7498\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 15.82batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 10.08batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  4.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7909\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 16.22batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.07\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 10.02batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  4.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.83\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  60%|██████    | 3/5 [00:00<00:00, 13.65batch/s]total loss: 1.07\n",
      "recon: 1.02\n",
      "reg: 1.30\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  9.23batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  4.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 14.51batch/s]total loss: 0.61\n",
      "recon: 0.64\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00,  9.44batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  4.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  60%|██████    | 3/5 [00:00<00:00, 10.75batch/s]total loss: 0.31\n",
      "recon: 0.40\n",
      "reg: -2.21\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00,  7.40batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:01,  3.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 16.44batch/s]total loss: 0.79\n",
      "recon: 0.64\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 10.08batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8183\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 16.78batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.51\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 10.41batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  4.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00, 15.06batch/s]total loss: 0.51\n",
      "recon: 0.46\n",
      "reg: 1.29\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  8.72batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 17.40batch/s]total loss: 0.76\n",
      "recon: 0.72\n",
      "reg: 0.88\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  9.72batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:01,  3.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8033\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 14.47batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.35\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  8.46batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:01,  3.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8392\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 16.79batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.35\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 10.45batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8333\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 13.79batch/s]total loss: 0.94\n",
      "recon: 0.82\n",
      "reg: 2.90\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  9.34batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  60%|██████    | 3/5 [00:00<00:00, 14.25batch/s]total loss: 0.71\n",
      "recon: 0.78\n",
      "reg: -1.62\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  9.61batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 16.20batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.77\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  8.69batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:01,  3.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8986\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 15.54batch/s]total loss: 0.91\n",
      "recon: 0.92\n",
      "reg: -0.23\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  9.84batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8309\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  60%|██████    | 3/5 [00:00<00:00, 13.37batch/s]total loss: 0.65\n",
      "recon: 0.61\n",
      "reg: 0.89\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  7.38batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.89batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 16.46batch/s]total loss: 1.08\n",
      "recon: 0.99\n",
      "reg: 2.14\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  9.19batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:01,  3.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8833\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 16.87batch/s]total loss: 0.63\n",
      "recon: 0.60\n",
      "reg: 0.78\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  9.65batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:01,  3.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7938\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 15.51batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.84\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  9.98batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  4.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 15.33batch/s]total loss: 0.70\n",
      "recon: 0.63\n",
      "reg: 1.61\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  9.31batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 14.54batch/s]total loss: 0.78\n",
      "recon: 0.83\n",
      "reg: -1.19\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  8.40batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8094\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 14.86batch/s]total loss: 1.65\n",
      "recon: 1.55\n",
      "reg: 2.45\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  9.54batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  4.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9859\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 15.29batch/s]total loss: 0.91\n",
      "recon: 0.89\n",
      "reg: 0.35\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  9.02batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:01,  3.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 17.24batch/s]total loss: 0.92\n",
      "recon: 0.82\n",
      "reg: 2.52\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  7.85batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:01,  2.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8423\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 16.94batch/s]total loss: 1.58\n",
      "recon: 1.54\n",
      "reg: 0.99\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 10.35batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  60%|██████    | 3/5 [00:00<00:00, 14.25batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.73\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  9.20batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  4.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8236\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_22-09-07/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.114875004534, Time: 154.45s\n",
      "Epoch 200, Training Loss: 0.041040038015, Time: 263.14s\n",
      "Epoch 300, Training Loss: 0.014057180213, Time: 377.34s\n",
      "Epoch 400, Training Loss: 0.009489276013, Time: 483.86s\n",
      "Epoch 500, Training Loss: 0.005714449228, Time: 593.02s\n",
      "Epoch 600, Training Loss: 0.003244221902, Time: 715.90s\n",
      "Epoch 700, Training Loss: 0.001277019807, Time: 842.21s\n",
      "Epoch 800, Training Loss: 0.000573103592, Time: 955.12s\n",
      "Epoch 900, Training Loss: 0.000360323455, Time: 1066.50s\n",
      "Epoch 1000, Training Loss: 0.000390910856, Time: 1177.81s\n",
      "Validation Loss: 0.000205482999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00021</td></tr><tr><td>val_loss</td><td>0.00021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-sweep-18</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/mvefn1or' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/mvefn1or</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250325_220906-mvefn1or/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yhab7hxc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0037153034043616376\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250325_223009-yhab7hxc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/yhab7hxc' target=\"_blank\">curious-sweep-19</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/yhab7hxc' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/yhab7hxc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_22-30-10. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 15.01batch/s]total loss: 4.54\n",
      "recon: 4.25\n",
      "reg: 7.01\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  8.76batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:01,  3.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.4454\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 15.14batch/s]total loss: 1.09\n",
      "recon: 1.05\n",
      "reg: 1.10\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 10.32batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  5.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.5912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 16.35batch/s]total loss: 1.23\n",
      "recon: 1.27\n",
      "reg: -1.13\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00, 10.10batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  4.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2307\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 16.54batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.76\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 10.34batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  4.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 14.10batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.45\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  4.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9394\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 15.54batch/s]total loss: 0.81\n",
      "recon: 0.71\n",
      "reg: 2.51\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00,  9.98batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 15.03batch/s]total loss: 0.67\n",
      "recon: 0.70\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 10.36batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  5.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 13.80batch/s]total loss: 0.71\n",
      "recon: 0.71\n",
      "reg: -0.09\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00,  9.50batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  4.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 16.09batch/s]total loss: 1.02\n",
      "recon: 0.89\n",
      "reg: 3.25\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 10.19batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9044\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 14.96batch/s]total loss: 0.65\n",
      "recon: 0.57\n",
      "reg: 2.05\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  9.84batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  4.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  60%|██████    | 3/5 [00:00<00:00, 12.16batch/s]total loss: 1.09\n",
      "recon: 0.94\n",
      "reg: 3.71\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00,  9.07batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  4.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9274\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 15.60batch/s]total loss: 0.93\n",
      "recon: 0.85\n",
      "reg: 1.84\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00, 10.30batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  4.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 17.09batch/s]total loss: 1.01\n",
      "recon: 0.97\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 10.59batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  60%|██████    | 3/5 [00:00<00:00, 14.32batch/s]total loss: 0.65\n",
      "recon: 0.65\n",
      "reg: -0.11\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00,  8.96batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  4.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 15.47batch/s]total loss: 0.75\n",
      "recon: 0.75\n",
      "reg: 0.04\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  9.26batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:01,  3.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8417\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 16.54batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.13\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 10.18batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  60%|██████    | 3/5 [00:00<00:00, 14.12batch/s]total loss: 0.85\n",
      "recon: 0.76\n",
      "reg: 2.07\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00,  9.47batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  4.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00,  9.74batch/s]total loss: 0.74\n",
      "recon: 0.63\n",
      "reg: 2.86\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00,  7.81batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  4.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8258\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 14.49batch/s]total loss: 0.37\n",
      "recon: 0.48\n",
      "reg: -2.77\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00,  9.93batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  4.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  60%|██████    | 3/5 [00:00<00:00, 12.03batch/s]total loss: 1.04\n",
      "recon: 1.06\n",
      "reg: -0.72\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00,  8.94batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8823\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 12.04batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.33\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00,  8.87batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9097\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 16.79batch/s]total loss: 0.53\n",
      "recon: 0.63\n",
      "reg: -2.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 10.49batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7636\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  60%|██████    | 3/5 [00:00<00:00, 13.82batch/s]total loss: 0.93\n",
      "recon: 0.91\n",
      "reg: 0.48\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  9.75batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  4.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8492\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 14.46batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.33\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00,  9.51batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 14.41batch/s]total loss: 0.86\n",
      "recon: 0.82\n",
      "reg: 1.08\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00,  9.80batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  4.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8431\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  60%|██████    | 3/5 [00:00<00:00,  6.75batch/s]total loss: 1.19\n",
      "recon: 1.07\n",
      "reg: 3.22\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00,  6.14batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9047\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 11.91batch/s]total loss: 0.98\n",
      "recon: 0.80\n",
      "reg: 4.48\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00,  9.04batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 15.60batch/s]total loss: 0.76\n",
      "recon: 0.70\n",
      "reg: 1.32\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  9.20batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  4.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8853\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  60%|██████    | 3/5 [00:00<00:00, 13.00batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.90\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00,  7.48batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:01,  2.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:00<00:00, 16.39batch/s]total loss: 0.65\n",
      "recon: 0.58\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  8.03batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  2.84batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 16.17batch/s]total loss: 1.03\n",
      "recon: 1.05\n",
      "reg: -0.60\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 10.39batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9293\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00, 14.87batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.74\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  8.79batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 15.08batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.58\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  9.56batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  4.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8369\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 13.45batch/s]total loss: 0.66\n",
      "recon: 0.70\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  8.44batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:01,  3.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  60%|██████    | 3/5 [00:00<00:00, 14.24batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.13\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  9.14batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  4.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9186\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 16.14batch/s]total loss: 0.56\n",
      "recon: 0.63\n",
      "reg: -1.68\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  7.61batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:01,  2.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 16.40batch/s]total loss: 0.71\n",
      "recon: 0.75\n",
      "reg: -0.86\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 10.97batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  5.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8243\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 14.36batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.79\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00,  9.49batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8526\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 14.65batch/s]total loss: 0.87\n",
      "recon: 0.81\n",
      "reg: 1.67\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  9.89batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8549\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 13.96batch/s]total loss: 1.35\n",
      "recon: 1.29\n",
      "reg: 1.42\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00,  9.46batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  60%|██████    | 3/5 [00:00<00:00, 11.79batch/s]total loss: 1.17\n",
      "recon: 1.03\n",
      "reg: 3.66\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00,  7.74batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:01,  3.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.96\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 16.36batch/s]total loss: 1.27\n",
      "recon: 1.29\n",
      "reg: -0.54\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  9.94batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  4.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 14.51batch/s]total loss: 0.97\n",
      "recon: 0.96\n",
      "reg: 0.04\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00,  8.80batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:01,  3.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8667\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  60%|██████    | 3/5 [00:00<00:00, 13.48batch/s]total loss: 0.88\n",
      "recon: 0.86\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00,  9.35batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  4.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 15.59batch/s]total loss: 0.92\n",
      "recon: 0.87\n",
      "reg: 1.15\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00, 10.46batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  5.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 14.30batch/s]total loss: 0.92\n",
      "recon: 0.84\n",
      "reg: 2.00\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00,  9.76batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  4.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 10.97batch/s]total loss: 0.92\n",
      "recon: 0.94\n",
      "reg: -0.45\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  7.74batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  4.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 15.28batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.89\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  9.68batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  4.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 17.03batch/s]total loss: 0.34\n",
      "recon: 0.53\n",
      "reg: -4.81\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 10.22batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7391\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  60%|██████    | 3/5 [00:00<00:00, 11.58batch/s]total loss: 1.03\n",
      "recon: 1.02\n",
      "reg: 0.36\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00,  8.76batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  4.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 15.80batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.50\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 10.31batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 14.04batch/s]total loss: 0.78\n",
      "recon: 0.78\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  8.75batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:01,  3.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 14.73batch/s]total loss: 0.60\n",
      "recon: 0.58\n",
      "reg: 0.51\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 10.02batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7782\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 16.03batch/s]total loss: 0.69\n",
      "recon: 0.80\n",
      "reg: -2.77\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00,  9.67batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  4.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 17.48batch/s]total loss: 1.01\n",
      "recon: 1.06\n",
      "reg: -1.18\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  9.24batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:01,  3.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 16.18batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.50\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00,  9.65batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 16.68batch/s]total loss: 0.86\n",
      "recon: 0.70\n",
      "reg: 3.93\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 10.60batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8203\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 14.03batch/s]total loss: 0.88\n",
      "recon: 0.95\n",
      "reg: -1.75\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  8.80batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:01,  3.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 14.59batch/s]total loss: 0.70\n",
      "recon: 0.62\n",
      "reg: 1.82\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00,  8.65batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:01,  3.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.794\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 13.28batch/s]total loss: 0.26\n",
      "recon: 0.40\n",
      "reg: -3.61\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  7.67batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  3.05batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.6987\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 16.87batch/s]total loss: 0.59\n",
      "recon: 0.57\n",
      "reg: 0.43\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  9.27batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7719\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 16.31batch/s]total loss: 0.96\n",
      "recon: 0.99\n",
      "reg: -0.90\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00,  8.81batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:01,  3.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8422\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 14.84batch/s]total loss: 0.66\n",
      "recon: 0.73\n",
      "reg: -1.79\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  9.84batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  60%|██████    | 3/5 [00:00<00:00, 13.60batch/s]total loss: 1.19\n",
      "recon: 1.06\n",
      "reg: 3.29\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  9.08batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  4.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9232\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 15.46batch/s]total loss: 0.77\n",
      "recon: 0.81\n",
      "reg: -0.83\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 10.03batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  5.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8216\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 15.02batch/s]total loss: 1.34\n",
      "recon: 1.26\n",
      "reg: 1.98\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00,  9.04batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:01,  3.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 16.18batch/s]total loss: 0.73\n",
      "recon: 0.70\n",
      "reg: 0.57\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00,  9.89batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  4.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 15.64batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.27\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  9.74batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  4.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8691\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 16.72batch/s]total loss: 0.82\n",
      "recon: 0.81\n",
      "reg: 0.11\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  8.97batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:01,  3.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8416\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 16.71batch/s]total loss: 0.98\n",
      "recon: 1.08\n",
      "reg: -2.70\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 10.27batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  4.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8468\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 14.70batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.86\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00,  9.68batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.79\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  60%|██████    | 3/5 [00:00<00:00, 11.21batch/s]total loss: 0.56\n",
      "recon: 0.57\n",
      "reg: -0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  8.76batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 13.32batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.67\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  9.53batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  5.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8143\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 16.26batch/s]total loss: 0.39\n",
      "recon: 0.38\n",
      "reg: 0.29\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00,  9.49batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:01,  3.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7498\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 16.56batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00,  9.43batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:01,  3.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7909\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 17.21batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.07\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00,  9.86batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  4.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.83\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  80%|████████  | 4/5 [00:00<00:00, 14.45batch/s]total loss: 1.07\n",
      "recon: 1.02\n",
      "reg: 1.30\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  8.78batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 14.91batch/s]total loss: 0.61\n",
      "recon: 0.64\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 10.03batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  60%|██████    | 3/5 [00:00<00:00, 10.43batch/s]total loss: 0.31\n",
      "recon: 0.40\n",
      "reg: -2.21\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00,  7.60batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:01,  3.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 15.65batch/s]total loss: 0.79\n",
      "recon: 0.64\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  8.87batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:01,  3.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8183\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 16.99batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.51\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00,  9.02batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:01,  3.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  60%|██████    | 3/5 [00:00<00:00, 13.32batch/s]total loss: 0.51\n",
      "recon: 0.46\n",
      "reg: 1.29\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  8.76batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 15.20batch/s]total loss: 0.76\n",
      "recon: 0.72\n",
      "reg: 0.88\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  8.56batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:01,  3.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8033\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 16.56batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.35\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  9.28batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:01,  3.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8392\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 16.54batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.35\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  9.75batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  4.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8333\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 15.08batch/s]total loss: 0.94\n",
      "recon: 0.82\n",
      "reg: 2.90\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  9.52batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 15.02batch/s]total loss: 0.71\n",
      "recon: 0.78\n",
      "reg: -1.62\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  9.30batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 15.34batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.77\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  9.98batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8986\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 16.79batch/s]total loss: 0.91\n",
      "recon: 0.92\n",
      "reg: -0.23\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00, 10.40batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8309\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 11.24batch/s]total loss: 0.65\n",
      "recon: 0.61\n",
      "reg: 0.89\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  6.41batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.72batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 14.98batch/s]total loss: 1.08\n",
      "recon: 0.99\n",
      "reg: 2.14\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  9.68batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  4.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8833\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 15.20batch/s]total loss: 0.63\n",
      "recon: 0.60\n",
      "reg: 0.78\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  9.11batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:01,  3.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7938\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 14.21batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.84\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  9.53batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  4.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 14.77batch/s]total loss: 0.70\n",
      "recon: 0.63\n",
      "reg: 1.61\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  9.47batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  60%|██████    | 3/5 [00:00<00:00, 13.97batch/s]total loss: 0.78\n",
      "recon: 0.83\n",
      "reg: -1.19\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  5.45batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:02,  1.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8094\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 13.15batch/s]total loss: 1.65\n",
      "recon: 1.55\n",
      "reg: 2.45\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  9.30batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9859\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 14.84batch/s]total loss: 0.91\n",
      "recon: 0.89\n",
      "reg: 0.35\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  9.03batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:01,  3.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 10.07batch/s]total loss: 0.92\n",
      "recon: 0.82\n",
      "reg: 2.52\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  8.10batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8423\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 12.19batch/s]total loss: 1.58\n",
      "recon: 1.54\n",
      "reg: 0.99\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00,  8.80batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 11.82batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.73\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  6.57batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:01,  2.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8236\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_22-30-10/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.114875004534, Time: 106.90s\n",
      "Epoch 200, Training Loss: 0.041040038015, Time: 207.58s\n",
      "Epoch 300, Training Loss: 0.014057180213, Time: 309.31s\n",
      "Epoch 400, Training Loss: 0.009489276013, Time: 410.97s\n",
      "Epoch 500, Training Loss: 0.005714449228, Time: 512.23s\n",
      "Epoch 600, Training Loss: 0.003244221902, Time: 615.76s\n",
      "Epoch 700, Training Loss: 0.001277019807, Time: 717.64s\n",
      "Epoch 800, Training Loss: 0.000573103592, Time: 816.86s\n",
      "Epoch 900, Training Loss: 0.000360323455, Time: 918.10s\n",
      "Epoch 1000, Training Loss: 0.000390910856, Time: 1028.62s\n",
      "Validation Loss: 0.000205482999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00021</td></tr><tr><td>val_loss</td><td>0.00021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">curious-sweep-19</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/yhab7hxc' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/yhab7hxc</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250325_223009-yhab7hxc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p54ybwau with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0016625093712817937\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250325_224836-p54ybwau</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/p54ybwau' target=\"_blank\">crisp-sweep-20</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/p54ybwau' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/p54ybwau</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_22-48-37. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 15.19batch/s]total loss: 4.54\n",
      "recon: 4.25\n",
      "reg: 7.01\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  9.50batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:00,  4.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.4454\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 15.29batch/s]total loss: 1.09\n",
      "recon: 1.05\n",
      "reg: 1.10\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 10.41batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  5.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.5912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 13.23batch/s]total loss: 1.23\n",
      "recon: 1.27\n",
      "reg: -1.13\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  9.47batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  5.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2307\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 16.83batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.76\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 10.33batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  4.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 15.52batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.45\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  9.87batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  4.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9394\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 15.69batch/s]total loss: 0.81\n",
      "recon: 0.71\n",
      "reg: 2.51\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 10.10batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 13.86batch/s]total loss: 0.67\n",
      "recon: 0.70\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00,  9.80batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 16.40batch/s]total loss: 0.71\n",
      "recon: 0.71\n",
      "reg: -0.09\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 10.79batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  5.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 15.10batch/s]total loss: 1.02\n",
      "recon: 0.89\n",
      "reg: 3.25\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 10.03batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9044\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 16.46batch/s]total loss: 0.65\n",
      "recon: 0.57\n",
      "reg: 2.05\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  9.76batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  4.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 15.92batch/s]total loss: 1.09\n",
      "recon: 0.94\n",
      "reg: 3.71\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 10.33batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9274\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 16.80batch/s]total loss: 0.93\n",
      "recon: 0.85\n",
      "reg: 1.84\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00, 11.02batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  5.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 16.57batch/s]total loss: 1.01\n",
      "recon: 0.97\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00,  9.75batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 16.90batch/s]total loss: 0.65\n",
      "recon: 0.65\n",
      "reg: -0.11\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 10.57batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  4.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 16.72batch/s]total loss: 0.75\n",
      "recon: 0.75\n",
      "reg: 0.04\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00, 10.58batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  4.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8417\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 16.68batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.13\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 10.73batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  60%|██████    | 3/5 [00:00<00:00, 11.87batch/s]total loss: 0.85\n",
      "recon: 0.76\n",
      "reg: 2.07\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00,  8.45batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  4.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00, 16.72batch/s]total loss: 0.74\n",
      "recon: 0.63\n",
      "reg: 2.86\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00, 10.45batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8258\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 14.65batch/s]total loss: 0.37\n",
      "recon: 0.48\n",
      "reg: -2.77\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00,  9.61batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  4.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 13.91batch/s]total loss: 1.04\n",
      "recon: 1.06\n",
      "reg: -0.72\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00,  9.50batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  4.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8823\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 15.62batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.33\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 10.10batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9097\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 16.53batch/s]total loss: 0.53\n",
      "recon: 0.63\n",
      "reg: -2.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 10.05batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  4.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7636\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  60%|██████    | 3/5 [00:00<00:00, 10.18batch/s]total loss: 0.93\n",
      "recon: 0.91\n",
      "reg: 0.48\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  8.32batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  4.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8492\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 16.37batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.33\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 10.56batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 16.38batch/s]total loss: 0.86\n",
      "recon: 0.82\n",
      "reg: 1.08\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 10.79batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  5.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8431\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 16.03batch/s]total loss: 1.19\n",
      "recon: 1.07\n",
      "reg: 3.22\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 10.52batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  5.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9047\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 14.83batch/s]total loss: 0.98\n",
      "recon: 0.80\n",
      "reg: 4.48\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00,  9.97batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  4.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 14.77batch/s]total loss: 0.76\n",
      "recon: 0.70\n",
      "reg: 1.32\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  7.72batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:01,  3.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8853\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 11.46batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.90\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00,  9.01batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  5.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:00<00:00, 13.44batch/s]total loss: 0.65\n",
      "recon: 0.58\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:01<00:00,  3.88batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:03,  1.03batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 13.69batch/s]total loss: 1.03\n",
      "recon: 1.05\n",
      "reg: -0.60\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00,  9.40batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9293\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 11.94batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.74\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  7.83batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:01,  3.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 16.94batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.58\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  9.88batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  4.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8369\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 12.16batch/s]total loss: 0.66\n",
      "recon: 0.70\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  8.19batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  4.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 16.70batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.13\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  9.81batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  4.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9186\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 14.53batch/s]total loss: 0.56\n",
      "recon: 0.63\n",
      "reg: -1.68\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  8.92batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  4.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 15.19batch/s]total loss: 0.71\n",
      "recon: 0.75\n",
      "reg: -0.86\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00,  8.98batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:01,  3.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8243\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 13.63batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.79\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00,  9.55batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8526\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 14.94batch/s]total loss: 0.87\n",
      "recon: 0.81\n",
      "reg: 1.67\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  9.02batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:01,  3.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8549\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 16.00batch/s]total loss: 1.35\n",
      "recon: 1.29\n",
      "reg: 1.42\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 10.44batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  60%|██████    | 3/5 [00:00<00:00,  8.30batch/s]total loss: 1.17\n",
      "recon: 1.03\n",
      "reg: 3.66\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00,  7.50batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.96\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 16.06batch/s]total loss: 1.27\n",
      "recon: 1.29\n",
      "reg: -0.54\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  6.95batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:01,  2.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 15.75batch/s]total loss: 0.97\n",
      "recon: 0.96\n",
      "reg: 0.04\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 10.02batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8667\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 15.39batch/s]total loss: 0.88\n",
      "recon: 0.86\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00,  8.56batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:01,  3.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 16.77batch/s]total loss: 0.92\n",
      "recon: 0.87\n",
      "reg: 1.15\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  9.17batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:01,  3.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00,  8.70batch/s]total loss: 0.92\n",
      "recon: 0.84\n",
      "reg: 2.00\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00,  7.45batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  4.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 16.40batch/s]total loss: 0.92\n",
      "recon: 0.94\n",
      "reg: -0.45\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 10.39batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 17.10batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.89\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  9.74batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  4.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 16.76batch/s]total loss: 0.34\n",
      "recon: 0.53\n",
      "reg: -4.81\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 10.60batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  4.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7391\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 16.42batch/s]total loss: 1.03\n",
      "recon: 1.02\n",
      "reg: 0.36\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 10.19batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 15.85batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.50\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00,  8.36batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:01,  3.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 14.54batch/s]total loss: 0.78\n",
      "recon: 0.78\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  9.26batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  4.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 16.74batch/s]total loss: 0.60\n",
      "recon: 0.58\n",
      "reg: 0.51\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00,  9.74batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  4.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7782\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  60%|██████    | 3/5 [00:00<00:00, 13.68batch/s]total loss: 0.69\n",
      "recon: 0.80\n",
      "reg: -2.77\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00,  8.31batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:01,  3.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 15.69batch/s]total loss: 1.01\n",
      "recon: 1.06\n",
      "reg: -1.18\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 10.35batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  5.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 16.29batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.50\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 10.48batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  60%|██████    | 3/5 [00:00<00:00, 13.90batch/s]total loss: 0.86\n",
      "recon: 0.70\n",
      "reg: 3.93\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00,  9.66batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8203\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 14.31batch/s]total loss: 0.88\n",
      "recon: 0.95\n",
      "reg: -1.75\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  9.58batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  4.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 16.65batch/s]total loss: 0.70\n",
      "recon: 0.62\n",
      "reg: 1.82\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00,  9.84batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  4.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.794\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00, 13.93batch/s]total loss: 0.26\n",
      "recon: 0.40\n",
      "reg: -3.61\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  6.52batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  2.67batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.6987\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 16.39batch/s]total loss: 0.59\n",
      "recon: 0.57\n",
      "reg: 0.43\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 10.43batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7719\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 16.89batch/s]total loss: 0.96\n",
      "recon: 0.99\n",
      "reg: -0.90\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00,  9.36batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:01,  3.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8422\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  60%|██████    | 3/5 [00:00<00:00, 12.27batch/s]total loss: 0.66\n",
      "recon: 0.73\n",
      "reg: -1.79\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  8.03batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:01,  3.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 16.75batch/s]total loss: 1.19\n",
      "recon: 1.06\n",
      "reg: 3.29\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00, 10.77batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  5.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9232\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  60%|██████    | 3/5 [00:00<00:00, 13.69batch/s]total loss: 0.77\n",
      "recon: 0.81\n",
      "reg: -0.83\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00,  9.10batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  4.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8216\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 16.04batch/s]total loss: 1.34\n",
      "recon: 1.26\n",
      "reg: 1.98\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 10.51batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  4.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 16.13batch/s]total loss: 0.73\n",
      "recon: 0.70\n",
      "reg: 0.57\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 10.55batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  4.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 12.19batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.27\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  8.42batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  4.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8691\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 15.31batch/s]total loss: 0.82\n",
      "recon: 0.81\n",
      "reg: 0.11\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  9.55batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  4.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8416\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 17.04batch/s]total loss: 0.98\n",
      "recon: 1.08\n",
      "reg: -2.70\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00,  9.40batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:01,  3.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8468\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 15.57batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.86\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00,  9.92batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.79\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 16.37batch/s]total loss: 0.56\n",
      "recon: 0.57\n",
      "reg: -0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00, 10.09batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  4.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 12.09batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.67\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  8.34batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:01,  3.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8143\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 17.02batch/s]total loss: 0.39\n",
      "recon: 0.38\n",
      "reg: 0.29\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 10.51batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  4.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7498\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 16.22batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00,  9.75batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  4.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7909\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 16.10batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.07\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00,  9.06batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:01,  3.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.83\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  80%|████████  | 4/5 [00:00<00:00, 10.31batch/s]total loss: 1.07\n",
      "recon: 1.02\n",
      "reg: 1.30\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  6.44batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:01,  2.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 14.73batch/s]total loss: 0.61\n",
      "recon: 0.64\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00,  9.35batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  4.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  60%|██████    | 3/5 [00:00<00:00, 10.50batch/s]total loss: 0.31\n",
      "recon: 0.40\n",
      "reg: -2.21\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00,  8.43batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  4.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 16.64batch/s]total loss: 0.79\n",
      "recon: 0.64\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 10.50batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  4.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8183\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 16.31batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.51\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00,  9.96batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  4.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00, 15.78batch/s]total loss: 0.51\n",
      "recon: 0.46\n",
      "reg: 1.29\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  8.57batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00,  9.77batch/s]total loss: 0.76\n",
      "recon: 0.72\n",
      "reg: 0.88\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  8.12batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8033\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 16.20batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.35\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00, 10.32batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  4.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8392\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 11.51batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.35\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  8.29batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  4.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8333\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 15.42batch/s]total loss: 0.94\n",
      "recon: 0.82\n",
      "reg: 2.90\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  9.41batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 15.60batch/s]total loss: 0.71\n",
      "recon: 0.78\n",
      "reg: -1.62\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  8.07batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:01,  3.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 16.76batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.77\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00, 10.50batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8986\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 14.68batch/s]total loss: 0.91\n",
      "recon: 0.92\n",
      "reg: -0.23\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  9.11batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:01,  3.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8309\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 16.66batch/s]total loss: 0.65\n",
      "recon: 0.61\n",
      "reg: 0.89\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  7.63batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.85batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 17.36batch/s]total loss: 1.08\n",
      "recon: 0.99\n",
      "reg: 2.14\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00, 10.91batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8833\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 14.89batch/s]total loss: 0.63\n",
      "recon: 0.60\n",
      "reg: 0.78\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  9.89batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7938\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 12.58batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.84\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  9.24batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  5.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  60%|██████    | 3/5 [00:00<00:00,  9.88batch/s]total loss: 0.70\n",
      "recon: 0.63\n",
      "reg: 1.61\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  7.98batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 16.69batch/s]total loss: 0.78\n",
      "recon: 0.83\n",
      "reg: -1.19\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  9.52batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:01,  3.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8094\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 17.01batch/s]total loss: 1.65\n",
      "recon: 1.55\n",
      "reg: 2.45\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  9.10batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:01,  3.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9859\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 14.96batch/s]total loss: 0.91\n",
      "recon: 0.89\n",
      "reg: 0.35\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  9.71batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  4.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00, 16.12batch/s]total loss: 0.92\n",
      "recon: 0.82\n",
      "reg: 2.52\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  9.41batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  5.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8423\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 14.99batch/s]total loss: 1.58\n",
      "recon: 1.54\n",
      "reg: 0.99\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00,  9.77batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 16.71batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.73\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  9.33batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  4.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8236\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_22-48-37/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.114875004534, Time: 114.73s\n",
      "Epoch 200, Training Loss: 0.041040038015, Time: 223.00s\n",
      "Epoch 300, Training Loss: 0.014057180213, Time: 328.64s\n",
      "Epoch 400, Training Loss: 0.009489276013, Time: 439.72s\n",
      "Epoch 500, Training Loss: 0.005714449228, Time: 543.53s\n",
      "Epoch 600, Training Loss: 0.003244221902, Time: 647.93s\n",
      "Epoch 700, Training Loss: 0.001277019807, Time: 756.01s\n",
      "Epoch 800, Training Loss: 0.000573103592, Time: 863.62s\n",
      "Epoch 900, Training Loss: 0.000360323455, Time: 973.11s\n",
      "Epoch 1000, Training Loss: 0.000390910856, Time: 1093.41s\n",
      "Validation Loss: 0.000205482999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00021</td></tr><tr><td>val_loss</td><td>0.00021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crisp-sweep-20</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/p54ybwau' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/p54ybwau</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250325_224836-p54ybwau/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8m6jrcpa with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00041403758965559455\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250325_230808-8m6jrcpa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/8m6jrcpa' target=\"_blank\">fresh-sweep-21</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/8m6jrcpa' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/8m6jrcpa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_23-08-08. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 15.11batch/s]total loss: 4.54\n",
      "recon: 4.25\n",
      "reg: 7.01\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  9.17batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:01,  3.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.4454\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 15.48batch/s]total loss: 1.09\n",
      "recon: 1.05\n",
      "reg: 1.10\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00,  8.85batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  4.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.5912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 11.94batch/s]total loss: 1.23\n",
      "recon: 1.27\n",
      "reg: -1.13\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  8.92batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2307\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 12.66batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.76\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00,  9.46batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  5.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 14.66batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.45\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  9.90batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  4.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9394\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 15.51batch/s]total loss: 0.81\n",
      "recon: 0.71\n",
      "reg: 2.51\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00,  9.87batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  4.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 16.56batch/s]total loss: 0.67\n",
      "recon: 0.70\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00,  8.37batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:01,  3.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 12.14batch/s]total loss: 0.71\n",
      "recon: 0.71\n",
      "reg: -0.09\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00,  9.04batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 10.08batch/s]total loss: 1.02\n",
      "recon: 0.89\n",
      "reg: 3.25\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  7.61batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:01,  3.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9044\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00, 13.17batch/s]total loss: 0.65\n",
      "recon: 0.57\n",
      "reg: 2.05\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  7.45batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:01,  3.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 15.08batch/s]total loss: 1.09\n",
      "recon: 0.94\n",
      "reg: 3.71\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00,  9.03batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:01,  3.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9274\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 15.59batch/s]total loss: 0.93\n",
      "recon: 0.85\n",
      "reg: 1.84\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  8.63batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:01,  3.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 13.45batch/s]total loss: 1.01\n",
      "recon: 0.97\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00,  8.45batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:01,  3.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 13.01batch/s]total loss: 0.65\n",
      "recon: 0.65\n",
      "reg: -0.11\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00,  9.24batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  4.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 13.56batch/s]total loss: 0.75\n",
      "recon: 0.75\n",
      "reg: 0.04\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  9.33batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  4.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8417\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  60%|██████    | 3/5 [00:00<00:00, 12.63batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.13\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00,  7.02batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:01,  3.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 14.81batch/s]total loss: 0.85\n",
      "recon: 0.76\n",
      "reg: 2.07\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00,  7.61batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:01,  2.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00, 11.63batch/s]total loss: 0.74\n",
      "recon: 0.63\n",
      "reg: 2.86\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00,  8.77batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8258\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 13.59batch/s]total loss: 0.37\n",
      "recon: 0.48\n",
      "reg: -2.77\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00,  7.89batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:01,  3.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 10.94batch/s]total loss: 1.04\n",
      "recon: 1.06\n",
      "reg: -0.72\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00,  7.21batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:01,  3.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8823\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 15.12batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.33\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00,  7.88batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:01,  3.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9097\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00,  6.82batch/s]total loss: 0.53\n",
      "recon: 0.63\n",
      "reg: -2.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00,  6.05batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  4.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7636\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  60%|██████    | 3/5 [00:00<00:00, 12.52batch/s]total loss: 0.93\n",
      "recon: 0.91\n",
      "reg: 0.48\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  8.28batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:01,  3.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8492\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 15.41batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.33\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00,  9.48batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 15.14batch/s]total loss: 0.86\n",
      "recon: 0.82\n",
      "reg: 1.08\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00,  7.05batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:01,  2.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8431\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 11.97batch/s]total loss: 1.19\n",
      "recon: 1.07\n",
      "reg: 3.22\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00,  8.09batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  4.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9047\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 12.91batch/s]total loss: 0.98\n",
      "recon: 0.80\n",
      "reg: 4.48\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00,  8.01batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:01,  3.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  60%|██████    | 3/5 [00:00<00:00, 12.12batch/s]total loss: 0.76\n",
      "recon: 0.70\n",
      "reg: 1.32\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  8.79batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  4.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8853\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 15.94batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.90\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00,  9.45batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  4.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:00<00:00, 15.46batch/s]total loss: 0.65\n",
      "recon: 0.58\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  6.94batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  2.31batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 11.75batch/s]total loss: 1.03\n",
      "recon: 1.05\n",
      "reg: -0.60\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00,  8.72batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9293\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 12.22batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.74\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  8.81batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 13.43batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.58\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  8.37batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  4.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8369\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  60%|██████    | 3/5 [00:00<00:00, 12.50batch/s]total loss: 0.66\n",
      "recon: 0.70\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  8.64batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  4.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 16.32batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.13\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  9.56batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  4.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9186\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00, 13.65batch/s]total loss: 0.56\n",
      "recon: 0.63\n",
      "reg: -1.68\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  8.30batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  4.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 13.81batch/s]total loss: 0.71\n",
      "recon: 0.75\n",
      "reg: -0.86\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00,  9.28batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  4.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8243\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 13.75batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.79\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00,  7.87batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:01,  3.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8526\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 15.72batch/s]total loss: 0.87\n",
      "recon: 0.81\n",
      "reg: 1.67\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  8.55batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:01,  3.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8549\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 15.25batch/s]total loss: 1.35\n",
      "recon: 1.29\n",
      "reg: 1.42\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00,  9.36batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  4.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 16.34batch/s]total loss: 1.17\n",
      "recon: 1.03\n",
      "reg: 3.66\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00,  9.00batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:01,  3.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.96\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00, 12.61batch/s]total loss: 1.27\n",
      "recon: 1.29\n",
      "reg: -0.54\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  7.97batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  4.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 12.77batch/s]total loss: 0.97\n",
      "recon: 0.96\n",
      "reg: 0.04\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00,  8.90batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  4.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8667\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  60%|██████    | 3/5 [00:00<00:00, 10.47batch/s]total loss: 0.88\n",
      "recon: 0.86\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00,  7.82batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  4.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 14.82batch/s]total loss: 0.92\n",
      "recon: 0.87\n",
      "reg: 1.15\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  8.99batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:01,  3.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 16.20batch/s]total loss: 0.92\n",
      "recon: 0.84\n",
      "reg: 2.00\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00,  9.45batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  4.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 12.35batch/s]total loss: 0.92\n",
      "recon: 0.94\n",
      "reg: -0.45\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  7.73batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  4.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00,  9.53batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.89\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  6.89batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:01,  3.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 14.81batch/s]total loss: 0.34\n",
      "recon: 0.53\n",
      "reg: -4.81\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00,  7.75batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:01,  2.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7391\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 11.85batch/s]total loss: 1.03\n",
      "recon: 1.02\n",
      "reg: 0.36\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00,  8.96batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 14.52batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.50\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  4.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 13.43batch/s]total loss: 0.78\n",
      "recon: 0.78\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  8.45batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:01,  3.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  60%|██████    | 3/5 [00:00<00:00, 11.72batch/s]total loss: 0.60\n",
      "recon: 0.58\n",
      "reg: 0.51\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00,  8.33batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  4.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7782\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 14.10batch/s]total loss: 0.69\n",
      "recon: 0.80\n",
      "reg: -2.77\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00,  9.54batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  4.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  60%|██████    | 3/5 [00:00<00:00, 13.11batch/s]total loss: 1.01\n",
      "recon: 1.06\n",
      "reg: -1.18\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  8.52batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:01,  3.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 15.33batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.50\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00,  8.87batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:01,  3.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 14.41batch/s]total loss: 0.86\n",
      "recon: 0.70\n",
      "reg: 3.93\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00,  9.40batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  4.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8203\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  60%|██████    | 3/5 [00:00<00:00,  9.36batch/s]total loss: 0.88\n",
      "recon: 0.95\n",
      "reg: -1.75\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  7.96batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  4.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 14.21batch/s]total loss: 0.70\n",
      "recon: 0.62\n",
      "reg: 1.82\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00,  9.41batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.794\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 15.10batch/s]total loss: 0.26\n",
      "recon: 0.40\n",
      "reg: -3.61\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  6.07batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:02,  1.89batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.6987\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 13.37batch/s]total loss: 0.59\n",
      "recon: 0.57\n",
      "reg: 0.43\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  9.16batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7719\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 12.89batch/s]total loss: 0.96\n",
      "recon: 0.99\n",
      "reg: -0.90\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00,  9.27batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  4.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8422\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  60%|██████    | 3/5 [00:00<00:00, 11.41batch/s]total loss: 0.66\n",
      "recon: 0.73\n",
      "reg: -1.79\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  8.73batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00,  9.33batch/s]total loss: 1.19\n",
      "recon: 1.06\n",
      "reg: 3.29\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  7.36batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  4.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9232\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 14.46batch/s]total loss: 0.77\n",
      "recon: 0.81\n",
      "reg: -0.83\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00,  8.14batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:01,  3.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8216\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 16.50batch/s]total loss: 1.34\n",
      "recon: 1.26\n",
      "reg: 1.98\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00,  9.64batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  4.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 11.85batch/s]total loss: 0.73\n",
      "recon: 0.70\n",
      "reg: 0.57\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00,  8.70batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  4.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 12.82batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.27\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  8.17batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:01,  3.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8691\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  60%|██████    | 3/5 [00:00<00:00, 12.34batch/s]total loss: 0.82\n",
      "recon: 0.81\n",
      "reg: 0.11\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  7.87batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:01,  3.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8416\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 16.65batch/s]total loss: 0.98\n",
      "recon: 1.08\n",
      "reg: -2.70\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00,  9.16batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:01,  3.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8468\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 12.81batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.86\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00,  8.02batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.79\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 12.75batch/s]total loss: 0.56\n",
      "recon: 0.57\n",
      "reg: -0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  8.74batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  4.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 13.33batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.67\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  7.91batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:01,  3.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8143\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 14.77batch/s]total loss: 0.39\n",
      "recon: 0.38\n",
      "reg: 0.29\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00,  8.91batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:01,  3.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7498\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 15.35batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00,  8.48batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:01,  3.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7909\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00,  7.69batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.07\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00,  6.73batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  4.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.83\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  80%|████████  | 4/5 [00:00<00:00, 11.25batch/s]total loss: 1.07\n",
      "recon: 1.02\n",
      "reg: 1.30\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  8.35batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  4.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00,  8.88batch/s]total loss: 0.61\n",
      "recon: 0.64\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:01<00:00,  4.25batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:01,  2.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  60%|██████    | 3/5 [00:00<00:00, 12.19batch/s]total loss: 0.31\n",
      "recon: 0.40\n",
      "reg: -2.21\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00,  6.96batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:01,  2.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 14.20batch/s]total loss: 0.79\n",
      "recon: 0.64\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  8.00batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:01,  3.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8183\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 13.85batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.51\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00,  8.44batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:01,  3.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 11.22batch/s]total loss: 0.51\n",
      "recon: 0.46\n",
      "reg: 1.29\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  8.76batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 12.57batch/s]total loss: 0.76\n",
      "recon: 0.72\n",
      "reg: 0.88\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  9.00batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8033\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00,  9.88batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.35\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  7.41batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  4.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8392\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  60%|██████    | 3/5 [00:00<00:00, 12.05batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.35\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  7.91batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:01,  3.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8333\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  60%|██████    | 3/5 [00:00<00:00, 13.27batch/s]total loss: 0.94\n",
      "recon: 0.82\n",
      "reg: 2.90\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  7.45batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:01,  2.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00,  9.16batch/s]total loss: 0.71\n",
      "recon: 0.78\n",
      "reg: -1.62\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  7.30batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 14.52batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.77\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  9.40batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8986\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  60%|██████    | 3/5 [00:00<00:00,  8.41batch/s]total loss: 0.91\n",
      "recon: 0.92\n",
      "reg: -0.23\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  6.85batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:01,  3.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8309\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 16.13batch/s]total loss: 0.65\n",
      "recon: 0.61\n",
      "reg: 0.89\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  6.94batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.26batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 11.60batch/s]total loss: 1.08\n",
      "recon: 0.99\n",
      "reg: 2.14\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  8.19batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:01,  3.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8833\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 13.65batch/s]total loss: 0.63\n",
      "recon: 0.60\n",
      "reg: 0.78\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  6.94batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:01,  2.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7938\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 15.07batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.84\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  8.00batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:01,  3.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 14.17batch/s]total loss: 0.70\n",
      "recon: 0.63\n",
      "reg: 1.61\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  7.26batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:01,  3.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 12.80batch/s]total loss: 0.78\n",
      "recon: 0.83\n",
      "reg: -1.19\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  9.27batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8094\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 15.54batch/s]total loss: 1.65\n",
      "recon: 1.55\n",
      "reg: 2.45\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  9.64batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  4.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9859\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  60%|██████    | 3/5 [00:00<00:00, 10.04batch/s]total loss: 0.91\n",
      "recon: 0.89\n",
      "reg: 0.35\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  8.12batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00, 14.38batch/s]total loss: 0.92\n",
      "recon: 0.82\n",
      "reg: 2.52\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  8.41batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  4.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8423\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 14.57batch/s]total loss: 1.58\n",
      "recon: 1.54\n",
      "reg: 0.99\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00,  7.39batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:01,  2.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  60%|██████    | 3/5 [00:00<00:00, 12.29batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.73\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  7.66batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:01,  3.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8236\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_23-08-08/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.114875004534, Time: 115.62s\n",
      "Epoch 200, Training Loss: 0.041040038015, Time: 227.30s\n",
      "Epoch 300, Training Loss: 0.014057180213, Time: 343.60s\n",
      "Epoch 400, Training Loss: 0.009489276013, Time: 457.69s\n",
      "Epoch 500, Training Loss: 0.005714449228, Time: 570.50s\n",
      "Epoch 600, Training Loss: 0.003244221902, Time: 681.28s\n",
      "Epoch 700, Training Loss: 0.001277019807, Time: 793.03s\n",
      "Epoch 800, Training Loss: 0.000573103592, Time: 906.02s\n",
      "Epoch 900, Training Loss: 0.000360323455, Time: 1019.15s\n",
      "Epoch 1000, Training Loss: 0.000390910856, Time: 1130.58s\n",
      "Validation Loss: 0.000205482999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00021</td></tr><tr><td>val_loss</td><td>0.00021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-sweep-21</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/8m6jrcpa' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/8m6jrcpa</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250325_230808-8m6jrcpa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c688ng4u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009636873131957943\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250325_232824-c688ng4u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/c688ng4u' target=\"_blank\">swept-sweep-22</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/c688ng4u' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/c688ng4u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_23-28-25. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 14.15batch/s]total loss: 4.54\n",
      "recon: 4.25\n",
      "reg: 7.01\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  9.12batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:00,  4.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.4454\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  60%|██████    | 3/5 [00:00<00:00, 13.59batch/s]total loss: 1.09\n",
      "recon: 1.05\n",
      "reg: 1.10\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00,  9.13batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  4.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.5912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 14.68batch/s]total loss: 1.23\n",
      "recon: 1.27\n",
      "reg: -1.13\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  9.41batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  4.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2307\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 16.61batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.76\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00,  7.69batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:01,  2.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 12.83batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.45\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  9.02batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9394\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 15.69batch/s]total loss: 0.81\n",
      "recon: 0.71\n",
      "reg: 2.51\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00,  9.36batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  4.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 14.37batch/s]total loss: 0.67\n",
      "recon: 0.70\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00,  9.45batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  4.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 14.45batch/s]total loss: 0.71\n",
      "recon: 0.71\n",
      "reg: -0.09\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00,  8.63batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:01,  3.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 13.78batch/s]total loss: 1.02\n",
      "recon: 0.89\n",
      "reg: 3.25\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  9.50batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  4.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9044\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 15.85batch/s]total loss: 0.65\n",
      "recon: 0.57\n",
      "reg: 2.05\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  9.11batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  4.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 15.78batch/s]total loss: 1.09\n",
      "recon: 0.94\n",
      "reg: 3.71\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00,  8.95batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:01,  3.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9274\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 15.54batch/s]total loss: 0.93\n",
      "recon: 0.85\n",
      "reg: 1.84\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  9.24batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:01,  3.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 16.26batch/s]total loss: 1.01\n",
      "recon: 0.97\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 10.24batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  4.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 14.18batch/s]total loss: 0.65\n",
      "recon: 0.65\n",
      "reg: -0.11\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00,  9.35batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  60%|██████    | 3/5 [00:00<00:00, 10.86batch/s]total loss: 0.75\n",
      "recon: 0.75\n",
      "reg: 0.04\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  8.29batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  4.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8417\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 14.31batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.13\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00,  9.89batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  5.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 13.76batch/s]total loss: 0.85\n",
      "recon: 0.76\n",
      "reg: 2.07\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00,  9.23batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  4.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  60%|██████    | 3/5 [00:00<00:00, 13.14batch/s]total loss: 0.74\n",
      "recon: 0.63\n",
      "reg: 2.86\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00,  8.83batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  4.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8258\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  60%|██████    | 3/5 [00:00<00:00, 11.64batch/s]total loss: 0.37\n",
      "recon: 0.48\n",
      "reg: -2.77\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00,  8.09batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  4.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 15.03batch/s]total loss: 1.04\n",
      "recon: 1.06\n",
      "reg: -0.72\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00,  9.83batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8823\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  60%|██████    | 3/5 [00:00<00:00, 13.10batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.33\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00,  8.71batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  4.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9097\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 15.29batch/s]total loss: 0.53\n",
      "recon: 0.63\n",
      "reg: -2.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 10.04batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  4.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7636\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 15.36batch/s]total loss: 0.93\n",
      "recon: 0.91\n",
      "reg: 0.48\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  8.86batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:01,  3.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8492\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  60%|██████    | 3/5 [00:00<00:00, 13.31batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.33\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00,  9.32batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 15.17batch/s]total loss: 0.86\n",
      "recon: 0.82\n",
      "reg: 1.08\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00,  9.51batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  4.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8431\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 11.92batch/s]total loss: 1.19\n",
      "recon: 1.07\n",
      "reg: 3.22\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00,  8.77batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  4.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9047\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  60%|██████    | 3/5 [00:00<00:00, 12.73batch/s]total loss: 0.98\n",
      "recon: 0.80\n",
      "reg: 4.48\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00,  8.89batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  4.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 15.25batch/s]total loss: 0.76\n",
      "recon: 0.70\n",
      "reg: 1.32\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  9.49batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  4.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8853\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 16.01batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.90\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  4.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:00<00:00, 12.18batch/s]total loss: 0.65\n",
      "recon: 0.58\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  7.04batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  2.74batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 15.87batch/s]total loss: 1.03\n",
      "recon: 1.05\n",
      "reg: -0.60\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00,  9.75batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9293\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 16.31batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.74\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00, 10.25batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  60%|██████    | 3/5 [00:00<00:00,  9.62batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.58\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  7.84batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8369\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 11.36batch/s]total loss: 0.66\n",
      "recon: 0.70\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  7.98batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 13.91batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.13\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  8.76batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:01,  3.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9186\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 15.22batch/s]total loss: 0.56\n",
      "recon: 0.63\n",
      "reg: -1.68\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  9.48batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  4.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 15.23batch/s]total loss: 0.71\n",
      "recon: 0.75\n",
      "reg: -0.86\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00,  8.11batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:01,  3.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8243\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 15.66batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.79\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00,  9.27batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:01,  3.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8526\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  60%|██████    | 3/5 [00:00<00:00, 13.35batch/s]total loss: 0.87\n",
      "recon: 0.81\n",
      "reg: 1.67\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  9.29batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8549\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 15.05batch/s]total loss: 1.35\n",
      "recon: 1.29\n",
      "reg: 1.42\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00,  9.55batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  4.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 14.40batch/s]total loss: 1.17\n",
      "recon: 1.03\n",
      "reg: 3.66\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00,  9.44batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.96\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 14.22batch/s]total loss: 1.27\n",
      "recon: 1.29\n",
      "reg: -0.54\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  8.33batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:01,  3.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 11.43batch/s]total loss: 0.97\n",
      "recon: 0.96\n",
      "reg: 0.04\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00,  8.44batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  4.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8667\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 15.62batch/s]total loss: 0.88\n",
      "recon: 0.86\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00,  9.40batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  4.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00, 14.83batch/s]total loss: 0.92\n",
      "recon: 0.87\n",
      "reg: 1.15\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  8.39batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  4.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 16.05batch/s]total loss: 0.92\n",
      "recon: 0.84\n",
      "reg: 2.00\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00,  8.54batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:01,  3.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 14.81batch/s]total loss: 0.92\n",
      "recon: 0.94\n",
      "reg: -0.45\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  8.70batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:01,  3.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 15.50batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.89\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00, 10.21batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  4.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 14.90batch/s]total loss: 0.34\n",
      "recon: 0.53\n",
      "reg: -4.81\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00,  9.75batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7391\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 13.30batch/s]total loss: 1.03\n",
      "recon: 1.02\n",
      "reg: 0.36\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00,  8.41batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 13.31batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.50\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00,  7.01batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:01,  2.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00, 12.51batch/s]total loss: 0.78\n",
      "recon: 0.78\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  7.75batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  4.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  60%|██████    | 3/5 [00:00<00:00, 12.44batch/s]total loss: 0.60\n",
      "recon: 0.58\n",
      "reg: 0.51\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00,  8.52batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  4.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7782\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 16.08batch/s]total loss: 0.69\n",
      "recon: 0.80\n",
      "reg: -2.77\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 10.05batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  4.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 15.60batch/s]total loss: 1.01\n",
      "recon: 1.06\n",
      "reg: -1.18\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  9.49batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  4.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  60%|██████    | 3/5 [00:00<00:00, 13.42batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.50\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00,  9.23batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 14.78batch/s]total loss: 0.86\n",
      "recon: 0.70\n",
      "reg: 3.93\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00,  8.84batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:01,  3.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8203\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 12.45batch/s]total loss: 0.88\n",
      "recon: 0.95\n",
      "reg: -1.75\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  8.76batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  4.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 10.63batch/s]total loss: 0.70\n",
      "recon: 0.62\n",
      "reg: 1.82\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00,  7.30batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:01,  3.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.794\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 15.69batch/s]total loss: 0.26\n",
      "recon: 0.40\n",
      "reg: -3.61\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  7.03batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  2.36batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.6987\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 14.54batch/s]total loss: 0.59\n",
      "recon: 0.57\n",
      "reg: 0.43\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  9.41batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7719\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 13.96batch/s]total loss: 0.96\n",
      "recon: 0.99\n",
      "reg: -0.90\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00,  9.48batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8422\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 13.18batch/s]total loss: 0.66\n",
      "recon: 0.73\n",
      "reg: -1.79\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  7.43batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:01,  3.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 14.03batch/s]total loss: 1.19\n",
      "recon: 1.06\n",
      "reg: 3.29\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  9.28batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  4.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9232\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 13.23batch/s]total loss: 0.77\n",
      "recon: 0.81\n",
      "reg: -0.83\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00,  8.86batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  4.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8216\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  60%|██████    | 3/5 [00:00<00:00, 12.98batch/s]total loss: 1.34\n",
      "recon: 1.26\n",
      "reg: 1.98\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00,  8.77batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  4.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 14.33batch/s]total loss: 0.73\n",
      "recon: 0.70\n",
      "reg: 0.57\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00,  9.21batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  4.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 15.63batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.27\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  8.34batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:01,  3.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8691\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 14.30batch/s]total loss: 0.82\n",
      "recon: 0.81\n",
      "reg: 0.11\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  8.82batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:01,  3.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8416\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 15.66batch/s]total loss: 0.98\n",
      "recon: 1.08\n",
      "reg: -2.70\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00,  9.77batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  4.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8468\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 14.93batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.86\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00,  8.74batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  4.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.79\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  60%|██████    | 3/5 [00:00<00:00, 11.04batch/s]total loss: 0.56\n",
      "recon: 0.57\n",
      "reg: -0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  8.46batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  4.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 13.71batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.67\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  8.47batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:01,  3.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8143\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 13.58batch/s]total loss: 0.39\n",
      "recon: 0.38\n",
      "reg: 0.29\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00,  9.21batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  4.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7498\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 15.31batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00,  9.50batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  4.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7909\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 11.90batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.07\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00,  6.14batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:01,  2.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.83\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00, 14.09batch/s]total loss: 1.07\n",
      "recon: 1.02\n",
      "reg: 1.30\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  7.85batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:01,  3.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 12.19batch/s]total loss: 0.61\n",
      "recon: 0.64\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00,  7.81batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:01,  3.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 16.28batch/s]total loss: 0.31\n",
      "recon: 0.40\n",
      "reg: -2.21\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00,  9.87batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  4.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 14.39batch/s]total loss: 0.79\n",
      "recon: 0.64\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  9.59batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  4.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8183\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  60%|██████    | 3/5 [00:00<00:00, 12.10batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.51\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00,  8.87batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  4.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 13.99batch/s]total loss: 0.51\n",
      "recon: 0.46\n",
      "reg: 1.29\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  9.50batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 14.21batch/s]total loss: 0.76\n",
      "recon: 0.72\n",
      "reg: 0.88\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  8.43batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:01,  3.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8033\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 15.58batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.35\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  9.46batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  4.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8392\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 15.22batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.35\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  7.65batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:01,  2.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8333\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 11.94batch/s]total loss: 0.94\n",
      "recon: 0.82\n",
      "reg: 2.90\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  8.79batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 12.49batch/s]total loss: 0.71\n",
      "recon: 0.78\n",
      "reg: -1.62\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  8.71batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 14.27batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.77\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  9.21batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8986\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00, 11.93batch/s]total loss: 0.91\n",
      "recon: 0.92\n",
      "reg: -0.23\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  7.61batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8309\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 14.84batch/s]total loss: 0.65\n",
      "recon: 0.61\n",
      "reg: 0.89\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  6.34batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.04batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  60%|██████    | 3/5 [00:00<00:00, 12.44batch/s]total loss: 1.08\n",
      "recon: 0.99\n",
      "reg: 2.14\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  8.47batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  4.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8833\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 14.58batch/s]total loss: 0.63\n",
      "recon: 0.60\n",
      "reg: 0.78\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  9.30batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  4.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7938\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 14.81batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.84\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  8.40batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:01,  3.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 14.39batch/s]total loss: 0.70\n",
      "recon: 0.63\n",
      "reg: 1.61\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  9.71batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 12.13batch/s]total loss: 0.78\n",
      "recon: 0.83\n",
      "reg: -1.19\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  8.61batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8094\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 11.67batch/s]total loss: 1.65\n",
      "recon: 1.55\n",
      "reg: 2.45\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  8.27batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  4.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9859\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 14.77batch/s]total loss: 0.91\n",
      "recon: 0.89\n",
      "reg: 0.35\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  7.61batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:01,  2.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 15.04batch/s]total loss: 0.92\n",
      "recon: 0.82\n",
      "reg: 2.52\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  8.56batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:01,  3.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8423\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 14.13batch/s]total loss: 1.58\n",
      "recon: 1.54\n",
      "reg: 0.99\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00,  8.10batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:01,  3.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 13.86batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.73\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  8.87batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  4.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8236\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_23-28-25/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.114875004534, Time: 116.74s\n",
      "Epoch 200, Training Loss: 0.041040038015, Time: 231.53s\n",
      "Epoch 300, Training Loss: 0.014057180213, Time: 346.81s\n",
      "Epoch 400, Training Loss: 0.009489276013, Time: 461.18s\n",
      "Epoch 500, Training Loss: 0.005714449228, Time: 576.57s\n",
      "Epoch 600, Training Loss: 0.003244221902, Time: 699.09s\n",
      "Epoch 700, Training Loss: 0.001277019807, Time: 819.40s\n",
      "Epoch 800, Training Loss: 0.000573103592, Time: 930.56s\n",
      "Epoch 900, Training Loss: 0.000360323455, Time: 1043.66s\n",
      "Epoch 1000, Training Loss: 0.000390910856, Time: 1157.89s\n",
      "Validation Loss: 0.000205482999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00021</td></tr><tr><td>val_loss</td><td>0.00021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swept-sweep-22</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/c688ng4u' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/c688ng4u</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250325_232824-c688ng4u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w9sadwfd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.012665309609407998\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250325_234908-w9sadwfd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/w9sadwfd' target=\"_blank\">northern-sweep-23</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/w9sadwfd' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/w9sadwfd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_23-49-09. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  60%|██████    | 3/5 [00:00<00:00, 21.75batch/s]total loss: 6.57\n",
      "recon: 6.04\n",
      "reg: 13.33\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00, 13.24batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:00,  5.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 9.618\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  60%|██████    | 3/5 [00:00<00:00, 23.65batch/s]total loss: 3.78\n",
      "recon: 3.69\n",
      "reg: 2.27\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 12.28batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  5.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 4.3731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  60%|██████    | 3/5 [00:00<00:00, 23.76batch/s]total loss: 1.66\n",
      "recon: 1.47\n",
      "reg: 4.55\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00, 14.06batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  5.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 2.5129\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  60%|██████    | 3/5 [00:00<00:00, 18.57batch/s]total loss: 1.25\n",
      "recon: 1.17\n",
      "reg: 2.03\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 10.76batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  4.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.6694\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  60%|██████    | 3/5 [00:00<00:00, 21.10batch/s]total loss: 0.99\n",
      "recon: 0.93\n",
      "reg: 1.68\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00, 14.47batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  7.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2335\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 17.82batch/s]total loss: 1.15\n",
      "recon: 1.00\n",
      "reg: 3.74\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 13.00batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  7.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  60%|██████    | 3/5 [00:00<00:00, 23.25batch/s]total loss: 0.73\n",
      "recon: 0.77\n",
      "reg: -0.92\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 13.25batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  5.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9913\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 23.87batch/s]total loss: 0.72\n",
      "recon: 0.72\n",
      "reg: 0.03\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 12.70batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  5.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9148\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 23.72batch/s]total loss: 1.03\n",
      "recon: 0.89\n",
      "reg: 3.49\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 13.41batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  6.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9637\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  40%|████      | 2/5 [00:00<00:00, 15.28batch/s]total loss: 0.73\n",
      "recon: 0.63\n",
      "reg: 2.36\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00, 13.57batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  7.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8591\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  60%|██████    | 3/5 [00:00<00:00, 13.25batch/s]total loss: 0.96\n",
      "recon: 0.83\n",
      "reg: 3.26\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00,  9.92batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9028\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00, 21.53batch/s]total loss: 0.90\n",
      "recon: 0.82\n",
      "reg: 2.14\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00, 12.14batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  6.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.1281\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  60%|██████    | 3/5 [00:00<00:00, 23.83batch/s]total loss: 1.00\n",
      "recon: 0.96\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 10.11batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:01,  3.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9531\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  60%|██████    | 3/5 [00:00<00:00, 22.63batch/s]total loss: 0.54\n",
      "recon: 0.49\n",
      "reg: 1.14\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 12.88batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  5.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9048\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00, 24.57batch/s]total loss: 0.74\n",
      "recon: 0.74\n",
      "reg: -0.01\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00, 13.74batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  6.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9273\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  60%|██████    | 3/5 [00:00<00:00, 24.24batch/s]total loss: 0.88\n",
      "recon: 0.89\n",
      "reg: -0.28\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 14.79batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  6.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  60%|██████    | 3/5 [00:00<00:00, 25.93batch/s]total loss: 1.05\n",
      "recon: 0.97\n",
      "reg: 1.81\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00, 14.59batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  6.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9335\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  60%|██████    | 3/5 [00:00<00:00, 24.56batch/s]total loss: 0.82\n",
      "recon: 0.68\n",
      "reg: 3.54\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00, 13.00batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  5.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8611\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 22.98batch/s]total loss: 0.40\n",
      "recon: 0.49\n",
      "reg: -2.44\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 12.94batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  6.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7805\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  60%|██████    | 3/5 [00:00<00:00, 23.72batch/s]total loss: 0.99\n",
      "recon: 1.02\n",
      "reg: -0.85\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:01<00:00,  4.36batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  6.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8923\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  60%|██████    | 3/5 [00:00<00:00, 26.71batch/s]total loss: 1.26\n",
      "recon: 1.19\n",
      "reg: 1.64\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00,  9.63batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:01,  2.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9339\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  60%|██████    | 3/5 [00:00<00:00, 21.87batch/s]total loss: 0.57\n",
      "recon: 0.64\n",
      "reg: -1.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 14.05batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  6.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7958\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  60%|██████    | 3/5 [00:00<00:00, 21.57batch/s]total loss: 0.92\n",
      "recon: 0.88\n",
      "reg: 0.98\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00, 11.53batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  4.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8633\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  60%|██████    | 3/5 [00:00<00:00, 24.13batch/s]total loss: 1.03\n",
      "recon: 1.00\n",
      "reg: 0.64\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 11.69batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9341\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  40%|████      | 2/5 [00:00<00:00, 17.76batch/s]total loss: 0.84\n",
      "recon: 0.80\n",
      "reg: 1.13\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 13.38batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  6.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8531\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  60%|██████    | 3/5 [00:00<00:00, 24.51batch/s]total loss: 1.20\n",
      "recon: 1.06\n",
      "reg: 3.54\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 14.52batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  6.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9188\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  60%|██████    | 3/5 [00:00<00:00, 22.30batch/s]total loss: 0.97\n",
      "recon: 0.80\n",
      "reg: 4.13\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 13.91batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  6.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00, 21.13batch/s]total loss: 0.72\n",
      "recon: 0.65\n",
      "reg: 1.62\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00, 11.82batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  5.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8762\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 13.79batch/s]total loss: 0.97\n",
      "recon: 0.94\n",
      "reg: 0.74\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 10.49batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  6.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8947\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  60%|██████    | 3/5 [00:00<00:00, 22.78batch/s]total loss: 0.64\n",
      "recon: 0.58\n",
      "reg: 1.52\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00, 10.28batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  3.54batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8136\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  40%|████      | 2/5 [00:00<00:00, 14.13batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.80\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 12.57batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  6.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8989\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  60%|██████    | 3/5 [00:00<00:00, 21.62batch/s]total loss: 0.95\n",
      "recon: 0.98\n",
      "reg: -0.69\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00, 14.21batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  6.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0023\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  60%|██████    | 3/5 [00:00<00:00, 22.56batch/s]total loss: 0.68\n",
      "recon: 0.70\n",
      "reg: -0.74\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00, 14.18batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  6.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8839\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 17.79batch/s]total loss: 0.87\n",
      "recon: 0.92\n",
      "reg: -1.02\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00, 11.10batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  5.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 16.62batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.31\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00, 11.59batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  6.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9198\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  60%|██████    | 3/5 [00:00<00:00, 22.83batch/s]total loss: 0.59\n",
      "recon: 0.64\n",
      "reg: -1.16\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00, 14.23batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  6.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 20.97batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.72\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 12.00batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  6.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8328\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  60%|██████    | 3/5 [00:00<00:00, 22.44batch/s]total loss: 0.70\n",
      "recon: 0.64\n",
      "reg: 1.45\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 13.06batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  5.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  60%|██████    | 3/5 [00:00<00:00, 24.26batch/s]total loss: 0.85\n",
      "recon: 0.80\n",
      "reg: 1.47\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00, 14.37batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  6.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8568\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  40%|████      | 2/5 [00:00<00:00, 14.25batch/s]total loss: 1.34\n",
      "recon: 1.29\n",
      "reg: 1.44\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 12.94batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  7.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9474\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  60%|██████    | 3/5 [00:00<00:00, 23.76batch/s]total loss: 1.21\n",
      "recon: 1.05\n",
      "reg: 3.86\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 14.83batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  6.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9591\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 17.03batch/s]total loss: 1.30\n",
      "recon: 1.30\n",
      "reg: -0.01\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00, 11.69batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  6.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.955\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 17.36batch/s]total loss: 0.96\n",
      "recon: 0.96\n",
      "reg: 0.15\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 11.73batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  6.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8643\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  60%|██████    | 3/5 [00:00<00:00, 24.00batch/s]total loss: 0.86\n",
      "recon: 0.85\n",
      "reg: 0.35\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 11.73batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  4.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.85\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  60%|██████    | 3/5 [00:00<00:00, 23.31batch/s]total loss: 0.95\n",
      "recon: 0.91\n",
      "reg: 1.00\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00, 14.71batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  6.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8873\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 17.00batch/s]total loss: 1.00\n",
      "recon: 0.90\n",
      "reg: 2.39\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00, 12.11batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  6.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8763\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  60%|██████    | 3/5 [00:00<00:00, 23.38batch/s]total loss: 0.94\n",
      "recon: 0.95\n",
      "reg: -0.39\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 12.87batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  5.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  60%|██████    | 3/5 [00:00<00:00, 23.26batch/s]total loss: 0.99\n",
      "recon: 0.96\n",
      "reg: 0.68\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00, 13.19batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  5.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8696\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  60%|██████    | 3/5 [00:00<00:00, 22.20batch/s]total loss: 0.37\n",
      "recon: 0.57\n",
      "reg: -4.88\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 12.50batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.756\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  60%|██████    | 3/5 [00:00<00:00, 22.87batch/s]total loss: 1.05\n",
      "recon: 1.03\n",
      "reg: 0.56\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 13.93batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  6.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9286\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  60%|██████    | 3/5 [00:00<00:00, 23.55batch/s]total loss: 1.01\n",
      "recon: 0.95\n",
      "reg: 1.49\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 14.25batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  6.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  60%|██████    | 3/5 [00:00<00:00, 25.08batch/s]total loss: 0.73\n",
      "recon: 0.73\n",
      "reg: 0.11\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  9.79batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:01,  3.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8219\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 17.69batch/s]total loss: 0.63\n",
      "recon: 0.62\n",
      "reg: 0.27\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 11.96batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  5.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7857\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  60%|██████    | 3/5 [00:00<00:00, 22.68batch/s]total loss: 0.67\n",
      "recon: 0.78\n",
      "reg: -2.80\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 12.50batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  5.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7882\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 11.32batch/s]total loss: 1.01\n",
      "recon: 1.05\n",
      "reg: -1.00\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  8.82batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  6.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8625\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  60%|██████    | 3/5 [00:00<00:00, 23.72batch/s]total loss: 0.82\n",
      "recon: 0.79\n",
      "reg: 0.95\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 14.83batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  6.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8205\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 25.17batch/s]total loss: 0.92\n",
      "recon: 0.76\n",
      "reg: 3.99\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 13.27batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  6.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 14.05batch/s]total loss: 0.88\n",
      "recon: 0.94\n",
      "reg: -1.60\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  6.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8338\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 22.26batch/s]total loss: 0.73\n",
      "recon: 0.65\n",
      "reg: 2.04\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 11.94batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  5.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8135\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  60%|██████    | 3/5 [00:00<00:00, 23.30batch/s]total loss: 0.29\n",
      "recon: 0.41\n",
      "reg: -3.13\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00, 10.93batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  3.81batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7155\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 22.92batch/s]total loss: 0.57\n",
      "recon: 0.57\n",
      "reg: 0.04\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 12.33batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  5.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7851\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  60%|██████    | 3/5 [00:00<00:00, 18.21batch/s]total loss: 0.95\n",
      "recon: 0.99\n",
      "reg: -0.94\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 12.89batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  6.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8465\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  60%|██████    | 3/5 [00:00<00:00, 23.60batch/s]total loss: 0.65\n",
      "recon: 0.72\n",
      "reg: -1.85\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00, 13.85batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  6.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7768\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00, 21.64batch/s]total loss: 1.13\n",
      "recon: 1.01\n",
      "reg: 3.17\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00, 12.47batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  6.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8888\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  60%|██████    | 3/5 [00:00<00:00, 23.38batch/s]total loss: 0.76\n",
      "recon: 0.80\n",
      "reg: -0.98\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 14.63batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  6.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8045\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  60%|██████    | 3/5 [00:00<00:00, 22.61batch/s]total loss: 1.35\n",
      "recon: 1.28\n",
      "reg: 1.65\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 13.78batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  6.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9959\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 17.68batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.61\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 11.05batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  5.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9093\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  60%|██████    | 3/5 [00:00<00:00, 22.41batch/s]total loss: 0.91\n",
      "recon: 0.81\n",
      "reg: 2.62\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00, 14.32batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  6.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9013\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  60%|██████    | 3/5 [00:00<00:00, 22.41batch/s]total loss: 0.87\n",
      "recon: 0.83\n",
      "reg: 0.84\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00, 13.49batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  6.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8714\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 21.54batch/s]total loss: 0.87\n",
      "recon: 0.98\n",
      "reg: -2.71\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 12.31batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  6.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8445\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  60%|██████    | 3/5 [00:00<00:00, 24.14batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.76\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 10.40batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  6.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7994\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  60%|██████    | 3/5 [00:00<00:00, 23.12batch/s]total loss: 0.59\n",
      "recon: 0.58\n",
      "reg: 0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  9.73batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  4.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8111\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 18.97batch/s]total loss: 0.79\n",
      "recon: 0.80\n",
      "reg: -0.39\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  9.57batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:01,  3.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8246\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  60%|██████    | 3/5 [00:00<00:00, 22.55batch/s]total loss: 0.43\n",
      "recon: 0.40\n",
      "reg: 0.55\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 14.04batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  6.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  60%|██████    | 3/5 [00:00<00:00, 22.15batch/s]total loss: 0.75\n",
      "recon: 0.73\n",
      "reg: 0.48\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 14.40batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  6.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8145\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 16.72batch/s]total loss: 0.95\n",
      "recon: 0.95\n",
      "reg: -0.01\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 11.70batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  6.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8654\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  60%|██████    | 3/5 [00:00<00:00, 22.51batch/s]total loss: 1.06\n",
      "recon: 1.01\n",
      "reg: 1.35\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00, 13.60batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  5.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8969\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  60%|██████    | 3/5 [00:00<00:00, 20.95batch/s]total loss: 0.68\n",
      "recon: 0.71\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 11.40batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  4.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8474\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 15.47batch/s]total loss: 0.32\n",
      "recon: 0.42\n",
      "reg: -2.41\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 10.67batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  6.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.745\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 19.79batch/s]total loss: 0.76\n",
      "recon: 0.62\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 12.40batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  6.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.816\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  60%|██████    | 3/5 [00:00<00:00, 22.91batch/s]total loss: 0.71\n",
      "recon: 0.74\n",
      "reg: -0.67\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00,  8.09batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:01,  2.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.817\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  60%|██████    | 3/5 [00:00<00:00, 11.77batch/s]total loss: 0.52\n",
      "recon: 0.46\n",
      "reg: 1.53\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:01<00:00,  4.54batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:03,  1.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7839\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00, 22.99batch/s]total loss: 0.73\n",
      "recon: 0.69\n",
      "reg: 0.84\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  7.34batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:01,  2.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8012\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  60%|██████    | 3/5 [00:00<00:00, 22.27batch/s]total loss: 0.90\n",
      "recon: 0.88\n",
      "reg: 0.29\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00, 10.45batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:01,  3.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8352\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 22.38batch/s]total loss: 0.96\n",
      "recon: 0.88\n",
      "reg: 2.14\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 12.66batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  6.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8412\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  60%|██████    | 3/5 [00:00<00:00, 21.63batch/s]total loss: 0.93\n",
      "recon: 0.81\n",
      "reg: 2.97\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 13.35batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  5.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8484\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 15.21batch/s]total loss: 0.70\n",
      "recon: 0.78\n",
      "reg: -2.07\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 10.56batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  5.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8034\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  60%|██████    | 3/5 [00:00<00:00, 23.73batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.76\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00, 11.83batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  5.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8877\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 15.27batch/s]total loss: 0.92\n",
      "recon: 0.92\n",
      "reg: -0.03\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00, 10.15batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8281\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  60%|██████    | 3/5 [00:00<00:00, 20.42batch/s]total loss: 0.70\n",
      "recon: 0.66\n",
      "reg: 1.03\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00, 10.14batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  3.56batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7832\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  60%|██████    | 3/5 [00:00<00:00, 22.76batch/s]total loss: 1.03\n",
      "recon: 0.94\n",
      "reg: 2.21\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00, 14.54batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  6.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8713\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  60%|██████    | 3/5 [00:00<00:00, 23.02batch/s]total loss: 0.65\n",
      "recon: 0.62\n",
      "reg: 0.82\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00, 14.34batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  6.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7852\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 16.93batch/s]total loss: 0.69\n",
      "recon: 0.63\n",
      "reg: 1.59\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00, 11.49batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  5.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8002\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00, 24.77batch/s]total loss: 0.72\n",
      "recon: 0.64\n",
      "reg: 2.07\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00, 13.09batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  6.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7891\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  60%|██████    | 3/5 [00:00<00:00, 22.19batch/s]total loss: 0.74\n",
      "recon: 0.80\n",
      "reg: -1.38\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 11.81batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8048\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  60%|██████    | 3/5 [00:00<00:00, 14.95batch/s]total loss: 1.69\n",
      "recon: 1.57\n",
      "reg: 2.98\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00, 11.96batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  6.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00, 25.13batch/s]total loss: 0.86\n",
      "recon: 0.87\n",
      "reg: -0.21\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00, 13.59batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  6.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8329\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00, 23.38batch/s]total loss: 0.89\n",
      "recon: 0.78\n",
      "reg: 2.58\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00, 10.48batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  4.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8424\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  60%|██████    | 3/5 [00:00<00:00, 23.24batch/s]total loss: 1.66\n",
      "recon: 1.62\n",
      "reg: 1.08\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 11.23batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0069\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  60%|██████    | 3/5 [00:00<00:00, 23.86batch/s]total loss: 0.66\n",
      "recon: 0.64\n",
      "reg: 0.45\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00, 12.93batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  5.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8068\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-25_23-49-09/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 1.221418838575, Time: 113.48s\n",
      "Epoch 200, Training Loss: 0.491538102739, Time: 228.00s\n",
      "Epoch 300, Training Loss: 0.332566187717, Time: 340.01s\n",
      "Epoch 400, Training Loss: 0.260381536372, Time: 454.97s\n",
      "Epoch 500, Training Loss: 0.238699528901, Time: 568.14s\n",
      "Epoch 600, Training Loss: 0.214160446264, Time: 672.67s\n",
      "Epoch 700, Training Loss: 0.182535452335, Time: 778.06s\n",
      "Epoch 800, Training Loss: 0.158908702491, Time: 897.50s\n",
      "Epoch 900, Training Loss: 0.154207809153, Time: 1060.94s\n",
      "Epoch 1000, Training Loss: 0.136691391849, Time: 1243.51s\n",
      "Validation Loss: 0.177810805943\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.17781</td></tr><tr><td>val_loss</td><td>0.17781</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">northern-sweep-23</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/w9sadwfd' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/w9sadwfd</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250325_234908-w9sadwfd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8a33xfcf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0029365897740699655\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_001052-8a33xfcf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/8a33xfcf' target=\"_blank\">ruby-sweep-24</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/8a33xfcf' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/8a33xfcf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_00-10-53. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 14.20batch/s]total loss: 4.54\n",
      "recon: 4.25\n",
      "reg: 7.01\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  8.25batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:01,  3.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.4454\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 12.19batch/s]total loss: 1.09\n",
      "recon: 1.05\n",
      "reg: 1.10\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00,  7.38batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:01,  3.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.5912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 14.55batch/s]total loss: 1.23\n",
      "recon: 1.27\n",
      "reg: -1.13\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  8.48batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:01,  3.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2307\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 13.77batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.76\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00,  8.25batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:01,  3.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 12.70batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.45\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  8.32batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  4.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9394\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 11.69batch/s]total loss: 0.81\n",
      "recon: 0.71\n",
      "reg: 2.51\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00,  7.72batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:01,  3.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 14.83batch/s]total loss: 0.67\n",
      "recon: 0.70\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00,  8.95batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:01,  3.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 11.09batch/s]total loss: 0.71\n",
      "recon: 0.71\n",
      "reg: -0.09\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00,  7.07batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  4.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 12.18batch/s]total loss: 1.02\n",
      "recon: 0.89\n",
      "reg: 3.25\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  8.73batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9044\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 12.49batch/s]total loss: 0.65\n",
      "recon: 0.57\n",
      "reg: 2.05\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  8.93batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  4.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  60%|██████    | 3/5 [00:00<00:00, 12.05batch/s]total loss: 1.09\n",
      "recon: 0.94\n",
      "reg: 3.71\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00,  7.21batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:01,  2.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9274\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 12.59batch/s]total loss: 0.93\n",
      "recon: 0.85\n",
      "reg: 1.84\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  8.24batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:01,  3.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 13.22batch/s]total loss: 1.01\n",
      "recon: 0.97\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00,  8.79batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  4.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 10.38batch/s]total loss: 0.65\n",
      "recon: 0.65\n",
      "reg: -0.11\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00,  8.12batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  4.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 10.94batch/s]total loss: 0.75\n",
      "recon: 0.75\n",
      "reg: 0.04\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  6.68batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:01,  3.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8417\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 13.06batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.13\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00,  7.40batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:01,  3.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 11.23batch/s]total loss: 0.85\n",
      "recon: 0.76\n",
      "reg: 2.07\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00,  8.42batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  4.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00, 11.24batch/s]total loss: 0.74\n",
      "recon: 0.63\n",
      "reg: 2.86\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00,  6.67batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:01,  3.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8258\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 13.70batch/s]total loss: 0.37\n",
      "recon: 0.48\n",
      "reg: -2.77\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00,  7.60batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:01,  3.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 13.04batch/s]total loss: 1.04\n",
      "recon: 1.06\n",
      "reg: -0.72\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00,  9.23batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  4.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8823\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 14.34batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.33\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00,  6.49batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:01,  2.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9097\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  60%|██████    | 3/5 [00:00<00:00, 10.99batch/s]total loss: 0.53\n",
      "recon: 0.63\n",
      "reg: -2.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00,  7.11batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:01,  3.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7636\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 13.97batch/s]total loss: 0.93\n",
      "recon: 0.91\n",
      "reg: 0.48\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  6.63batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:01,  2.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8492\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 12.20batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.33\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00,  7.13batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:01,  3.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00,  8.21batch/s]total loss: 0.86\n",
      "recon: 0.82\n",
      "reg: 1.08\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00,  6.66batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:01,  3.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8431\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  60%|██████    | 3/5 [00:00<00:00, 10.03batch/s]total loss: 1.19\n",
      "recon: 1.07\n",
      "reg: 3.22\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00,  6.35batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:01,  2.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9047\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00,  9.59batch/s]total loss: 0.98\n",
      "recon: 0.80\n",
      "reg: 4.48\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00,  7.33batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  4.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 12.83batch/s]total loss: 0.76\n",
      "recon: 0.70\n",
      "reg: 1.32\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  8.14batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:01,  3.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8853\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 12.11batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.90\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00,  7.78batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:01,  3.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  60%|██████    | 3/5 [00:00<00:00, 11.53batch/s]total loss: 0.65\n",
      "recon: 0.58\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  5.58batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:02,  1.88batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  60%|██████    | 3/5 [00:00<00:00, 13.37batch/s]total loss: 1.03\n",
      "recon: 1.05\n",
      "reg: -0.60\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00,  7.93batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:01,  3.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9293\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00,  5.75batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.74\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:01<00:00,  4.22batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:01,  2.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 13.89batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.58\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  8.75batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:01,  3.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8369\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 12.30batch/s]total loss: 0.66\n",
      "recon: 0.70\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  7.67batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:01,  3.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00, 10.60batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.13\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  5.78batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:01,  3.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9186\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 10.33batch/s]total loss: 0.56\n",
      "recon: 0.63\n",
      "reg: -1.68\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:01<00:00,  4.84batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:02,  1.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  60%|██████    | 3/5 [00:00<00:00, 11.28batch/s]total loss: 0.71\n",
      "recon: 0.75\n",
      "reg: -0.86\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00,  5.39batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:02,  1.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8243\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 15.16batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.79\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00,  7.31batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:01,  2.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8526\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  60%|██████    | 3/5 [00:00<00:00,  3.98batch/s]total loss: 0.87\n",
      "recon: 0.81\n",
      "reg: 1.67\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:01<00:00,  3.35batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:01,  2.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8549\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 13.28batch/s]total loss: 1.35\n",
      "recon: 1.29\n",
      "reg: 1.42\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00,  7.44batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:01,  3.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:01<00:00,  4.32batch/s]total loss: 1.17\n",
      "recon: 1.03\n",
      "reg: 3.66\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:02<00:00,  2.45batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:01<00:04,  1.02s/batch]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.96\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:01<00:00,  1.90batch/s]total loss: 1.27\n",
      "recon: 1.29\n",
      "reg: -0.54\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:04<00:00,  1.09batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:02<00:11,  2.77s/batch]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:02<00:00,  1.36batch/s]total loss: 0.97\n",
      "recon: 0.96\n",
      "reg: 0.04\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:04<00:00,  1.05batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:02<00:08,  2.20s/batch]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8667\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00,  9.06batch/s]total loss: 0.88\n",
      "recon: 0.86\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:01<00:00,  3.44batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:03,  1.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00,  7.51batch/s]total loss: 0.92\n",
      "recon: 0.87\n",
      "reg: 1.15\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:01<00:00,  3.96batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:02,  1.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00,  9.25batch/s]total loss: 0.92\n",
      "recon: 0.84\n",
      "reg: 2.00\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:01<00:00,  4.83batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:02,  1.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 12.11batch/s]total loss: 0.92\n",
      "recon: 0.94\n",
      "reg: -0.45\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  6.02batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:01,  2.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00,  9.31batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.89\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  6.37batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:01,  3.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00,  8.09batch/s]total loss: 0.34\n",
      "recon: 0.53\n",
      "reg: -4.81\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00,  6.62batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:01,  3.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7391\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00,  7.02batch/s]total loss: 1.03\n",
      "recon: 1.02\n",
      "reg: 0.36\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00,  5.33batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:01,  2.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00,  8.20batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.50\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00,  5.16batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:01,  2.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00, 11.37batch/s]total loss: 0.78\n",
      "recon: 0.78\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:01<00:00,  4.21batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:02,  1.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00,  6.08batch/s]total loss: 0.60\n",
      "recon: 0.58\n",
      "reg: 0.51\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00,  5.19batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:01,  3.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7782\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 13.38batch/s]total loss: 0.69\n",
      "recon: 0.80\n",
      "reg: -2.77\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00,  6.86batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:01,  2.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00,  9.51batch/s]total loss: 1.01\n",
      "recon: 1.06\n",
      "reg: -1.18\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  6.42batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:01,  2.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00,  4.01batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.50\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:01<00:00,  3.87batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:01,  3.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00,  6.97batch/s]total loss: 0.86\n",
      "recon: 0.70\n",
      "reg: 3.93\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00,  5.02batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:01,  2.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8203\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 10.43batch/s]total loss: 0.88\n",
      "recon: 0.95\n",
      "reg: -1.75\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  6.98batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:01,  3.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00,  5.92batch/s]total loss: 0.70\n",
      "recon: 0.62\n",
      "reg: 1.82\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:01<00:00,  4.57batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:01,  2.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.794\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00,  7.95batch/s]total loss: 0.26\n",
      "recon: 0.40\n",
      "reg: -3.61\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:01<00:00,  3.52batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:03,  1.26batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.6987\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 14.60batch/s]total loss: 0.59\n",
      "recon: 0.57\n",
      "reg: 0.43\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  7.08batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:01,  2.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7719\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00,  6.88batch/s]total loss: 0.96\n",
      "recon: 0.99\n",
      "reg: -0.90\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:01<00:00,  4.93batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:01,  2.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8422\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00,  9.93batch/s]total loss: 0.66\n",
      "recon: 0.73\n",
      "reg: -1.79\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  6.16batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:01,  2.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00,  6.76batch/s]total loss: 1.19\n",
      "recon: 1.06\n",
      "reg: 3.29\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  5.53batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:01,  3.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9232\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00,  9.18batch/s]total loss: 0.77\n",
      "recon: 0.81\n",
      "reg: -0.83\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00,  6.15batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:01,  3.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8216\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00,  4.87batch/s]total loss: 1.34\n",
      "recon: 1.26\n",
      "reg: 1.98\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:01<00:00,  3.65batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:01,  2.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00,  8.86batch/s]total loss: 0.73\n",
      "recon: 0.70\n",
      "reg: 0.57\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00,  5.74batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:01,  2.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  9.40batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.27\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:01<00:00,  4.17batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:02,  1.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8691\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 12.98batch/s]total loss: 0.82\n",
      "recon: 0.81\n",
      "reg: 0.11\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  5.90batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:02,  1.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8416\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00,  7.53batch/s]total loss: 0.98\n",
      "recon: 1.08\n",
      "reg: -2.70\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:01<00:00,  4.92batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:01,  2.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8468\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 13.15batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.86\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00,  5.22batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:02,  1.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.79\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00,  4.76batch/s]total loss: 0.56\n",
      "recon: 0.57\n",
      "reg: -0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:01<00:00,  3.04batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:03,  1.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:07<00:00,  1.04s/batch]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.67\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:07<00:00,  1.55s/batch]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:02,  1.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8143\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:01<00:00,  3.27batch/s]total loss: 0.39\n",
      "recon: 0.38\n",
      "reg: 0.29\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:02<00:00,  2.21batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:03,  1.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7498\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  60%|██████    | 3/5 [00:00<00:00,  8.73batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00,  6.50batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:01,  3.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7909\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  60%|██████    | 3/5 [00:00<00:00, 10.96batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.07\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00,  7.27batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:01,  3.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.83\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  60%|██████    | 3/5 [00:00<00:00, 11.64batch/s]total loss: 1.07\n",
      "recon: 1.02\n",
      "reg: 1.30\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  7.48batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:01,  3.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 14.05batch/s]total loss: 0.61\n",
      "recon: 0.64\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00,  7.39batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:01,  3.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00,  8.56batch/s]total loss: 0.31\n",
      "recon: 0.40\n",
      "reg: -2.21\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00,  5.37batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:01,  2.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 12.84batch/s]total loss: 0.79\n",
      "recon: 0.64\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  7.07batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:01,  3.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8183\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 13.18batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.51\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00,  8.56batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  4.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 13.61batch/s]total loss: 0.51\n",
      "recon: 0.46\n",
      "reg: 1.29\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:01<00:00,  4.48batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:03,  1.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 10.27batch/s]total loss: 0.76\n",
      "recon: 0.72\n",
      "reg: 0.88\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:01<00:00,  4.93batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:02,  1.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8033\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  60%|██████    | 3/5 [00:00<00:00, 10.66batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.35\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  7.70batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:01,  3.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8392\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  8.47batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.35\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:01<00:00,  4.11batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:02,  1.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8333\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 14.16batch/s]total loss: 0.94\n",
      "recon: 0.82\n",
      "reg: 2.90\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  7.77batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 13.73batch/s]total loss: 0.71\n",
      "recon: 0.78\n",
      "reg: -1.62\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  7.20batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:01,  3.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00,  9.16batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.77\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  7.24batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8986\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  60%|██████    | 3/5 [00:00<00:00, 12.42batch/s]total loss: 0.91\n",
      "recon: 0.92\n",
      "reg: -0.23\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  8.17batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:01,  3.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8309\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00, 10.29batch/s]total loss: 0.65\n",
      "recon: 0.61\n",
      "reg: 0.89\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  5.50batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.41batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00,  9.79batch/s]total loss: 1.08\n",
      "recon: 0.99\n",
      "reg: 2.14\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  7.64batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  4.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8833\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00, 10.62batch/s]total loss: 0.63\n",
      "recon: 0.60\n",
      "reg: 0.78\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  5.66batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:01,  3.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7938\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 14.52batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.84\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  7.38batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:01,  3.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 10.76batch/s]total loss: 0.70\n",
      "recon: 0.63\n",
      "reg: 1.61\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  7.79batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:01,  3.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 12.17batch/s]total loss: 0.78\n",
      "recon: 0.83\n",
      "reg: -1.19\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  6.84batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:01,  3.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8094\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 13.20batch/s]total loss: 1.65\n",
      "recon: 1.55\n",
      "reg: 2.45\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  7.88batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:01,  3.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9859\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 13.21batch/s]total loss: 0.91\n",
      "recon: 0.89\n",
      "reg: 0.35\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  7.83batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:01,  3.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00,  9.97batch/s]total loss: 0.92\n",
      "recon: 0.82\n",
      "reg: 2.52\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  7.45batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8423\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 10.98batch/s]total loss: 1.58\n",
      "recon: 1.54\n",
      "reg: 0.99\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00,  7.46batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:01,  3.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 13.92batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.73\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  7.39batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:01,  3.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8236\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_00-10-53/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.114875004534, Time: 136.71s\n",
      "Epoch 200, Training Loss: 0.041040038015, Time: 254.51s\n",
      "Epoch 300, Training Loss: 0.014057180213, Time: 371.57s\n",
      "Epoch 400, Training Loss: 0.009489276013, Time: 487.39s\n",
      "Epoch 500, Training Loss: 0.005714449228, Time: 602.34s\n",
      "Epoch 600, Training Loss: 0.003244221902, Time: 718.75s\n",
      "Epoch 700, Training Loss: 0.001277019807, Time: 844.78s\n",
      "Epoch 800, Training Loss: 0.000573103592, Time: 958.93s\n",
      "Epoch 900, Training Loss: 0.000360323455, Time: 1075.09s\n",
      "Epoch 1000, Training Loss: 0.000390910856, Time: 1189.94s\n",
      "Validation Loss: 0.000205482999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00021</td></tr><tr><td>val_loss</td><td>0.00021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ruby-sweep-24</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/8a33xfcf' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/8a33xfcf</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_001052-8a33xfcf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r6xiu37w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.004090210157735514\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_003248-r6xiu37w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/r6xiu37w' target=\"_blank\">solar-sweep-25</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/r6xiu37w' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/r6xiu37w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_00-32-48. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 17.06batch/s]total loss: 4.22\n",
      "recon: 3.77\n",
      "reg: 11.31\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  9.52batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:00,  4.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 5.8681\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 18.47batch/s]total loss: 1.65\n",
      "recon: 1.54\n",
      "reg: 2.77\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 10.01batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  5.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 2.0765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  60%|██████    | 3/5 [00:00<00:00, 20.04batch/s]total loss: 1.12\n",
      "recon: 1.00\n",
      "reg: 3.06\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00, 12.98batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  6.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.3569\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 17.13batch/s]total loss: 0.75\n",
      "recon: 0.73\n",
      "reg: 0.54\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 11.37batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  5.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.3297\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  60%|██████    | 3/5 [00:00<00:00, 14.49batch/s]total loss: 0.75\n",
      "recon: 0.72\n",
      "reg: 0.86\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  9.99batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  4.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9718\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  60%|██████    | 3/5 [00:00<00:00, 20.13batch/s]total loss: 0.86\n",
      "recon: 0.67\n",
      "reg: 4.65\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 10.94batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  5.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 18.57batch/s]total loss: 0.58\n",
      "recon: 0.62\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 11.61batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  5.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8504\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 18.43batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.41\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 10.05batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:01,  3.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8605\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 16.28batch/s]total loss: 1.01\n",
      "recon: 0.83\n",
      "reg: 4.63\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  9.64batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  4.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8974\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 19.46batch/s]total loss: 0.63\n",
      "recon: 0.53\n",
      "reg: 2.50\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00, 12.35batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  5.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8088\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 15.69batch/s]total loss: 0.84\n",
      "recon: 0.68\n",
      "reg: 4.15\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 10.00batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8563\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 18.71batch/s]total loss: 0.83\n",
      "recon: 0.70\n",
      "reg: 3.16\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00, 11.52batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  5.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0289\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 19.00batch/s]total loss: 0.90\n",
      "recon: 0.87\n",
      "reg: 0.61\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 10.21batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:01,  3.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 17.90batch/s]total loss: 0.50\n",
      "recon: 0.48\n",
      "reg: 0.51\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 12.07batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  6.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8685\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 13.09batch/s]total loss: 0.73\n",
      "recon: 0.74\n",
      "reg: -0.29\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  8.78batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.945\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 19.22batch/s]total loss: 0.84\n",
      "recon: 0.88\n",
      "reg: -0.84\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 11.25batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9212\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 16.91batch/s]total loss: 1.04\n",
      "recon: 0.98\n",
      "reg: 1.45\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00, 10.85batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  5.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9489\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00, 17.43batch/s]total loss: 0.80\n",
      "recon: 0.66\n",
      "reg: 3.54\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00, 10.12batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  4.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 18.04batch/s]total loss: 0.41\n",
      "recon: 0.50\n",
      "reg: -2.36\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00,  8.48batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:01,  2.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7855\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 18.10batch/s]total loss: 1.01\n",
      "recon: 1.02\n",
      "reg: -0.26\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 11.50batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9014\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 18.52batch/s]total loss: 1.25\n",
      "recon: 1.16\n",
      "reg: 2.12\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00,  9.32batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:01,  3.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9263\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 17.23batch/s]total loss: 0.56\n",
      "recon: 0.64\n",
      "reg: -2.12\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 11.36batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  5.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.792\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 16.74batch/s]total loss: 0.90\n",
      "recon: 0.86\n",
      "reg: 0.97\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00, 11.65batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  6.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8642\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 16.74batch/s]total loss: 1.04\n",
      "recon: 1.03\n",
      "reg: 0.46\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00,  9.10batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:01,  3.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 14.30batch/s]total loss: 0.85\n",
      "recon: 0.80\n",
      "reg: 1.07\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 10.41batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  5.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8486\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 16.05batch/s]total loss: 1.23\n",
      "recon: 1.09\n",
      "reg: 3.67\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 10.87batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  5.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 18.93batch/s]total loss: 0.90\n",
      "recon: 0.72\n",
      "reg: 4.61\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 10.16batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:01,  3.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8568\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 18.89batch/s]total loss: 0.67\n",
      "recon: 0.62\n",
      "reg: 1.08\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00, 11.61batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  5.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8687\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 17.12batch/s]total loss: 0.96\n",
      "recon: 0.90\n",
      "reg: 1.38\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 11.05batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  5.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8994\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:00<00:00, 15.96batch/s]total loss: 0.66\n",
      "recon: 0.59\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  7.46batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  2.65batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.821\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 21.80batch/s]total loss: 0.99\n",
      "recon: 1.01\n",
      "reg: -0.54\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 11.72batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  5.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9282\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  60%|██████    | 3/5 [00:00<00:00, 19.13batch/s]total loss: 0.90\n",
      "recon: 0.92\n",
      "reg: -0.43\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00, 11.10batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9571\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 17.56batch/s]total loss: 0.69\n",
      "recon: 0.72\n",
      "reg: -0.65\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00, 10.17batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  4.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 14.52batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  9.90batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8364\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 18.34batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.17\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  9.86batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:01,  3.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9152\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 14.28batch/s]total loss: 0.61\n",
      "recon: 0.66\n",
      "reg: -1.35\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  9.63batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  4.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 18.11batch/s]total loss: 0.67\n",
      "recon: 0.71\n",
      "reg: -0.88\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 11.41batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  5.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8229\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 17.00batch/s]total loss: 0.75\n",
      "recon: 0.71\n",
      "reg: 1.01\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 10.80batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  5.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8788\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 11.85batch/s]total loss: 0.86\n",
      "recon: 0.79\n",
      "reg: 1.79\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  8.23batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8673\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 17.61batch/s]total loss: 1.31\n",
      "recon: 1.27\n",
      "reg: 1.05\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 10.68batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 18.72batch/s]total loss: 1.20\n",
      "recon: 1.07\n",
      "reg: 3.32\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 11.75batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  5.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9633\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  60%|██████    | 3/5 [00:00<00:00, 12.38batch/s]total loss: 1.30\n",
      "recon: 1.31\n",
      "reg: -0.36\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  9.22batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9496\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 18.29batch/s]total loss: 0.93\n",
      "recon: 0.93\n",
      "reg: 0.17\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 11.36batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  5.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 18.42batch/s]total loss: 0.94\n",
      "recon: 0.92\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 10.52batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  4.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8562\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  60%|██████    | 3/5 [00:00<00:00, 11.85batch/s]total loss: 0.93\n",
      "recon: 0.88\n",
      "reg: 1.24\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  9.56batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  5.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 16.78batch/s]total loss: 0.97\n",
      "recon: 0.88\n",
      "reg: 2.09\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00, 11.03batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  5.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8641\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 13.54batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.15\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  9.19batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  4.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8433\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 18.13batch/s]total loss: 1.01\n",
      "recon: 0.98\n",
      "reg: 0.77\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00, 11.34batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  5.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 16.23batch/s]total loss: 0.34\n",
      "recon: 0.52\n",
      "reg: -4.56\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 10.61batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  5.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 12.98batch/s]total loss: 1.08\n",
      "recon: 1.06\n",
      "reg: 0.47\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00,  8.45batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:01,  3.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9505\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 18.45batch/s]total loss: 1.03\n",
      "recon: 0.97\n",
      "reg: 1.44\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 11.21batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9209\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 18.15batch/s]total loss: 0.71\n",
      "recon: 0.72\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00, 11.70batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  5.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8215\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 16.17batch/s]total loss: 0.61\n",
      "recon: 0.59\n",
      "reg: 0.44\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00,  9.53batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  4.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.779\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 17.63batch/s]total loss: 0.64\n",
      "recon: 0.76\n",
      "reg: -2.85\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 10.89batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  4.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7735\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 21.19batch/s]total loss: 0.98\n",
      "recon: 1.03\n",
      "reg: -1.16\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 11.04batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  4.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  60%|██████    | 3/5 [00:00<00:00, 13.96batch/s]total loss: 0.81\n",
      "recon: 0.78\n",
      "reg: 0.95\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 10.01batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  5.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8081\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 16.93batch/s]total loss: 0.88\n",
      "recon: 0.72\n",
      "reg: 3.95\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 10.82batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  5.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8261\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  60%|██████    | 3/5 [00:00<00:00, 19.84batch/s]total loss: 0.86\n",
      "recon: 0.93\n",
      "reg: -1.69\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00, 11.21batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  4.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8217\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  60%|██████    | 3/5 [00:00<00:00, 15.07batch/s]total loss: 0.74\n",
      "recon: 0.65\n",
      "reg: 2.22\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 10.17batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  4.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8079\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 13.42batch/s]total loss: 0.30\n",
      "recon: 0.42\n",
      "reg: -2.93\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  7.83batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  3.16batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.714\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  60%|██████    | 3/5 [00:00<00:00, 18.69batch/s]total loss: 0.57\n",
      "recon: 0.56\n",
      "reg: 0.40\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  9.42batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:01,  3.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7736\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 18.72batch/s]total loss: 0.92\n",
      "recon: 0.96\n",
      "reg: -0.93\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 11.86batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  5.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8327\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 15.48batch/s]total loss: 0.62\n",
      "recon: 0.68\n",
      "reg: -1.56\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00, 10.35batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  5.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7675\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 15.66batch/s]total loss: 1.13\n",
      "recon: 1.00\n",
      "reg: 3.27\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  9.55batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  4.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8851\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 14.16batch/s]total loss: 0.75\n",
      "recon: 0.79\n",
      "reg: -0.97\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00,  9.78batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7985\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 18.33batch/s]total loss: 1.36\n",
      "recon: 1.28\n",
      "reg: 2.04\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 10.81batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9811\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 14.81batch/s]total loss: 0.80\n",
      "recon: 0.78\n",
      "reg: 0.62\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 10.80batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  5.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9199\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 16.92batch/s]total loss: 0.96\n",
      "recon: 0.86\n",
      "reg: 2.54\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00, 10.85batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9219\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 17.39batch/s]total loss: 0.86\n",
      "recon: 0.83\n",
      "reg: 0.78\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00, 10.52batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8767\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 14.82batch/s]total loss: 0.94\n",
      "recon: 1.05\n",
      "reg: -2.69\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00,  9.68batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 16.55batch/s]total loss: 0.60\n",
      "recon: 0.70\n",
      "reg: -2.41\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 10.95batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  5.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7882\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 14.14batch/s]total loss: 0.58\n",
      "recon: 0.57\n",
      "reg: 0.32\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  8.89batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:01,  3.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.799\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00, 10.84batch/s]total loss: 0.73\n",
      "recon: 0.74\n",
      "reg: -0.11\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  6.77batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8149\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 16.64batch/s]total loss: 0.38\n",
      "recon: 0.38\n",
      "reg: 0.15\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 10.33batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.753\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 14.51batch/s]total loss: 0.71\n",
      "recon: 0.69\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 10.63batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  5.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.795\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 16.73batch/s]total loss: 0.83\n",
      "recon: 0.84\n",
      "reg: -0.28\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 10.37batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  4.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8184\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  80%|████████  | 4/5 [00:00<00:00, 17.03batch/s]total loss: 1.08\n",
      "recon: 1.03\n",
      "reg: 1.25\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  9.76batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:01,  3.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8889\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 14.56batch/s]total loss: 0.58\n",
      "recon: 0.61\n",
      "reg: -0.67\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00,  9.72batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7991\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 18.35batch/s]total loss: 0.37\n",
      "recon: 0.47\n",
      "reg: -2.28\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 11.21batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  4.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7713\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 13.61batch/s]total loss: 0.75\n",
      "recon: 0.62\n",
      "reg: 3.28\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  8.82batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:01,  3.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8041\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 18.16batch/s]total loss: 0.73\n",
      "recon: 0.75\n",
      "reg: -0.57\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 11.32batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  5.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7942\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 15.69batch/s]total loss: 0.50\n",
      "recon: 0.45\n",
      "reg: 1.35\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00, 10.62batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  5.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 13.34batch/s]total loss: 0.76\n",
      "recon: 0.73\n",
      "reg: 0.81\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00, 10.03batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  5.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 15.58batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.12\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00, 10.64batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  5.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 17.80batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.13\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 11.06batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  5.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8398\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 17.93batch/s]total loss: 0.97\n",
      "recon: 0.86\n",
      "reg: 2.88\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 10.79batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8718\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 17.59batch/s]total loss: 0.64\n",
      "recon: 0.73\n",
      "reg: -2.26\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 10.74batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  60%|██████    | 3/5 [00:00<00:00, 13.58batch/s]total loss: 1.19\n",
      "recon: 1.11\n",
      "reg: 1.96\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  8.85batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9163\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 17.68batch/s]total loss: 0.93\n",
      "recon: 0.92\n",
      "reg: 0.26\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00, 11.48batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  5.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8425\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 17.48batch/s]total loss: 0.65\n",
      "recon: 0.60\n",
      "reg: 1.23\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  8.53batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  3.08batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7892\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  60%|██████    | 3/5 [00:00<00:00, 15.18batch/s]total loss: 1.10\n",
      "recon: 1.01\n",
      "reg: 2.28\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00, 10.22batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  5.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8862\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 15.87batch/s]total loss: 0.61\n",
      "recon: 0.58\n",
      "reg: 0.67\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00, 10.23batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7965\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 14.96batch/s]total loss: 0.78\n",
      "recon: 0.71\n",
      "reg: 1.69\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  9.29batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  4.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 15.72batch/s]total loss: 0.71\n",
      "recon: 0.65\n",
      "reg: 1.51\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00, 10.66batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  5.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 18.17batch/s]total loss: 0.81\n",
      "recon: 0.86\n",
      "reg: -1.24\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 11.16batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 15.47batch/s]total loss: 1.77\n",
      "recon: 1.65\n",
      "reg: 2.95\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00, 10.33batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  5.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 14.53batch/s]total loss: 0.87\n",
      "recon: 0.87\n",
      "reg: 0.02\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  9.93batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  4.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8254\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 16.35batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.28\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00, 11.33batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  5.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8351\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 17.87batch/s]total loss: 1.59\n",
      "recon: 1.55\n",
      "reg: 1.00\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 10.67batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9762\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 19.17batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.61\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00, 11.99batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  5.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8294\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_00-32-48/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.255701720901, Time: 122.60s\n",
      "Epoch 200, Training Loss: 0.131409470923, Time: 244.62s\n",
      "Epoch 300, Training Loss: 0.067633039749, Time: 359.07s\n",
      "Epoch 400, Training Loss: 0.039594843505, Time: 483.79s\n",
      "Epoch 500, Training Loss: 0.012818424488, Time: 603.20s\n",
      "Epoch 600, Training Loss: 0.007906403818, Time: 722.67s\n",
      "Epoch 700, Training Loss: 0.006631630821, Time: 840.16s\n",
      "Epoch 800, Training Loss: 0.003244960273, Time: 953.96s\n",
      "Epoch 900, Training Loss: 0.002754969009, Time: 1072.68s\n",
      "Epoch 1000, Training Loss: 0.002386060804, Time: 1189.67s\n",
      "Validation Loss: 0.070456305779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.07046</td></tr><tr><td>val_loss</td><td>0.07046</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-25</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/r6xiu37w' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/r6xiu37w</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_003248-r6xiu37w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8aat1i7o with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005366676279819485\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_005355-8aat1i7o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/8aat1i7o' target=\"_blank\">solar-sweep-26</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/8aat1i7o' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/8aat1i7o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_00-53-56. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 11.85batch/s]total loss: 4.54\n",
      "recon: 4.25\n",
      "reg: 7.01\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  7.70batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:01,  3.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.4454\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00,  7.33batch/s]total loss: 1.09\n",
      "recon: 1.05\n",
      "reg: 1.10\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:01<00:00,  4.83batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:01,  2.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.5912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00,  8.33batch/s]total loss: 1.23\n",
      "recon: 1.27\n",
      "reg: -1.13\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  6.67batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:01,  3.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2307\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 15.31batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.76\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00,  9.97batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00, 15.77batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.45\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  7.21batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:01,  2.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9394\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 13.40batch/s]total loss: 0.81\n",
      "recon: 0.71\n",
      "reg: 2.51\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00,  8.79batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  4.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 13.93batch/s]total loss: 0.67\n",
      "recon: 0.70\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00,  8.85batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  4.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 12.70batch/s]total loss: 0.71\n",
      "recon: 0.71\n",
      "reg: -0.09\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00,  7.70batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:01,  3.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 15.61batch/s]total loss: 1.02\n",
      "recon: 0.89\n",
      "reg: 3.25\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  9.35batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  4.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9044\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00,  9.79batch/s]total loss: 0.65\n",
      "recon: 0.57\n",
      "reg: 2.05\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  7.60batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  4.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  60%|██████    | 3/5 [00:00<00:00, 12.05batch/s]total loss: 1.09\n",
      "recon: 0.94\n",
      "reg: 3.71\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00,  7.31batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:01,  3.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9274\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 14.64batch/s]total loss: 0.93\n",
      "recon: 0.85\n",
      "reg: 1.84\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  7.25batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:01,  3.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 13.43batch/s]total loss: 1.01\n",
      "recon: 0.97\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00,  9.23batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  4.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 14.97batch/s]total loss: 0.65\n",
      "recon: 0.65\n",
      "reg: -0.11\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00,  7.82batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:01,  2.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  60%|██████    | 3/5 [00:00<00:00, 11.20batch/s]total loss: 0.75\n",
      "recon: 0.75\n",
      "reg: 0.04\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  7.79batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:01,  3.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8417\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 12.23batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.13\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00,  8.93batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 11.94batch/s]total loss: 0.85\n",
      "recon: 0.76\n",
      "reg: 2.07\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00,  6.51batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:01,  2.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00, 15.83batch/s]total loss: 0.74\n",
      "recon: 0.63\n",
      "reg: 2.86\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00,  9.43batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  4.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8258\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 15.78batch/s]total loss: 0.37\n",
      "recon: 0.48\n",
      "reg: -2.77\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00,  9.40batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  4.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 13.71batch/s]total loss: 1.04\n",
      "recon: 1.06\n",
      "reg: -0.72\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00,  9.55batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8823\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  60%|██████    | 3/5 [00:00<00:00, 12.27batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.33\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00,  8.66batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  4.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9097\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  60%|██████    | 3/5 [00:00<00:00, 12.54batch/s]total loss: 0.53\n",
      "recon: 0.63\n",
      "reg: -2.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00,  8.65batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  4.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7636\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 15.76batch/s]total loss: 0.93\n",
      "recon: 0.91\n",
      "reg: 0.48\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  8.12batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:01,  3.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8492\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  60%|██████    | 3/5 [00:00<00:00, 10.49batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.33\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00,  8.16batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  60%|██████    | 3/5 [00:00<00:00, 10.60batch/s]total loss: 0.86\n",
      "recon: 0.82\n",
      "reg: 1.08\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00,  7.47batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:01,  3.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8431\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 14.57batch/s]total loss: 1.19\n",
      "recon: 1.07\n",
      "reg: 3.22\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00,  9.34batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  4.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9047\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  60%|██████    | 3/5 [00:00<00:00, 13.38batch/s]total loss: 0.98\n",
      "recon: 0.80\n",
      "reg: 4.48\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00,  8.74batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  4.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 16.07batch/s]total loss: 0.76\n",
      "recon: 0.70\n",
      "reg: 1.32\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  9.88batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  4.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8853\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 15.99batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.90\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00,  9.46batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  4.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  60%|██████    | 3/5 [00:00<00:00, 13.43batch/s]total loss: 0.65\n",
      "recon: 0.58\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  6.98batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  2.58batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 14.13batch/s]total loss: 1.03\n",
      "recon: 1.05\n",
      "reg: -0.60\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00,  8.94batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9293\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  60%|██████    | 3/5 [00:00<00:00, 12.89batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.74\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  8.58batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 16.41batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.58\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  9.06batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:01,  3.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8369\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 15.87batch/s]total loss: 0.66\n",
      "recon: 0.70\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  8.57batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:01,  3.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  60%|██████    | 3/5 [00:00<00:00, 13.54batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.13\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  9.34batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  4.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9186\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 13.85batch/s]total loss: 0.56\n",
      "recon: 0.63\n",
      "reg: -1.68\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  9.15batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  4.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 15.10batch/s]total loss: 0.71\n",
      "recon: 0.75\n",
      "reg: -0.86\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00,  9.79batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  4.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8243\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  60%|██████    | 3/5 [00:00<00:00, 11.60batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.79\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00,  8.56batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  4.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8526\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 15.33batch/s]total loss: 0.87\n",
      "recon: 0.81\n",
      "reg: 1.67\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  9.84batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8549\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 15.64batch/s]total loss: 1.35\n",
      "recon: 1.29\n",
      "reg: 1.42\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00,  9.12batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:01,  3.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  60%|██████    | 3/5 [00:00<00:00, 11.85batch/s]total loss: 1.17\n",
      "recon: 1.03\n",
      "reg: 3.66\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00,  8.55batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  4.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.96\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 16.21batch/s]total loss: 1.27\n",
      "recon: 1.29\n",
      "reg: -0.54\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  9.70batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  4.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 12.97batch/s]total loss: 0.97\n",
      "recon: 0.96\n",
      "reg: 0.04\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00,  7.86batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:01,  3.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8667\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 15.50batch/s]total loss: 0.88\n",
      "recon: 0.86\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00,  9.45batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  4.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 14.45batch/s]total loss: 0.92\n",
      "recon: 0.87\n",
      "reg: 1.15\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  9.42batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  4.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 16.02batch/s]total loss: 0.92\n",
      "recon: 0.84\n",
      "reg: 2.00\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00,  6.63batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:01,  2.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 12.24batch/s]total loss: 0.92\n",
      "recon: 0.94\n",
      "reg: -0.45\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  8.53batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  4.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 14.93batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.89\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  9.63batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  4.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 14.88batch/s]total loss: 0.34\n",
      "recon: 0.53\n",
      "reg: -4.81\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00,  8.42batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:01,  3.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7391\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 14.21batch/s]total loss: 1.03\n",
      "recon: 1.02\n",
      "reg: 0.36\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00,  9.49batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  4.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  60%|██████    | 3/5 [00:00<00:00, 11.15batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.50\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00,  6.53batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:01,  2.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 14.85batch/s]total loss: 0.78\n",
      "recon: 0.78\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  8.37batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:01,  3.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 15.43batch/s]total loss: 0.60\n",
      "recon: 0.58\n",
      "reg: 0.51\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00,  9.51batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  4.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7782\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 15.15batch/s]total loss: 0.69\n",
      "recon: 0.80\n",
      "reg: -2.77\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00,  9.53batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  4.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 15.99batch/s]total loss: 1.01\n",
      "recon: 1.06\n",
      "reg: -1.18\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  9.00batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:01,  3.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 15.26batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.50\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00,  9.11batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:01,  3.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 15.72batch/s]total loss: 0.86\n",
      "recon: 0.70\n",
      "reg: 3.93\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00,  9.48batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  4.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8203\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 12.68batch/s]total loss: 0.88\n",
      "recon: 0.95\n",
      "reg: -1.75\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  8.37batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:01,  3.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 14.06batch/s]total loss: 0.70\n",
      "recon: 0.62\n",
      "reg: 1.82\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00,  9.20batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  4.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.794\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 14.74batch/s]total loss: 0.26\n",
      "recon: 0.40\n",
      "reg: -3.61\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  6.19batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:02,  1.96batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.6987\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 15.41batch/s]total loss: 0.59\n",
      "recon: 0.57\n",
      "reg: 0.43\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  9.80batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7719\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 14.62batch/s]total loss: 0.96\n",
      "recon: 0.99\n",
      "reg: -0.90\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00,  9.25batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  4.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8422\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 14.86batch/s]total loss: 0.66\n",
      "recon: 0.73\n",
      "reg: -1.79\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  8.34batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:01,  3.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 15.11batch/s]total loss: 1.19\n",
      "recon: 1.06\n",
      "reg: 3.29\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  9.64batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  4.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9232\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 15.01batch/s]total loss: 0.77\n",
      "recon: 0.81\n",
      "reg: -0.83\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00,  8.98batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:01,  3.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8216\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 15.08batch/s]total loss: 1.34\n",
      "recon: 1.26\n",
      "reg: 1.98\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00,  8.40batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:01,  3.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00,  7.39batch/s]total loss: 0.73\n",
      "recon: 0.70\n",
      "reg: 0.57\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00,  5.20batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:01,  2.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 15.60batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.27\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  9.69batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  4.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8691\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  60%|██████    | 3/5 [00:00<00:00, 12.32batch/s]total loss: 0.82\n",
      "recon: 0.81\n",
      "reg: 0.11\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  7.72batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:01,  3.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8416\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 14.28batch/s]total loss: 0.98\n",
      "recon: 1.08\n",
      "reg: -2.70\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00,  9.38batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  4.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8468\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 13.43batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.86\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00,  9.44batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.79\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  60%|██████    | 3/5 [00:00<00:00, 10.20batch/s]total loss: 0.56\n",
      "recon: 0.57\n",
      "reg: -0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  7.73batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 14.02batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.67\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  9.17batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  4.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8143\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 12.56batch/s]total loss: 0.39\n",
      "recon: 0.38\n",
      "reg: 0.29\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00,  7.88batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:01,  3.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7498\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 15.14batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00,  9.49batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  4.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7909\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 13.11batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.07\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00,  8.91batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.83\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  80%|████████  | 4/5 [00:00<00:00, 11.73batch/s]total loss: 1.07\n",
      "recon: 1.02\n",
      "reg: 1.30\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  8.14batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:01,  3.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 15.33batch/s]total loss: 0.61\n",
      "recon: 0.64\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00,  9.24batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  4.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 14.60batch/s]total loss: 0.31\n",
      "recon: 0.40\n",
      "reg: -2.21\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00,  9.26batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  4.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  60%|██████    | 3/5 [00:00<00:00, 12.36batch/s]total loss: 0.79\n",
      "recon: 0.64\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  8.63batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  4.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8183\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 15.38batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.51\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00,  9.61batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  4.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 16.12batch/s]total loss: 0.51\n",
      "recon: 0.46\n",
      "reg: 1.29\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  9.51batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  60%|██████    | 3/5 [00:00<00:00, 12.96batch/s]total loss: 0.76\n",
      "recon: 0.72\n",
      "reg: 0.88\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  8.66batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  4.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8033\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 13.46batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.35\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  6.89batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:01,  2.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8392\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 16.76batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.35\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  9.41batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:01,  3.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8333\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 15.34batch/s]total loss: 0.94\n",
      "recon: 0.82\n",
      "reg: 2.90\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  9.51batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 14.46batch/s]total loss: 0.71\n",
      "recon: 0.78\n",
      "reg: -1.62\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  9.31batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 15.63batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.77\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  8.84batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:01,  3.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8986\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 13.37batch/s]total loss: 0.91\n",
      "recon: 0.92\n",
      "reg: -0.23\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  9.26batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8309\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 13.66batch/s]total loss: 0.65\n",
      "recon: 0.61\n",
      "reg: 0.89\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  7.50batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.86batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 13.47batch/s]total loss: 1.08\n",
      "recon: 0.99\n",
      "reg: 2.14\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  9.35batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  4.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8833\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 14.40batch/s]total loss: 0.63\n",
      "recon: 0.60\n",
      "reg: 0.78\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  8.59batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:01,  3.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7938\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 14.22batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.84\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  8.69batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:01,  3.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 14.09batch/s]total loss: 0.70\n",
      "recon: 0.63\n",
      "reg: 1.61\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  8.23batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:01,  3.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 13.59batch/s]total loss: 0.78\n",
      "recon: 0.83\n",
      "reg: -1.19\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  9.21batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8094\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 15.45batch/s]total loss: 1.65\n",
      "recon: 1.55\n",
      "reg: 2.45\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  8.71batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:01,  3.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9859\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 14.97batch/s]total loss: 0.91\n",
      "recon: 0.89\n",
      "reg: 0.35\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  5.75batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:02,  1.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 15.67batch/s]total loss: 0.92\n",
      "recon: 0.82\n",
      "reg: 2.52\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  9.48batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  4.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8423\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  60%|██████    | 3/5 [00:00<00:00, 12.55batch/s]total loss: 1.58\n",
      "recon: 1.54\n",
      "reg: 0.99\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00,  8.50batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 13.96batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.73\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  7.60batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:01,  2.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8236\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_00-53-56/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.114875004534, Time: 115.15s\n",
      "Epoch 200, Training Loss: 0.041040038015, Time: 232.85s\n",
      "Epoch 300, Training Loss: 0.014057180213, Time: 350.89s\n",
      "Epoch 400, Training Loss: 0.009489276013, Time: 463.06s\n",
      "Epoch 500, Training Loss: 0.005714449228, Time: 567.09s\n",
      "Epoch 600, Training Loss: 0.003244221902, Time: 682.76s\n",
      "Epoch 700, Training Loss: 0.001277019807, Time: 809.94s\n",
      "Epoch 800, Training Loss: 0.000573103592, Time: 921.91s\n",
      "Epoch 900, Training Loss: 0.000360323455, Time: 1039.42s\n",
      "Epoch 1000, Training Loss: 0.000390910856, Time: 1157.89s\n",
      "Validation Loss: 0.000205482999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00021</td></tr><tr><td>val_loss</td><td>0.00021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-26</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/8aat1i7o' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/8aat1i7o</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_005355-8aat1i7o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rsh0to5r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008162908836027606\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_011445-rsh0to5r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/rsh0to5r' target=\"_blank\">dauntless-sweep-27</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/rsh0to5r' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/rsh0to5r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_01-14-46. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 14.53batch/s]total loss: 4.54\n",
      "recon: 4.25\n",
      "reg: 7.01\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  8.65batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:01,  3.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.4454\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 15.95batch/s]total loss: 1.09\n",
      "recon: 1.05\n",
      "reg: 1.10\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00,  9.19batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:01,  3.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.5912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 14.56batch/s]total loss: 1.23\n",
      "recon: 1.27\n",
      "reg: -1.13\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  8.99batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  4.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2307\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 14.95batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.76\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00,  9.83batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  60%|██████    | 3/5 [00:00<00:00, 13.90batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.45\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  9.16batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  4.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9394\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 13.87batch/s]total loss: 0.81\n",
      "recon: 0.71\n",
      "reg: 2.51\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00,  9.34batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 16.40batch/s]total loss: 0.67\n",
      "recon: 0.70\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 10.38batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  4.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 14.62batch/s]total loss: 0.71\n",
      "recon: 0.71\n",
      "reg: -0.09\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00,  9.47batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  5.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 10.80batch/s]total loss: 1.02\n",
      "recon: 0.89\n",
      "reg: 3.25\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  8.17batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  5.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9044\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 15.75batch/s]total loss: 0.65\n",
      "recon: 0.57\n",
      "reg: 2.05\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00, 10.38batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 15.17batch/s]total loss: 1.09\n",
      "recon: 0.94\n",
      "reg: 3.71\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00,  9.20batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  5.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9274\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 13.02batch/s]total loss: 0.93\n",
      "recon: 0.85\n",
      "reg: 1.84\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  8.63batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  4.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 17.06batch/s]total loss: 1.01\n",
      "recon: 0.97\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00,  9.57batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:01,  3.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 16.71batch/s]total loss: 0.65\n",
      "recon: 0.65\n",
      "reg: -0.11\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00,  9.04batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  4.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00, 13.23batch/s]total loss: 0.75\n",
      "recon: 0.75\n",
      "reg: 0.04\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  7.38batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:01,  3.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8417\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 16.87batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.13\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00,  9.99batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 13.06batch/s]total loss: 0.85\n",
      "recon: 0.76\n",
      "reg: 2.07\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00,  8.94batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  4.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  60%|██████    | 3/5 [00:00<00:00, 10.32batch/s]total loss: 0.74\n",
      "recon: 0.63\n",
      "reg: 2.86\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00,  7.80batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  4.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8258\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 16.74batch/s]total loss: 0.37\n",
      "recon: 0.48\n",
      "reg: -2.77\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00,  9.87batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  4.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 15.96batch/s]total loss: 1.04\n",
      "recon: 1.06\n",
      "reg: -0.72\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00,  9.76batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  4.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8823\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  60%|██████    | 3/5 [00:00<00:00, 12.82batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.33\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00,  7.00batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:01,  2.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9097\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 16.10batch/s]total loss: 0.53\n",
      "recon: 0.63\n",
      "reg: -2.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 10.23batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7636\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 15.05batch/s]total loss: 0.93\n",
      "recon: 0.91\n",
      "reg: 0.48\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  8.87batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:01,  3.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8492\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  60%|██████    | 3/5 [00:00<00:00, 12.30batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.33\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00,  8.17batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:01,  3.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 14.21batch/s]total loss: 0.86\n",
      "recon: 0.82\n",
      "reg: 1.08\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00,  9.57batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8431\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 13.87batch/s]total loss: 1.19\n",
      "recon: 1.07\n",
      "reg: 3.22\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00,  9.50batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9047\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  60%|██████    | 3/5 [00:00<00:00, 12.04batch/s]total loss: 0.98\n",
      "recon: 0.80\n",
      "reg: 4.48\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00,  8.85batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 13.97batch/s]total loss: 0.76\n",
      "recon: 0.70\n",
      "reg: 1.32\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  9.51batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8853\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  60%|██████    | 3/5 [00:00<00:00, 12.85batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.90\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00,  9.35batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  4.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00, 15.39batch/s]total loss: 0.65\n",
      "recon: 0.58\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  7.06batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  2.82batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 14.59batch/s]total loss: 1.03\n",
      "recon: 1.05\n",
      "reg: -0.60\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00,  9.46batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9293\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 13.50batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.74\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  9.12batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00, 15.07batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.58\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  8.18batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  4.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8369\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 15.38batch/s]total loss: 0.66\n",
      "recon: 0.70\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  9.22batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:01,  3.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 15.85batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.13\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  9.01batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:01,  3.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9186\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 16.12batch/s]total loss: 0.56\n",
      "recon: 0.63\n",
      "reg: -1.68\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  9.79batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  4.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 15.62batch/s]total loss: 0.71\n",
      "recon: 0.75\n",
      "reg: -0.86\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00,  9.18batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:01,  3.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8243\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 15.02batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.79\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00,  8.37batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:01,  3.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8526\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 12.59batch/s]total loss: 0.87\n",
      "recon: 0.81\n",
      "reg: 1.67\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  8.80batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  4.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8549\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 16.61batch/s]total loss: 1.35\n",
      "recon: 1.29\n",
      "reg: 1.42\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00,  9.27batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:01,  3.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 15.63batch/s]total loss: 1.17\n",
      "recon: 1.03\n",
      "reg: 3.66\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00,  9.94batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  4.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.96\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  60%|██████    | 3/5 [00:00<00:00, 12.24batch/s]total loss: 1.27\n",
      "recon: 1.29\n",
      "reg: -0.54\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  8.47batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  4.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 15.30batch/s]total loss: 0.97\n",
      "recon: 0.96\n",
      "reg: 0.04\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00,  9.81batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  4.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8667\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 15.46batch/s]total loss: 0.88\n",
      "recon: 0.86\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00,  9.54batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  4.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 15.27batch/s]total loss: 0.92\n",
      "recon: 0.87\n",
      "reg: 1.15\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  9.13batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:01,  3.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 14.82batch/s]total loss: 0.92\n",
      "recon: 0.84\n",
      "reg: 2.00\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00,  9.84batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  4.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 13.74batch/s]total loss: 0.92\n",
      "recon: 0.94\n",
      "reg: -0.45\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  9.37batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 14.68batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.89\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  9.36batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  4.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  60%|██████    | 3/5 [00:00<00:00, 13.35batch/s]total loss: 0.34\n",
      "recon: 0.53\n",
      "reg: -4.81\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00,  8.97batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  4.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7391\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 13.98batch/s]total loss: 1.03\n",
      "recon: 1.02\n",
      "reg: 0.36\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00,  9.59batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 15.41batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.50\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00,  9.23batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  4.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 14.62batch/s]total loss: 0.78\n",
      "recon: 0.78\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  9.45batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  4.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 14.44batch/s]total loss: 0.60\n",
      "recon: 0.58\n",
      "reg: 0.51\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00,  8.65batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:01,  3.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7782\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 15.65batch/s]total loss: 0.69\n",
      "recon: 0.80\n",
      "reg: -2.77\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 10.32batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  5.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 14.74batch/s]total loss: 1.01\n",
      "recon: 1.06\n",
      "reg: -1.18\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  9.96batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  4.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 11.43batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.50\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00,  8.51batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 14.34batch/s]total loss: 0.86\n",
      "recon: 0.70\n",
      "reg: 3.93\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00,  9.63batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  4.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8203\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 10.02batch/s]total loss: 0.88\n",
      "recon: 0.95\n",
      "reg: -1.75\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  7.13batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:01,  3.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 14.61batch/s]total loss: 0.70\n",
      "recon: 0.62\n",
      "reg: 1.82\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00,  9.39batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.794\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 13.61batch/s]total loss: 0.26\n",
      "recon: 0.40\n",
      "reg: -3.61\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  7.60batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  2.98batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.6987\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 14.88batch/s]total loss: 0.59\n",
      "recon: 0.57\n",
      "reg: 0.43\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  9.74batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7719\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 14.65batch/s]total loss: 0.96\n",
      "recon: 0.99\n",
      "reg: -0.90\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00,  8.45batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  4.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8422\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 13.73batch/s]total loss: 0.66\n",
      "recon: 0.73\n",
      "reg: -1.79\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  9.06batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 13.79batch/s]total loss: 1.19\n",
      "recon: 1.06\n",
      "reg: 3.29\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  8.39batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:01,  3.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9232\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 14.85batch/s]total loss: 0.77\n",
      "recon: 0.81\n",
      "reg: -0.83\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00,  8.92batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  4.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8216\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 15.38batch/s]total loss: 1.34\n",
      "recon: 1.26\n",
      "reg: 1.98\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00,  9.82batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  4.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 13.28batch/s]total loss: 0.73\n",
      "recon: 0.70\n",
      "reg: 0.57\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00,  8.14batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  4.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 15.16batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.27\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  9.63batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  4.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8691\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 15.48batch/s]total loss: 0.82\n",
      "recon: 0.81\n",
      "reg: 0.11\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  9.70batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8416\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  60%|██████    | 3/5 [00:00<00:00, 12.47batch/s]total loss: 0.98\n",
      "recon: 1.08\n",
      "reg: -2.70\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00,  8.44batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  4.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8468\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 16.05batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.86\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 10.13batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.79\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 14.86batch/s]total loss: 0.56\n",
      "recon: 0.57\n",
      "reg: -0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  9.69batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  4.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  60%|██████    | 3/5 [00:00<00:00, 10.84batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.67\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  7.49batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:01,  3.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8143\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 14.40batch/s]total loss: 0.39\n",
      "recon: 0.38\n",
      "reg: 0.29\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00,  9.05batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  4.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7498\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 14.20batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00,  7.00batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:01,  2.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7909\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 14.78batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.07\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00,  9.65batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  4.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.83\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  80%|████████  | 4/5 [00:00<00:00, 14.29batch/s]total loss: 1.07\n",
      "recon: 1.02\n",
      "reg: 1.30\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  9.48batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  4.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 11.55batch/s]total loss: 0.61\n",
      "recon: 0.64\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00,  8.72batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  4.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 13.19batch/s]total loss: 0.31\n",
      "recon: 0.40\n",
      "reg: -2.21\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00,  9.23batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  4.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 14.94batch/s]total loss: 0.79\n",
      "recon: 0.64\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  8.00batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:01,  3.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8183\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 14.36batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.51\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00,  9.15batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  4.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 14.41batch/s]total loss: 0.51\n",
      "recon: 0.46\n",
      "reg: 1.29\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  9.70batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 14.37batch/s]total loss: 0.76\n",
      "recon: 0.72\n",
      "reg: 0.88\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  8.79batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8033\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 13.10batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.35\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  8.96batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  4.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8392\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 15.03batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.35\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  8.77batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:01,  3.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8333\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  60%|██████    | 3/5 [00:00<00:00, 11.70batch/s]total loss: 0.94\n",
      "recon: 0.82\n",
      "reg: 2.90\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  8.30batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  60%|██████    | 3/5 [00:00<00:00, 12.01batch/s]total loss: 0.71\n",
      "recon: 0.78\n",
      "reg: -1.62\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  8.51batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 15.46batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.77\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  7.72batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:01,  3.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8986\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 14.53batch/s]total loss: 0.91\n",
      "recon: 0.92\n",
      "reg: -0.23\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  9.14batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8309\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 13.36batch/s]total loss: 0.65\n",
      "recon: 0.61\n",
      "reg: 0.89\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  7.00batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.61batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 13.85batch/s]total loss: 1.08\n",
      "recon: 0.99\n",
      "reg: 2.14\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  7.93batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:01,  3.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8833\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 16.03batch/s]total loss: 0.63\n",
      "recon: 0.60\n",
      "reg: 0.78\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  8.89batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:01,  3.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7938\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 15.17batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.84\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  9.81batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 13.86batch/s]total loss: 0.70\n",
      "recon: 0.63\n",
      "reg: 1.61\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  8.47batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 14.75batch/s]total loss: 0.78\n",
      "recon: 0.83\n",
      "reg: -1.19\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  9.76batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8094\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 14.65batch/s]total loss: 1.65\n",
      "recon: 1.55\n",
      "reg: 2.45\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  9.64batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  4.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9859\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  60%|██████    | 3/5 [00:00<00:00, 11.23batch/s]total loss: 0.91\n",
      "recon: 0.89\n",
      "reg: 0.35\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  8.45batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 13.34batch/s]total loss: 0.92\n",
      "recon: 0.82\n",
      "reg: 2.52\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  8.78batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  4.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8423\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 13.56batch/s]total loss: 1.58\n",
      "recon: 1.54\n",
      "reg: 0.99\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00,  8.66batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 14.13batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.73\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  9.53batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  4.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8236\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_01-14-46/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.114875004534, Time: 118.62s\n",
      "Epoch 200, Training Loss: 0.041040038015, Time: 233.69s\n",
      "Epoch 300, Training Loss: 0.014057180213, Time: 348.23s\n",
      "Epoch 400, Training Loss: 0.009489276013, Time: 488.99s\n",
      "Epoch 500, Training Loss: 0.005714449228, Time: 631.01s\n",
      "Epoch 600, Training Loss: 0.003244221902, Time: 768.93s\n",
      "Epoch 700, Training Loss: 0.001277019807, Time: 887.99s\n",
      "Epoch 800, Training Loss: 0.000573103592, Time: 1004.75s\n",
      "Epoch 900, Training Loss: 0.000360323455, Time: 1120.22s\n",
      "Epoch 1000, Training Loss: 0.000390910856, Time: 1236.46s\n",
      "Validation Loss: 0.000205482999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00021</td></tr><tr><td>val_loss</td><td>0.00021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dauntless-sweep-27</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/rsh0to5r' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/rsh0to5r</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_011445-rsh0to5r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: afxm4fjn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004491534224389996\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_013644-afxm4fjn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/afxm4fjn' target=\"_blank\">expert-sweep-28</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/afxm4fjn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/afxm4fjn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_01-36-45. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  60%|██████    | 3/5 [00:00<00:00, 29.17batch/s]total loss: 10.68\n",
      "recon: 10.29\n",
      "reg: 9.64\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00, 16.79batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:00,  6.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 14.587\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 33.25batch/s]total loss: 1.81\n",
      "recon: 1.66\n",
      "reg: 3.67\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 18.40batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  7.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 4.3559\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 31.19batch/s]total loss: 1.43\n",
      "recon: 1.37\n",
      "reg: 1.33\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00, 15.24batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  5.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 2.1836\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  60%|██████    | 3/5 [00:00<00:00, 17.78batch/s]total loss: 0.98\n",
      "recon: 0.97\n",
      "reg: 0.15\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 11.48batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  5.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.281\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 30.54batch/s]total loss: 0.96\n",
      "recon: 0.93\n",
      "reg: 0.76\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00, 18.14batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  7.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.1513\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 30.28batch/s]total loss: 1.10\n",
      "recon: 0.95\n",
      "reg: 3.96\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 15.97batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  6.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0559\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  40%|████      | 2/5 [00:00<00:00, 18.39batch/s]total loss: 0.70\n",
      "recon: 0.70\n",
      "reg: -0.18\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 16.04batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  7.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9547\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 32.74batch/s]total loss: 0.68\n",
      "recon: 0.68\n",
      "reg: 0.02\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 17.92batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  7.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.888\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  60%|██████    | 3/5 [00:00<00:00, 23.73batch/s]total loss: 1.00\n",
      "recon: 0.87\n",
      "reg: 3.23\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 16.10batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  7.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.926\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 33.34batch/s]total loss: 0.71\n",
      "recon: 0.59\n",
      "reg: 2.96\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00, 18.52batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  7.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8582\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  60%|██████    | 3/5 [00:00<00:00, 24.90batch/s]total loss: 1.04\n",
      "recon: 0.91\n",
      "reg: 3.23\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 16.43batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  7.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9196\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 32.90batch/s]total loss: 0.74\n",
      "recon: 0.67\n",
      "reg: 1.76\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00, 18.81batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  7.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8989\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 30.82batch/s]total loss: 1.07\n",
      "recon: 1.02\n",
      "reg: 1.14\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 17.45batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  7.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9401\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  40%|████      | 2/5 [00:00<00:00, 17.51batch/s]total loss: 0.50\n",
      "recon: 0.47\n",
      "reg: 0.73\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 15.47batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  7.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 32.96batch/s]total loss: 0.81\n",
      "recon: 0.81\n",
      "reg: 0.09\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00, 17.49batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  6.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 32.50batch/s]total loss: 0.81\n",
      "recon: 0.85\n",
      "reg: -1.19\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 15.87batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  5.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8469\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  60%|██████    | 3/5 [00:00<00:00, 29.72batch/s]total loss: 0.85\n",
      "recon: 0.79\n",
      "reg: 1.63\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00, 12.96batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  4.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8591\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  40%|████      | 2/5 [00:00<00:00, 11.04batch/s]total loss: 0.80\n",
      "recon: 0.69\n",
      "reg: 2.74\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00, 12.36batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  6.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8467\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 33.41batch/s]total loss: 0.37\n",
      "recon: 0.49\n",
      "reg: -3.06\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 18.21batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  7.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7666\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  60%|██████    | 3/5 [00:00<00:00, 26.38batch/s]total loss: 0.99\n",
      "recon: 1.01\n",
      "reg: -0.50\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 14.92batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8835\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  60%|██████    | 3/5 [00:00<00:00, 28.44batch/s]total loss: 1.25\n",
      "recon: 1.19\n",
      "reg: 1.58\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 17.83batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  7.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9202\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  60%|██████    | 3/5 [00:00<00:00, 17.64batch/s]total loss: 0.53\n",
      "recon: 0.62\n",
      "reg: -2.33\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 13.58batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  6.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.773\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 31.68batch/s]total loss: 0.92\n",
      "recon: 0.89\n",
      "reg: 0.92\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00, 18.07batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  7.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8541\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 30.50batch/s]total loss: 0.99\n",
      "recon: 0.98\n",
      "reg: 0.19\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 12.80batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  60%|██████    | 3/5 [00:00<00:00, 29.52batch/s]total loss: 0.87\n",
      "recon: 0.82\n",
      "reg: 1.31\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 17.26batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  7.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8676\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 31.69batch/s]total loss: 1.24\n",
      "recon: 1.12\n",
      "reg: 2.83\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 17.93batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  7.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9319\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  60%|██████    | 3/5 [00:00<00:00, 28.92batch/s]total loss: 0.98\n",
      "recon: 0.78\n",
      "reg: 4.93\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 17.25batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  7.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8699\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  40%|████      | 2/5 [00:00<00:00, 16.73batch/s]total loss: 0.57\n",
      "recon: 0.54\n",
      "reg: 0.82\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00, 14.34batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  6.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7777\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  60%|██████    | 3/5 [00:00<00:00, 27.51batch/s]total loss: 0.88\n",
      "recon: 0.85\n",
      "reg: 0.70\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 17.68batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  8.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8523\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  60%|██████    | 3/5 [00:00<00:00, 24.17batch/s]total loss: 0.63\n",
      "recon: 0.57\n",
      "reg: 1.70\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00, 11.71batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  3.91batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7978\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 33.57batch/s]total loss: 0.92\n",
      "recon: 0.95\n",
      "reg: -0.79\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 15.49batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  6.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8749\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  60%|██████    | 3/5 [00:00<00:00, 27.48batch/s]total loss: 0.83\n",
      "recon: 0.87\n",
      "reg: -1.09\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00, 16.35batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  6.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9191\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 26.23batch/s]total loss: 0.67\n",
      "recon: 0.70\n",
      "reg: -0.63\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00, 14.59batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  6.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 27.04batch/s]total loss: 0.61\n",
      "recon: 0.66\n",
      "reg: -1.19\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00, 14.97batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  5.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8027\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  60%|██████    | 3/5 [00:00<00:00, 25.98batch/s]total loss: 1.26\n",
      "recon: 1.22\n",
      "reg: 0.91\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00, 16.88batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  7.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9166\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  60%|██████    | 3/5 [00:00<00:00, 29.19batch/s]total loss: 0.62\n",
      "recon: 0.67\n",
      "reg: -1.30\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00, 13.51batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  4.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8362\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  60%|██████    | 3/5 [00:00<00:00, 27.47batch/s]total loss: 0.79\n",
      "recon: 0.83\n",
      "reg: -1.06\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 16.94batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  7.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8492\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  40%|████      | 2/5 [00:00<00:00, 16.31batch/s]total loss: 0.64\n",
      "recon: 0.59\n",
      "reg: 1.31\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 13.26batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  5.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8305\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 31.25batch/s]total loss: 0.90\n",
      "recon: 0.84\n",
      "reg: 1.48\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00, 12.94batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  4.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8532\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  60%|██████    | 3/5 [00:00<00:00, 14.50batch/s]total loss: 1.37\n",
      "recon: 1.33\n",
      "reg: 0.99\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 11.50batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  5.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9311\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 32.20batch/s]total loss: 1.17\n",
      "recon: 1.01\n",
      "reg: 3.94\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 15.00batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  5.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9472\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 30.74batch/s]total loss: 1.28\n",
      "recon: 1.30\n",
      "reg: -0.58\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00, 16.65batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  6.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9291\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  60%|██████    | 3/5 [00:00<00:00, 27.77batch/s]total loss: 1.00\n",
      "recon: 1.01\n",
      "reg: -0.25\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 17.36batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  7.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8695\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 30.79batch/s]total loss: 0.79\n",
      "recon: 0.80\n",
      "reg: -0.41\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 14.00batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8289\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  60%|██████    | 3/5 [00:00<00:00, 26.91batch/s]total loss: 0.90\n",
      "recon: 0.87\n",
      "reg: 0.84\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00, 16.26batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  6.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8466\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 32.26batch/s]total loss: 0.92\n",
      "recon: 0.84\n",
      "reg: 1.99\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00, 17.43batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  6.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8399\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 28.22batch/s]total loss: 0.91\n",
      "recon: 0.94\n",
      "reg: -0.58\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 16.74batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  7.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8344\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  40%|████      | 2/5 [00:00<00:00, 17.09batch/s]total loss: 0.96\n",
      "recon: 0.95\n",
      "reg: 0.26\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00, 14.37batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  6.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8498\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  60%|██████    | 3/5 [00:00<00:00, 26.82batch/s]total loss: 0.34\n",
      "recon: 0.56\n",
      "reg: -5.42\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 16.16batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  6.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7382\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 24.00batch/s]total loss: 1.05\n",
      "recon: 1.05\n",
      "reg: -0.09\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 13.97batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  7.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9303\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 18.00batch/s]total loss: 1.06\n",
      "recon: 1.00\n",
      "reg: 1.48\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 11.97batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  7.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9209\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 32.69batch/s]total loss: 0.70\n",
      "recon: 0.72\n",
      "reg: -0.33\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00, 18.19batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  7.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8112\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  60%|██████    | 3/5 [00:00<00:00, 29.28batch/s]total loss: 0.58\n",
      "recon: 0.58\n",
      "reg: 0.05\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 13.83batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  5.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7704\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  40%|████      | 2/5 [00:00<00:00, 15.84batch/s]total loss: 0.61\n",
      "recon: 0.74\n",
      "reg: -3.17\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 14.84batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  7.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.767\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 30.38batch/s]total loss: 1.02\n",
      "recon: 1.07\n",
      "reg: -1.20\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 17.82batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  7.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8645\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 25.80batch/s]total loss: 0.82\n",
      "recon: 0.79\n",
      "reg: 0.60\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 15.65batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  7.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 33.45batch/s]total loss: 0.85\n",
      "recon: 0.71\n",
      "reg: 3.38\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 15.45batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  5.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8181\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  60%|██████    | 3/5 [00:00<00:00, 29.55batch/s]total loss: 0.85\n",
      "recon: 0.93\n",
      "reg: -1.81\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00, 16.05batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  6.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8208\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 32.21batch/s]total loss: 0.72\n",
      "recon: 0.64\n",
      "reg: 1.81\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 18.25batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  7.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7995\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  60%|██████    | 3/5 [00:00<00:00, 28.41batch/s]total loss: 0.28\n",
      "recon: 0.42\n",
      "reg: -3.61\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00, 10.57batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  3.15batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7071\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 24.85batch/s]total loss: 0.54\n",
      "recon: 0.53\n",
      "reg: 0.36\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 14.98batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  6.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7603\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 34.13batch/s]total loss: 0.90\n",
      "recon: 0.95\n",
      "reg: -1.17\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 19.11batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  7.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8232\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  40%|████      | 2/5 [00:00<00:00, 17.01batch/s]total loss: 0.63\n",
      "recon: 0.70\n",
      "reg: -1.94\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00, 14.07batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  6.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7622\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 30.91batch/s]total loss: 1.12\n",
      "recon: 1.00\n",
      "reg: 2.81\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00, 18.15batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  7.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8845\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 32.16batch/s]total loss: 0.82\n",
      "recon: 0.86\n",
      "reg: -1.01\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 17.08batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  6.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.816\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  40%|████      | 2/5 [00:00<00:00, 16.30batch/s]total loss: 1.32\n",
      "recon: 1.26\n",
      "reg: 1.62\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 14.00batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  7.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.957\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  60%|██████    | 3/5 [00:00<00:00, 26.14batch/s]total loss: 0.71\n",
      "recon: 0.71\n",
      "reg: 0.11\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 16.98batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  7.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8302\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  60%|██████    | 3/5 [00:00<00:00, 12.36batch/s]total loss: 0.85\n",
      "recon: 0.77\n",
      "reg: 1.92\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00, 11.52batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  7.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8609\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  60%|██████    | 3/5 [00:00<00:00, 24.51batch/s]total loss: 0.84\n",
      "recon: 0.82\n",
      "reg: 0.53\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00, 17.00batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  7.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8473\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 31.37batch/s]total loss: 0.85\n",
      "recon: 0.98\n",
      "reg: -3.13\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 16.98batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  6.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8251\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 32.13batch/s]total loss: 0.59\n",
      "recon: 0.69\n",
      "reg: -2.65\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 17.92batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  7.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7945\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  40%|████      | 2/5 [00:00<00:00, 19.22batch/s]total loss: 0.59\n",
      "recon: 0.60\n",
      "reg: -0.17\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00, 15.13batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  7.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8107\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 32.40batch/s]total loss: 0.79\n",
      "recon: 0.79\n",
      "reg: -0.02\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00, 17.80batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  7.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8275\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 34.36batch/s]total loss: 0.38\n",
      "recon: 0.37\n",
      "reg: 0.19\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 17.29batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  6.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7411\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  60%|██████    | 3/5 [00:00<00:00, 29.51batch/s]total loss: 0.75\n",
      "recon: 0.73\n",
      "reg: 0.61\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 17.63batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  7.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8221\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 34.28batch/s]total loss: 1.01\n",
      "recon: 1.04\n",
      "reg: -0.56\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 18.84batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  7.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8817\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  40%|████      | 2/5 [00:00<00:00, 19.97batch/s]total loss: 1.03\n",
      "recon: 0.99\n",
      "reg: 1.00\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00, 16.33batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  7.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8817\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  40%|████      | 2/5 [00:00<00:00, 16.32batch/s]total loss: 0.59\n",
      "recon: 0.62\n",
      "reg: -0.89\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 15.16batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  7.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7979\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  60%|██████    | 3/5 [00:00<00:00, 25.56batch/s]total loss: 0.28\n",
      "recon: 0.39\n",
      "reg: -2.69\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 15.32batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  7.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  40%|████      | 2/5 [00:00<00:00, 19.69batch/s]total loss: 0.76\n",
      "recon: 0.62\n",
      "reg: 3.57\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 15.84batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  7.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7955\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  60%|██████    | 3/5 [00:00<00:00, 27.97batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.55\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 16.78batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  7.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7962\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  60%|██████    | 3/5 [00:00<00:00, 29.19batch/s]total loss: 0.48\n",
      "recon: 0.42\n",
      "reg: 1.39\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00, 12.35batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  6.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7641\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  60%|██████    | 3/5 [00:00<00:00, 28.93batch/s]total loss: 0.75\n",
      "recon: 0.72\n",
      "reg: 0.81\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00, 16.25batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  6.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8015\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  60%|██████    | 3/5 [00:00<00:00, 23.46batch/s]total loss: 0.89\n",
      "recon: 0.89\n",
      "reg: 0.15\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00, 15.46batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  7.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8336\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  60%|██████    | 3/5 [00:00<00:00, 25.03batch/s]total loss: 0.95\n",
      "recon: 0.86\n",
      "reg: 2.20\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 16.27batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  7.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8382\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  60%|██████    | 3/5 [00:00<00:00, 27.09batch/s]total loss: 0.91\n",
      "recon: 0.80\n",
      "reg: 2.64\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 16.75batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  7.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8474\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  40%|████      | 2/5 [00:00<00:00, 16.72batch/s]total loss: 0.75\n",
      "recon: 0.85\n",
      "reg: -2.40\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 14.96batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  7.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8177\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  60%|██████    | 3/5 [00:00<00:00, 25.64batch/s]total loss: 1.08\n",
      "recon: 1.03\n",
      "reg: 1.21\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00, 16.77batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  7.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8592\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 33.80batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.15\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00, 18.27batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  7.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  40%|████      | 2/5 [00:00<00:00, 15.95batch/s]total loss: 0.69\n",
      "recon: 0.65\n",
      "reg: 0.79\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00, 10.98batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  3.97batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7746\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 34.25batch/s]total loss: 1.04\n",
      "recon: 0.96\n",
      "reg: 2.03\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00, 17.64batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  7.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  60%|██████    | 3/5 [00:00<00:00, 26.14batch/s]total loss: 0.63\n",
      "recon: 0.61\n",
      "reg: 0.57\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00, 16.91batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  7.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7729\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  60%|██████    | 3/5 [00:00<00:00, 27.69batch/s]total loss: 0.70\n",
      "recon: 0.64\n",
      "reg: 1.49\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00, 15.78batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  6.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7941\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 32.05batch/s]total loss: 0.69\n",
      "recon: 0.63\n",
      "reg: 1.40\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00, 18.26batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  7.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7756\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 31.06batch/s]total loss: 0.77\n",
      "recon: 0.82\n",
      "reg: -1.41\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 14.22batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8002\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  60%|██████    | 3/5 [00:00<00:00, 29.11batch/s]total loss: 1.74\n",
      "recon: 1.64\n",
      "reg: 2.46\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:01<00:00,  4.72batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:03,  1.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0071\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  40%|████      | 2/5 [00:00<00:00, 14.83batch/s]total loss: 0.86\n",
      "recon: 0.87\n",
      "reg: -0.26\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  9.90batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:01,  3.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8181\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  60%|██████    | 3/5 [00:00<00:00, 29.66batch/s]total loss: 0.89\n",
      "recon: 0.78\n",
      "reg: 2.56\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00, 17.23batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  7.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8297\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 15.81batch/s]total loss: 1.65\n",
      "recon: 1.62\n",
      "reg: 0.78\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00,  9.82batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  7.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9872\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  60%|██████    | 3/5 [00:00<00:00, 29.86batch/s]total loss: 0.66\n",
      "recon: 0.64\n",
      "reg: 0.49\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00, 10.24batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:01,  2.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7996\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_01-36-45/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.358929626271, Time: 116.46s\n",
      "Epoch 200, Training Loss: 0.109649273718, Time: 236.71s\n",
      "Epoch 300, Training Loss: 0.048237692539, Time: 359.66s\n",
      "Epoch 400, Training Loss: 0.021307321165, Time: 474.88s\n",
      "Epoch 500, Training Loss: 0.010868165304, Time: 587.58s\n",
      "Epoch 600, Training Loss: 0.008812890380, Time: 699.25s\n",
      "Epoch 700, Training Loss: 0.007541957484, Time: 816.49s\n",
      "Epoch 800, Training Loss: 0.007115037540, Time: 932.17s\n",
      "Epoch 900, Training Loss: 0.007000839559, Time: 1049.12s\n",
      "Epoch 1000, Training Loss: 0.005836906686, Time: 1163.09s\n",
      "Validation Loss: 0.091519073325\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.09152</td></tr><tr><td>val_loss</td><td>0.09152</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">expert-sweep-28</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/afxm4fjn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/afxm4fjn</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_013644-afxm4fjn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1xby2m18 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005597268853500271\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_015658-1xby2m18</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/1xby2m18' target=\"_blank\">revived-sweep-29</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/1xby2m18' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/1xby2m18</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_01-56-59. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 16.20batch/s]total loss: 3.52\n",
      "recon: 3.39\n",
      "reg: 3.22\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  9.29batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:01,  3.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.113\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  60%|██████    | 3/5 [00:00<00:00, 14.88batch/s]total loss: 1.41\n",
      "recon: 1.43\n",
      "reg: -0.39\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 10.04batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  5.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.7152\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00, 11.91batch/s]total loss: 1.46\n",
      "recon: 1.47\n",
      "reg: -0.20\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  7.48batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  4.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.4075\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 11.49batch/s]total loss: 0.78\n",
      "recon: 0.80\n",
      "reg: -0.54\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00,  8.87batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.136\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 17.61batch/s]total loss: 0.92\n",
      "recon: 0.93\n",
      "reg: -0.17\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  9.83batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  4.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.1085\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 16.67batch/s]total loss: 0.87\n",
      "recon: 0.76\n",
      "reg: 2.82\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 10.36batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  4.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9488\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 13.67batch/s]total loss: 0.59\n",
      "recon: 0.64\n",
      "reg: -1.16\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00,  8.80batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  4.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 16.88batch/s]total loss: 0.66\n",
      "recon: 0.68\n",
      "reg: -0.56\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 10.32batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 15.62batch/s]total loss: 1.02\n",
      "recon: 0.87\n",
      "reg: 3.73\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  9.57batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  4.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8897\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 17.38batch/s]total loss: 0.64\n",
      "recon: 0.55\n",
      "reg: 2.41\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  8.91batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:01,  3.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8002\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 17.00batch/s]total loss: 0.88\n",
      "recon: 0.74\n",
      "reg: 3.43\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00,  9.70batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:01,  3.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8524\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 13.28batch/s]total loss: 0.79\n",
      "recon: 0.73\n",
      "reg: 1.45\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  9.09batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  4.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9133\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 17.63batch/s]total loss: 0.97\n",
      "recon: 0.95\n",
      "reg: 0.65\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 10.55batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 17.13batch/s]total loss: 0.62\n",
      "recon: 0.60\n",
      "reg: 0.54\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 10.44batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  4.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8548\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 16.93batch/s]total loss: 0.69\n",
      "recon: 0.71\n",
      "reg: -0.62\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  9.28batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  4.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8112\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 13.06batch/s]total loss: 0.90\n",
      "recon: 0.96\n",
      "reg: -1.63\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00,  9.20batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8893\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 17.18batch/s]total loss: 0.85\n",
      "recon: 0.80\n",
      "reg: 1.14\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00, 10.52batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8653\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00, 15.60batch/s]total loss: 0.74\n",
      "recon: 0.62\n",
      "reg: 2.75\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00, 10.28batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8074\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 16.94batch/s]total loss: 0.36\n",
      "recon: 0.47\n",
      "reg: -2.62\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 10.91batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  5.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7452\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 15.42batch/s]total loss: 0.96\n",
      "recon: 1.00\n",
      "reg: -1.08\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 10.11batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.86\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 15.25batch/s]total loss: 1.20\n",
      "recon: 1.17\n",
      "reg: 0.90\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 10.19batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9011\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  60%|██████    | 3/5 [00:00<00:00, 13.48batch/s]total loss: 0.50\n",
      "recon: 0.61\n",
      "reg: -2.59\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00,  9.26batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7565\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 16.41batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.48\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  9.08batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:01,  3.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8462\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 14.92batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.40\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 10.01batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.894\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 14.57batch/s]total loss: 0.85\n",
      "recon: 0.79\n",
      "reg: 1.35\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00,  9.11batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  4.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8311\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  60%|██████    | 3/5 [00:00<00:00,  7.49batch/s]total loss: 1.19\n",
      "recon: 1.06\n",
      "reg: 3.29\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00,  7.29batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  4.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8946\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 15.81batch/s]total loss: 0.90\n",
      "recon: 0.74\n",
      "reg: 4.08\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 10.39batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 15.66batch/s]total loss: 0.70\n",
      "recon: 0.66\n",
      "reg: 1.00\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  9.22batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  4.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.864\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 15.86batch/s]total loss: 0.93\n",
      "recon: 0.91\n",
      "reg: 0.55\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 10.65batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  5.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8697\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  60%|██████    | 3/5 [00:00<00:00, 10.22batch/s]total loss: 0.62\n",
      "recon: 0.55\n",
      "reg: 1.61\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  6.97batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  3.12batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7933\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 16.91batch/s]total loss: 0.85\n",
      "recon: 0.89\n",
      "reg: -0.90\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00,  9.40batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8734\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  60%|██████    | 3/5 [00:00<00:00, 12.07batch/s]total loss: 0.93\n",
      "recon: 0.95\n",
      "reg: -0.59\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  8.83batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9791\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 17.36batch/s]total loss: 0.68\n",
      "recon: 0.70\n",
      "reg: -0.66\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00, 10.00batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  4.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8666\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 11.97batch/s]total loss: 0.86\n",
      "recon: 0.90\n",
      "reg: -0.86\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  8.63batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  4.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8538\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 17.64batch/s]total loss: 1.25\n",
      "recon: 1.21\n",
      "reg: 1.00\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  8.27batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:01,  2.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9208\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 16.17batch/s]total loss: 0.55\n",
      "recon: 0.63\n",
      "reg: -1.82\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00, 10.53batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7856\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  60%|██████    | 3/5 [00:00<00:00, 13.95batch/s]total loss: 0.66\n",
      "recon: 0.71\n",
      "reg: -1.30\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00,  9.33batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  4.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.81\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 17.88batch/s]total loss: 0.75\n",
      "recon: 0.69\n",
      "reg: 1.47\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 10.57batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  4.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8649\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 15.59batch/s]total loss: 0.86\n",
      "recon: 0.78\n",
      "reg: 1.90\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  9.71batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  4.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8641\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  60%|██████    | 3/5 [00:00<00:00, 13.65batch/s]total loss: 1.33\n",
      "recon: 1.26\n",
      "reg: 1.57\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00,  9.55batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9361\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 17.03batch/s]total loss: 1.17\n",
      "recon: 1.01\n",
      "reg: 4.03\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 10.12batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  4.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9425\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 18.09batch/s]total loss: 1.31\n",
      "recon: 1.33\n",
      "reg: -0.67\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00, 10.70batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  4.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.946\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 15.27batch/s]total loss: 0.94\n",
      "recon: 0.93\n",
      "reg: 0.32\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00,  9.40batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  4.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8463\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 14.38batch/s]total loss: 0.85\n",
      "recon: 0.86\n",
      "reg: -0.18\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00,  8.83batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:01,  3.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8288\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 16.50batch/s]total loss: 0.98\n",
      "recon: 0.93\n",
      "reg: 1.41\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  9.70batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  4.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9344\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 15.99batch/s]total loss: 1.01\n",
      "recon: 0.91\n",
      "reg: 2.51\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00,  8.07batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:01,  2.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8881\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 15.87batch/s]total loss: 0.94\n",
      "recon: 0.95\n",
      "reg: -0.25\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 10.16batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8579\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 16.03batch/s]total loss: 1.01\n",
      "recon: 0.98\n",
      "reg: 0.76\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  8.81batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:01,  3.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8695\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 14.33batch/s]total loss: 0.32\n",
      "recon: 0.53\n",
      "reg: -5.03\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00,  9.78batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7364\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 16.94batch/s]total loss: 1.04\n",
      "recon: 1.04\n",
      "reg: -0.04\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 10.65batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9178\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 16.73batch/s]total loss: 0.97\n",
      "recon: 0.91\n",
      "reg: 1.45\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00,  9.47batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:01,  3.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8954\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 14.83batch/s]total loss: 0.76\n",
      "recon: 0.76\n",
      "reg: -0.08\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  9.89batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8197\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 15.37batch/s]total loss: 0.57\n",
      "recon: 0.57\n",
      "reg: -0.05\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 10.25batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7725\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 12.11batch/s]total loss: 0.68\n",
      "recon: 0.79\n",
      "reg: -2.69\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00,  7.41batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  4.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 16.21batch/s]total loss: 0.97\n",
      "recon: 1.02\n",
      "reg: -1.22\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 10.43batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8524\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 15.41batch/s]total loss: 0.82\n",
      "recon: 0.79\n",
      "reg: 0.88\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 10.14batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8182\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  60%|██████    | 3/5 [00:00<00:00, 13.69batch/s]total loss: 0.87\n",
      "recon: 0.71\n",
      "reg: 4.06\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00,  9.73batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  5.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 13.88batch/s]total loss: 0.88\n",
      "recon: 0.93\n",
      "reg: -1.26\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  9.64batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8345\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 16.95batch/s]total loss: 0.74\n",
      "recon: 0.65\n",
      "reg: 2.15\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 10.47batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8068\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  60%|██████    | 3/5 [00:00<00:00, 13.83batch/s]total loss: 0.28\n",
      "recon: 0.40\n",
      "reg: -3.05\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  6.84batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  2.43batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7045\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 16.68batch/s]total loss: 0.60\n",
      "recon: 0.57\n",
      "reg: 0.92\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  9.13batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:01,  3.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7759\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 16.49batch/s]total loss: 0.89\n",
      "recon: 0.94\n",
      "reg: -1.21\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 10.27batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  4.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8237\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 14.82batch/s]total loss: 0.64\n",
      "recon: 0.71\n",
      "reg: -1.91\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  9.52batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  4.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7629\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 15.36batch/s]total loss: 1.16\n",
      "recon: 1.03\n",
      "reg: 3.11\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  9.56batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  4.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9071\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 17.62batch/s]total loss: 0.76\n",
      "recon: 0.81\n",
      "reg: -1.21\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 10.73batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8143\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 16.18batch/s]total loss: 1.42\n",
      "recon: 1.32\n",
      "reg: 2.45\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00,  7.39batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:01,  2.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0071\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 16.67batch/s]total loss: 0.76\n",
      "recon: 0.73\n",
      "reg: 0.84\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 10.02batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  4.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8655\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 16.99batch/s]total loss: 0.90\n",
      "recon: 0.81\n",
      "reg: 2.14\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  8.13batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:01,  2.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8864\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 16.59batch/s]total loss: 0.83\n",
      "recon: 0.81\n",
      "reg: 0.56\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00, 10.34batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  4.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8605\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 16.57batch/s]total loss: 0.94\n",
      "recon: 1.05\n",
      "reg: -2.88\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00,  8.10batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:01,  2.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8438\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 16.92batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.70\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00,  9.68batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:01,  3.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 17.99batch/s]total loss: 0.60\n",
      "recon: 0.59\n",
      "reg: 0.06\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00, 10.87batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  4.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.817\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 17.28batch/s]total loss: 0.75\n",
      "recon: 0.77\n",
      "reg: -0.52\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00, 10.62batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8247\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  60%|██████    | 3/5 [00:00<00:00, 13.67batch/s]total loss: 0.39\n",
      "recon: 0.37\n",
      "reg: 0.49\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00,  9.12batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  4.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7559\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 17.65batch/s]total loss: 0.72\n",
      "recon: 0.70\n",
      "reg: 0.44\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 10.19batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  4.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8028\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 15.12batch/s]total loss: 0.87\n",
      "recon: 0.87\n",
      "reg: -0.10\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00,  8.98batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:01,  3.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8308\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00, 14.51batch/s]total loss: 1.08\n",
      "recon: 1.03\n",
      "reg: 1.17\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  8.65batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8978\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 16.08batch/s]total loss: 0.63\n",
      "recon: 0.66\n",
      "reg: -0.76\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 10.13batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  4.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8253\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 16.72batch/s]total loss: 0.32\n",
      "recon: 0.41\n",
      "reg: -2.23\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 10.38batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7626\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 14.31batch/s]total loss: 0.76\n",
      "recon: 0.62\n",
      "reg: 3.38\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  8.48batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 16.62batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.73\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 10.34batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  4.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 16.34batch/s]total loss: 0.52\n",
      "recon: 0.47\n",
      "reg: 1.19\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  9.63batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7594\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  60%|██████    | 3/5 [00:00<00:00, 11.63batch/s]total loss: 0.76\n",
      "recon: 0.73\n",
      "reg: 0.72\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  8.84batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.805\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 16.78batch/s]total loss: 0.91\n",
      "recon: 0.91\n",
      "reg: 0.04\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00, 10.85batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  5.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 16.81batch/s]total loss: 0.95\n",
      "recon: 0.86\n",
      "reg: 2.38\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  9.93batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  4.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8402\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 16.90batch/s]total loss: 0.94\n",
      "recon: 0.83\n",
      "reg: 2.70\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 10.18batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8615\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 14.86batch/s]total loss: 0.68\n",
      "recon: 0.77\n",
      "reg: -2.15\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  9.90batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8091\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 12.58batch/s]total loss: 1.15\n",
      "recon: 1.08\n",
      "reg: 1.87\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  8.96batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8877\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 16.72batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.05\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  7.47batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:01,  2.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8304\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 13.40batch/s]total loss: 0.66\n",
      "recon: 0.62\n",
      "reg: 1.01\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  6.89batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.49batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7778\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 12.81batch/s]total loss: 1.08\n",
      "recon: 1.00\n",
      "reg: 2.07\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  7.84batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:01,  3.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 15.87batch/s]total loss: 0.61\n",
      "recon: 0.59\n",
      "reg: 0.53\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  7.61batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:01,  2.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7918\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  60%|██████    | 3/5 [00:00<00:00,  9.77batch/s]total loss: 0.77\n",
      "recon: 0.69\n",
      "reg: 2.16\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  7.50batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:01,  3.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8414\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  6.85batch/s]total loss: 0.71\n",
      "recon: 0.65\n",
      "reg: 1.38\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  5.34batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7946\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 15.38batch/s]total loss: 0.79\n",
      "recon: 0.84\n",
      "reg: -1.06\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  8.29batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:01,  3.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 11.90batch/s]total loss: 1.73\n",
      "recon: 1.60\n",
      "reg: 3.08\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  7.39batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:01,  3.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0039\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00,  9.10batch/s]total loss: 0.89\n",
      "recon: 0.90\n",
      "reg: -0.08\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  7.09batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:01,  3.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8473\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  60%|██████    | 3/5 [00:00<00:00,  4.24batch/s]total loss: 0.88\n",
      "recon: 0.79\n",
      "reg: 2.39\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:01<00:00,  3.97batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:01,  2.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8479\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 15.48batch/s]total loss: 1.65\n",
      "recon: 1.60\n",
      "reg: 1.22\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00,  8.60batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:01,  3.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.001\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  60%|██████    | 3/5 [00:00<00:00, 11.91batch/s]total loss: 0.63\n",
      "recon: 0.61\n",
      "reg: 0.49\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  6.79batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:01,  2.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8166\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_01-56-59/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.218730259943, Time: 111.45s\n",
      "Epoch 200, Training Loss: 0.070926699968, Time: 222.90s\n",
      "Epoch 300, Training Loss: 0.036841147431, Time: 337.00s\n",
      "Epoch 400, Training Loss: 0.031677664848, Time: 459.19s\n",
      "Epoch 500, Training Loss: 0.023271050683, Time: 575.34s\n",
      "Epoch 600, Training Loss: 0.023218240566, Time: 688.75s\n",
      "Epoch 700, Training Loss: 0.020471376009, Time: 795.84s\n",
      "Epoch 800, Training Loss: 0.018500855133, Time: 900.96s\n",
      "Epoch 900, Training Loss: 0.017616800221, Time: 1004.81s\n",
      "Epoch 1000, Training Loss: 0.017212281970, Time: 1113.95s\n",
      "Validation Loss: 0.016211510928\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.01621</td></tr><tr><td>val_loss</td><td>0.01621</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">revived-sweep-29</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/1xby2m18' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/1xby2m18</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_015658-1xby2m18/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4oy0aajj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00264484337436679\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_021657-4oy0aajj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/4oy0aajj' target=\"_blank\">celestial-sweep-30</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/4oy0aajj' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/4oy0aajj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_02-16-58. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:01<00:00,  3.82batch/s]total loss: 4.54\n",
      "recon: 4.25\n",
      "reg: 7.01\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:01<00:00,  2.77batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:01,  3.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.4454\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 12.66batch/s]total loss: 1.09\n",
      "recon: 1.05\n",
      "reg: 1.10\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00,  8.67batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.5912\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 16.04batch/s]total loss: 1.23\n",
      "recon: 1.27\n",
      "reg: -1.13\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  4.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2307\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 16.03batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.76\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00,  9.36batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:01,  3.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 15.04batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.45\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  8.27batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:01,  3.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9394\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 10.47batch/s]total loss: 0.81\n",
      "recon: 0.71\n",
      "reg: 2.51\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00,  6.48batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:01,  3.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.901\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 12.10batch/s]total loss: 0.67\n",
      "recon: 0.70\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00,  8.31batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  4.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  60%|██████    | 3/5 [00:00<00:00, 10.01batch/s]total loss: 0.71\n",
      "recon: 0.71\n",
      "reg: -0.09\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00,  6.76batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:01,  3.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 15.54batch/s]total loss: 1.02\n",
      "recon: 0.89\n",
      "reg: 3.25\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  7.49batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:01,  2.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9044\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 11.86batch/s]total loss: 0.65\n",
      "recon: 0.57\n",
      "reg: 2.05\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  7.42batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:01,  3.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 14.64batch/s]total loss: 1.09\n",
      "recon: 0.94\n",
      "reg: 3.71\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00,  9.57batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  4.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9274\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 13.90batch/s]total loss: 0.93\n",
      "recon: 0.85\n",
      "reg: 1.84\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  9.03batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  4.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  60%|██████    | 3/5 [00:00<00:00, 10.45batch/s]total loss: 1.01\n",
      "recon: 0.97\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00,  7.99batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  4.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 10.00batch/s]total loss: 0.65\n",
      "recon: 0.65\n",
      "reg: -0.11\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00,  7.83batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  4.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 12.44batch/s]total loss: 0.75\n",
      "recon: 0.75\n",
      "reg: 0.04\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  9.06batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  5.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8417\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 10.38batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.13\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00,  7.93batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 14.53batch/s]total loss: 0.85\n",
      "recon: 0.76\n",
      "reg: 2.07\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00,  9.85batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00, 13.77batch/s]total loss: 0.74\n",
      "recon: 0.63\n",
      "reg: 2.86\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00,  8.38batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:01,  3.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8258\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 14.43batch/s]total loss: 0.37\n",
      "recon: 0.48\n",
      "reg: -2.77\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00,  8.03batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:01,  3.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7576\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 15.06batch/s]total loss: 1.04\n",
      "recon: 1.06\n",
      "reg: -0.72\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00,  9.45batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  4.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8823\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 15.34batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.33\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00,  8.63batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:01,  3.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9097\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 15.70batch/s]total loss: 0.53\n",
      "recon: 0.63\n",
      "reg: -2.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00,  7.52batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:01,  2.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7636\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00, 11.95batch/s]total loss: 0.93\n",
      "recon: 0.91\n",
      "reg: 0.48\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  7.93batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  4.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8492\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 12.99batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.33\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00,  9.28batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 11.69batch/s]total loss: 0.86\n",
      "recon: 0.82\n",
      "reg: 1.08\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00,  7.81batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  4.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8431\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 14.13batch/s]total loss: 1.19\n",
      "recon: 1.07\n",
      "reg: 3.22\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00,  7.55batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:01,  3.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9047\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 14.95batch/s]total loss: 0.98\n",
      "recon: 0.80\n",
      "reg: 4.48\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00,  9.04batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:01,  3.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 14.89batch/s]total loss: 0.76\n",
      "recon: 0.70\n",
      "reg: 1.32\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  7.87batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:01,  3.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8853\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 15.57batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.90\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00,  9.26batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:01,  3.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8931\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:00<00:00, 15.39batch/s]total loss: 0.65\n",
      "recon: 0.58\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  7.48batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  2.64batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8147\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 15.17batch/s]total loss: 1.03\n",
      "recon: 1.05\n",
      "reg: -0.60\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00,  8.41batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9293\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 13.49batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.74\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  8.71batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9285\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 14.08batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.58\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  8.88batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:01,  3.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8369\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  60%|██████    | 3/5 [00:00<00:00,  8.27batch/s]total loss: 0.66\n",
      "recon: 0.70\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  7.29batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  4.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  60%|██████    | 3/5 [00:00<00:00, 10.14batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.13\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  7.55batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  4.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9186\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 15.86batch/s]total loss: 0.56\n",
      "recon: 0.63\n",
      "reg: -1.68\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  7.56batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:01,  3.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 16.25batch/s]total loss: 0.71\n",
      "recon: 0.75\n",
      "reg: -0.86\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00,  8.85batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:01,  3.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8243\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00,  9.28batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.79\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00,  7.50batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8526\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 11.90batch/s]total loss: 0.87\n",
      "recon: 0.81\n",
      "reg: 1.67\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  8.75batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8549\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 12.18batch/s]total loss: 1.35\n",
      "recon: 1.29\n",
      "reg: 1.42\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00,  8.33batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  4.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9426\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 11.93batch/s]total loss: 1.17\n",
      "recon: 1.03\n",
      "reg: 3.66\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00,  6.63batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:01,  3.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.96\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 14.23batch/s]total loss: 1.27\n",
      "recon: 1.29\n",
      "reg: -0.54\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  7.26batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:01,  2.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 14.85batch/s]total loss: 0.97\n",
      "recon: 0.96\n",
      "reg: 0.04\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00,  8.76batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:01,  3.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8667\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 15.28batch/s]total loss: 0.88\n",
      "recon: 0.86\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00,  8.82batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:01,  3.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8627\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 14.05batch/s]total loss: 0.92\n",
      "recon: 0.87\n",
      "reg: 1.15\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  8.05batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:01,  3.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00,  9.86batch/s]total loss: 0.92\n",
      "recon: 0.84\n",
      "reg: 2.00\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00,  7.78batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  4.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 10.38batch/s]total loss: 0.92\n",
      "recon: 0.94\n",
      "reg: -0.45\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  7.72batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  4.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  60%|██████    | 3/5 [00:00<00:00,  8.49batch/s]total loss: 0.98\n",
      "recon: 0.94\n",
      "reg: 0.89\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  7.58batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  60%|██████    | 3/5 [00:00<00:00, 11.62batch/s]total loss: 0.34\n",
      "recon: 0.53\n",
      "reg: -4.81\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00,  8.11batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:01,  3.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7391\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 14.97batch/s]total loss: 1.03\n",
      "recon: 1.02\n",
      "reg: 0.36\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00,  8.44batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:01,  3.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  60%|██████    | 3/5 [00:00<00:00, 13.12batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.50\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00,  8.30batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:01,  3.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8732\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 15.49batch/s]total loss: 0.78\n",
      "recon: 0.78\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  8.52batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:01,  3.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 14.10batch/s]total loss: 0.60\n",
      "recon: 0.58\n",
      "reg: 0.51\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00,  7.59batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:01,  2.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7782\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 10.21batch/s]total loss: 0.69\n",
      "recon: 0.80\n",
      "reg: -2.77\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00,  7.83batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  4.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 11.16batch/s]total loss: 1.01\n",
      "recon: 1.06\n",
      "reg: -1.18\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  8.38batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 11.47batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.50\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00,  7.90batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:01,  3.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 13.34batch/s]total loss: 0.86\n",
      "recon: 0.70\n",
      "reg: 3.93\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00,  8.14batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8203\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 12.80batch/s]total loss: 0.88\n",
      "recon: 0.95\n",
      "reg: -1.75\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  8.34batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  4.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.824\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 13.06batch/s]total loss: 0.70\n",
      "recon: 0.62\n",
      "reg: 1.82\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00,  7.62batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:01,  3.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.794\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 15.23batch/s]total loss: 0.26\n",
      "recon: 0.40\n",
      "reg: -3.61\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  7.37batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  2.59batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.6987\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 14.95batch/s]total loss: 0.59\n",
      "recon: 0.57\n",
      "reg: 0.43\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  8.02batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:01,  3.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7719\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 11.94batch/s]total loss: 0.96\n",
      "recon: 0.99\n",
      "reg: -0.90\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00,  6.73batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:01,  3.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8422\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 15.35batch/s]total loss: 0.66\n",
      "recon: 0.73\n",
      "reg: -1.79\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  8.01batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:01,  3.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7701\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 10.10batch/s]total loss: 1.19\n",
      "recon: 1.06\n",
      "reg: 3.29\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  7.28batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:01,  3.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9232\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 13.62batch/s]total loss: 0.77\n",
      "recon: 0.81\n",
      "reg: -0.83\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00,  9.13batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  4.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8216\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 14.63batch/s]total loss: 1.34\n",
      "recon: 1.26\n",
      "reg: 1.98\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00,  7.66batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:01,  3.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  60%|██████    | 3/5 [00:00<00:00, 13.08batch/s]total loss: 0.73\n",
      "recon: 0.70\n",
      "reg: 0.57\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00,  8.72batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  4.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 14.59batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.27\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  9.07batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  4.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8691\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 13.78batch/s]total loss: 0.82\n",
      "recon: 0.81\n",
      "reg: 0.11\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  8.62batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:01,  3.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8416\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 14.23batch/s]total loss: 0.98\n",
      "recon: 1.08\n",
      "reg: -2.70\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00,  7.73batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:01,  3.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8468\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 14.88batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.86\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00,  8.42batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:01,  3.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.79\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 11.35batch/s]total loss: 0.56\n",
      "recon: 0.57\n",
      "reg: -0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  7.95batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:01,  3.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7949\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00,  9.41batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.67\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  7.64batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  4.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8143\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 13.34batch/s]total loss: 0.39\n",
      "recon: 0.38\n",
      "reg: 0.29\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00,  9.03batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  4.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7498\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 12.18batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00,  7.58batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  4.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7909\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  60%|██████    | 3/5 [00:00<00:00, 10.27batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.07\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00,  7.40batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:01,  3.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.83\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  80%|████████  | 4/5 [00:00<00:00, 12.93batch/s]total loss: 1.07\n",
      "recon: 1.02\n",
      "reg: 1.30\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  7.90batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:01,  3.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 13.93batch/s]total loss: 0.61\n",
      "recon: 0.64\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00,  7.67batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:01,  3.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00,  9.79batch/s]total loss: 0.31\n",
      "recon: 0.40\n",
      "reg: -2.21\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00,  7.85batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  4.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 11.66batch/s]total loss: 0.79\n",
      "recon: 0.64\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  8.42batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8183\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 11.29batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.51\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00,  7.62batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  4.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  60%|██████    | 3/5 [00:00<00:00, 13.22batch/s]total loss: 0.51\n",
      "recon: 0.46\n",
      "reg: 1.29\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  8.78batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 14.98batch/s]total loss: 0.76\n",
      "recon: 0.72\n",
      "reg: 0.88\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  7.66batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:01,  2.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8033\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 15.40batch/s]total loss: 0.92\n",
      "recon: 0.91\n",
      "reg: 0.35\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  8.75batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:01,  3.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8392\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 14.05batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.35\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  7.97batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:01,  3.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8333\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 10.19batch/s]total loss: 0.94\n",
      "recon: 0.82\n",
      "reg: 2.90\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  8.16batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 12.55batch/s]total loss: 0.71\n",
      "recon: 0.78\n",
      "reg: -1.62\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  8.72batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 10.19batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.77\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  7.31batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8986\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  60%|██████    | 3/5 [00:00<00:00, 12.04batch/s]total loss: 0.91\n",
      "recon: 0.92\n",
      "reg: -0.23\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  8.74batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8309\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  60%|██████    | 3/5 [00:00<00:00, 11.82batch/s]total loss: 0.65\n",
      "recon: 0.61\n",
      "reg: 0.89\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  6.39batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.34batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 15.86batch/s]total loss: 1.08\n",
      "recon: 0.99\n",
      "reg: 2.14\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  7.95batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:01,  3.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8833\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00, 15.04batch/s]total loss: 0.63\n",
      "recon: 0.60\n",
      "reg: 0.78\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  8.12batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:01,  3.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7938\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 15.28batch/s]total loss: 0.71\n",
      "recon: 0.64\n",
      "reg: 1.84\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  8.06batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:01,  3.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.814\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  60%|██████    | 3/5 [00:00<00:00, 12.28batch/s]total loss: 0.70\n",
      "recon: 0.63\n",
      "reg: 1.61\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  7.46batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:01,  3.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 14.86batch/s]total loss: 0.78\n",
      "recon: 0.83\n",
      "reg: -1.19\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  9.34batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8094\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 11.46batch/s]total loss: 1.65\n",
      "recon: 1.55\n",
      "reg: 2.45\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  7.72batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:01,  3.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9859\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 15.23batch/s]total loss: 0.91\n",
      "recon: 0.89\n",
      "reg: 0.35\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  9.44batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  4.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 16.17batch/s]total loss: 0.92\n",
      "recon: 0.82\n",
      "reg: 2.52\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  9.13batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:01,  3.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8423\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 14.83batch/s]total loss: 1.58\n",
      "recon: 1.54\n",
      "reg: 0.99\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00,  8.72batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 15.60batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.73\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  9.68batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  4.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8236\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_02-16-58/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.114875004534, Time: 112.38s\n",
      "Epoch 200, Training Loss: 0.041040038015, Time: 225.59s\n",
      "Epoch 300, Training Loss: 0.014057180213, Time: 339.36s\n",
      "Epoch 400, Training Loss: 0.009489276013, Time: 454.28s\n",
      "Epoch 500, Training Loss: 0.005714449228, Time: 571.90s\n",
      "Epoch 600, Training Loss: 0.003244221902, Time: 687.62s\n",
      "Epoch 700, Training Loss: 0.001277019807, Time: 800.75s\n",
      "Epoch 800, Training Loss: 0.000573103592, Time: 914.90s\n",
      "Epoch 900, Training Loss: 0.000360323455, Time: 1029.39s\n",
      "Epoch 1000, Training Loss: 0.000390910856, Time: 1225.36s\n",
      "Validation Loss: 0.000205482999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00021</td></tr><tr><td>val_loss</td><td>0.00021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-sweep-30</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/4oy0aajj' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/4oy0aajj</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_021657-4oy0aajj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qcxahp6z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006024236289351811\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_023849-qcxahp6z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/qcxahp6z' target=\"_blank\">stilted-sweep-31</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/qcxahp6z' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/qcxahp6z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_02-38-50. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 19.06batch/s]total loss: 2.03\n",
      "recon: 1.70\n",
      "reg: 8.23\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  9.75batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:01,  3.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 3.683\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 18.66batch/s]total loss: 1.57\n",
      "recon: 1.47\n",
      "reg: 2.51\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00,  7.15batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:01,  2.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.9129\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  60%|██████    | 3/5 [00:00<00:00,  6.47batch/s]total loss: 1.18\n",
      "recon: 1.18\n",
      "reg: -0.01\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:01<00:00,  4.61batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:01,  2.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.328\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  60%|██████    | 3/5 [00:00<00:00,  9.57batch/s]total loss: 0.73\n",
      "recon: 0.75\n",
      "reg: -0.57\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00,  6.02batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:01,  2.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.1801\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 17.49batch/s]total loss: 1.00\n",
      "recon: 0.99\n",
      "reg: 0.18\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  7.52batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:01,  2.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0934\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 10.38batch/s]total loss: 0.94\n",
      "recon: 0.83\n",
      "reg: 2.89\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:01<00:00,  4.21batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:02,  1.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.988\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00,  6.14batch/s]total loss: 0.66\n",
      "recon: 0.73\n",
      "reg: -1.80\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:01<00:00,  4.97batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:01,  2.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8546\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  60%|██████    | 3/5 [00:00<00:00, 13.38batch/s]total loss: 0.67\n",
      "recon: 0.68\n",
      "reg: -0.41\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00,  6.02batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:01,  2.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8464\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  60%|██████    | 3/5 [00:00<00:00,  9.00batch/s]total loss: 1.01\n",
      "recon: 0.89\n",
      "reg: 2.99\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  5.84batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:01,  2.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8922\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 19.09batch/s]total loss: 0.67\n",
      "recon: 0.59\n",
      "reg: 1.96\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  6.93batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:01,  2.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8242\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 17.73batch/s]total loss: 1.00\n",
      "recon: 0.87\n",
      "reg: 3.27\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00,  7.70batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:01,  2.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8953\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00,  7.66batch/s]total loss: 0.79\n",
      "recon: 0.72\n",
      "reg: 1.78\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  6.02batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  4.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9075\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 18.81batch/s]total loss: 1.08\n",
      "recon: 1.05\n",
      "reg: 0.79\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 11.33batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  5.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9532\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 15.44batch/s]total loss: 0.51\n",
      "recon: 0.47\n",
      "reg: 0.88\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00,  6.93batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:01,  2.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8073\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  60%|██████    | 3/5 [00:00<00:00, 10.45batch/s]total loss: 0.80\n",
      "recon: 0.79\n",
      "reg: 0.32\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  8.15batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  4.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8323\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 19.69batch/s]total loss: 0.84\n",
      "recon: 0.90\n",
      "reg: -1.37\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 12.08batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  5.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8505\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 19.24batch/s]total loss: 0.86\n",
      "recon: 0.78\n",
      "reg: 1.93\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00,  7.83batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:01,  2.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8569\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:03<00:00,  2.05batch/s]total loss: 0.73\n",
      "recon: 0.64\n",
      "reg: 2.31\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:03<00:00,  1.27batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:01,  2.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8195\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00,  9.83batch/s]total loss: 0.36\n",
      "recon: 0.48\n",
      "reg: -3.09\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:01<00:00,  3.78batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:03,  1.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7538\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  60%|██████    | 3/5 [00:00<00:00, 13.43batch/s]total loss: 0.97\n",
      "recon: 1.01\n",
      "reg: -1.14\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 10.20batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8711\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  60%|██████    | 3/5 [00:00<00:00,  8.38batch/s]total loss: 1.26\n",
      "recon: 1.21\n",
      "reg: 1.17\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00,  8.12batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  5.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9182\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  60%|██████    | 3/5 [00:00<00:00,  7.60batch/s]total loss: 0.50\n",
      "recon: 0.60\n",
      "reg: -2.57\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00,  5.94batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:01,  3.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.764\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 17.62batch/s]total loss: 0.89\n",
      "recon: 0.86\n",
      "reg: 0.91\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  8.65batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:01,  3.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8456\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  60%|██████    | 3/5 [00:00<00:00, 12.19batch/s]total loss: 1.03\n",
      "recon: 1.01\n",
      "reg: 0.56\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00,  6.69batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:01,  2.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9119\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 17.11batch/s]total loss: 0.84\n",
      "recon: 0.80\n",
      "reg: 0.91\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00,  9.24batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8388\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 15.97batch/s]total loss: 1.25\n",
      "recon: 1.12\n",
      "reg: 3.06\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00,  7.68batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:01,  2.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9123\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 13.05batch/s]total loss: 0.94\n",
      "recon: 0.79\n",
      "reg: 3.70\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00,  7.11batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  5.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8623\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 17.97batch/s]total loss: 0.83\n",
      "recon: 0.77\n",
      "reg: 1.56\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  8.24batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:01,  2.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.939\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 16.72batch/s]total loss: 1.00\n",
      "recon: 0.97\n",
      "reg: 0.81\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00,  8.16batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:01,  2.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9186\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  60%|██████    | 3/5 [00:00<00:00, 14.38batch/s]total loss: 0.65\n",
      "recon: 0.59\n",
      "reg: 1.60\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  5.99batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:02,  1.92batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8296\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 17.72batch/s]total loss: 0.99\n",
      "recon: 1.02\n",
      "reg: -0.75\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00,  8.95batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:01,  3.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9163\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 17.27batch/s]total loss: 0.84\n",
      "recon: 0.86\n",
      "reg: -0.40\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00, 10.75batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8995\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  60%|██████    | 3/5 [00:00<00:00, 14.42batch/s]total loss: 0.67\n",
      "recon: 0.68\n",
      "reg: -0.41\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  7.72batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:01,  2.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8363\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 16.86batch/s]total loss: 0.65\n",
      "recon: 0.68\n",
      "reg: -0.85\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00, 11.33batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  5.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8123\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 11.21batch/s]total loss: 1.31\n",
      "recon: 1.27\n",
      "reg: 0.92\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  8.64batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  5.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9435\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  60%|██████    | 3/5 [00:00<00:00,  8.10batch/s]total loss: 0.58\n",
      "recon: 0.66\n",
      "reg: -1.83\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  7.85batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  5.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8201\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00,  9.45batch/s]total loss: 0.77\n",
      "recon: 0.81\n",
      "reg: -1.14\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00,  8.04batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8473\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 14.23batch/s]total loss: 0.68\n",
      "recon: 0.62\n",
      "reg: 1.57\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00,  9.87batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  5.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8495\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00, 16.42batch/s]total loss: 0.89\n",
      "recon: 0.82\n",
      "reg: 1.64\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  9.00batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8648\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 22.21batch/s]total loss: 1.38\n",
      "recon: 1.32\n",
      "reg: 1.40\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 10.46batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  4.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9466\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 18.80batch/s]total loss: 1.14\n",
      "recon: 1.01\n",
      "reg: 3.46\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 12.27batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  6.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9589\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 14.14batch/s]total loss: 1.32\n",
      "recon: 1.34\n",
      "reg: -0.62\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00, 10.08batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  5.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9489\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  60%|██████    | 3/5 [00:00<00:00, 13.01batch/s]total loss: 0.98\n",
      "recon: 0.98\n",
      "reg: 0.04\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 10.19batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  5.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8744\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 16.95batch/s]total loss: 0.88\n",
      "recon: 0.86\n",
      "reg: 0.51\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 11.16batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  5.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8543\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00, 23.00batch/s]total loss: 0.92\n",
      "recon: 0.87\n",
      "reg: 1.22\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00, 10.32batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:01,  3.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8567\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 18.47batch/s]total loss: 0.93\n",
      "recon: 0.84\n",
      "reg: 2.31\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00, 10.35batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  4.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8518\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  60%|██████    | 3/5 [00:00<00:00, 12.07batch/s]total loss: 0.95\n",
      "recon: 0.94\n",
      "reg: 0.23\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  6.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8525\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 12.85batch/s]total loss: 0.95\n",
      "recon: 0.93\n",
      "reg: 0.51\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  9.12batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  4.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8517\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 18.68batch/s]total loss: 0.36\n",
      "recon: 0.57\n",
      "reg: -5.07\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 10.35batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7443\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 22.21batch/s]total loss: 1.06\n",
      "recon: 1.05\n",
      "reg: 0.16\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00,  8.81batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:01,  3.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9171\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 18.87batch/s]total loss: 1.06\n",
      "recon: 1.01\n",
      "reg: 1.34\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 10.03batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:01,  3.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9192\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 17.31batch/s]total loss: 0.72\n",
      "recon: 0.72\n",
      "reg: 0.08\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00, 10.74batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8231\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  60%|██████    | 3/5 [00:00<00:00, 12.43batch/s]total loss: 0.59\n",
      "recon: 0.57\n",
      "reg: 0.53\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 10.06batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  5.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7753\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  60%|██████    | 3/5 [00:00<00:00, 15.71batch/s]total loss: 0.65\n",
      "recon: 0.76\n",
      "reg: -2.75\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 10.09batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.78\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 17.25batch/s]total loss: 1.01\n",
      "recon: 1.06\n",
      "reg: -1.01\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  9.78batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  4.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.865\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 19.62batch/s]total loss: 0.85\n",
      "recon: 0.81\n",
      "reg: 0.83\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 10.98batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8336\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 18.98batch/s]total loss: 0.90\n",
      "recon: 0.74\n",
      "reg: 3.98\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 11.35batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  4.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8383\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 12.95batch/s]total loss: 0.90\n",
      "recon: 0.97\n",
      "reg: -1.64\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00, 10.10batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  6.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8366\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 14.22batch/s]total loss: 0.68\n",
      "recon: 0.61\n",
      "reg: 1.78\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 10.76batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  6.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.802\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 19.46batch/s]total loss: 0.31\n",
      "recon: 0.43\n",
      "reg: -3.17\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  8.13batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  2.63batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7211\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 22.88batch/s]total loss: 0.58\n",
      "recon: 0.56\n",
      "reg: 0.33\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 12.88batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  6.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  60%|██████    | 3/5 [00:00<00:00, 10.26batch/s]total loss: 0.93\n",
      "recon: 0.98\n",
      "reg: -1.16\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00,  8.46batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  5.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8327\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 14.20batch/s]total loss: 0.66\n",
      "recon: 0.73\n",
      "reg: -1.78\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  9.04batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  5.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 16.46batch/s]total loss: 1.13\n",
      "recon: 1.01\n",
      "reg: 2.90\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00, 11.17batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  5.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9097\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  60%|██████    | 3/5 [00:00<00:00, 20.48batch/s]total loss: 0.85\n",
      "recon: 0.88\n",
      "reg: -0.88\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 11.98batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  5.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.842\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 18.93batch/s]total loss: 1.19\n",
      "recon: 1.12\n",
      "reg: 1.81\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00,  8.60batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:01,  3.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9244\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  60%|██████    | 3/5 [00:00<00:00, 20.64batch/s]total loss: 0.72\n",
      "recon: 0.70\n",
      "reg: 0.56\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 11.72batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8069\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 18.51batch/s]total loss: 0.87\n",
      "recon: 0.77\n",
      "reg: 2.48\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00, 11.55batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  5.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8517\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 17.26batch/s]total loss: 0.85\n",
      "recon: 0.81\n",
      "reg: 0.91\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00, 10.46batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  4.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8363\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 16.61batch/s]total loss: 0.96\n",
      "recon: 1.07\n",
      "reg: -2.64\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 10.76batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  5.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8442\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 23.00batch/s]total loss: 0.60\n",
      "recon: 0.72\n",
      "reg: -3.00\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00,  9.29batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:01,  3.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8065\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 17.71batch/s]total loss: 0.62\n",
      "recon: 0.60\n",
      "reg: 0.51\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00, 11.56batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  5.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8181\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 17.71batch/s]total loss: 0.81\n",
      "recon: 0.81\n",
      "reg: -0.07\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00, 11.56batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  5.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8307\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  60%|██████    | 3/5 [00:00<00:00, 10.54batch/s]total loss: 0.39\n",
      "recon: 0.38\n",
      "reg: 0.16\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00,  8.86batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  5.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7518\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 16.66batch/s]total loss: 0.75\n",
      "recon: 0.72\n",
      "reg: 0.74\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 11.35batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  5.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8112\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 22.83batch/s]total loss: 0.92\n",
      "recon: 0.93\n",
      "reg: -0.32\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 12.30batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  5.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8466\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  60%|██████    | 3/5 [00:00<00:00, 15.15batch/s]total loss: 1.04\n",
      "recon: 1.01\n",
      "reg: 0.84\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00, 11.05batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  5.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.897\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 13.42batch/s]total loss: 0.73\n",
      "recon: 0.76\n",
      "reg: -0.70\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 10.20batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  6.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8571\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 13.82batch/s]total loss: 0.28\n",
      "recon: 0.38\n",
      "reg: -2.41\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 10.65batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  6.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7379\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 16.35batch/s]total loss: 0.77\n",
      "recon: 0.61\n",
      "reg: 3.83\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  9.22batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:01,  3.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8109\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  60%|██████    | 3/5 [00:00<00:00, 20.50batch/s]total loss: 0.71\n",
      "recon: 0.73\n",
      "reg: -0.49\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 13.38batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  6.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 17.86batch/s]total loss: 0.51\n",
      "recon: 0.46\n",
      "reg: 1.23\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00, 11.89batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  6.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7896\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 10.87batch/s]total loss: 0.75\n",
      "recon: 0.73\n",
      "reg: 0.61\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  8.28batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  6.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.819\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  60%|██████    | 3/5 [00:00<00:00, 21.02batch/s]total loss: 0.93\n",
      "recon: 0.92\n",
      "reg: 0.39\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00, 11.10batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  6.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8513\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 23.16batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.13\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 11.26batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  4.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  60%|██████    | 3/5 [00:00<00:00, 15.10batch/s]total loss: 0.96\n",
      "recon: 0.83\n",
      "reg: 3.14\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  9.87batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8552\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 18.11batch/s]total loss: 0.70\n",
      "recon: 0.79\n",
      "reg: -2.09\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 12.42batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  6.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8079\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 14.72batch/s]total loss: 1.09\n",
      "recon: 1.02\n",
      "reg: 1.71\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00, 10.16batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  5.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8677\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  60%|██████    | 3/5 [00:00<00:00, 12.57batch/s]total loss: 0.95\n",
      "recon: 0.95\n",
      "reg: -0.14\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00, 10.02batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  6.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8308\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  60%|██████    | 3/5 [00:00<00:00, 20.46batch/s]total loss: 0.65\n",
      "recon: 0.63\n",
      "reg: 0.70\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  6.76batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:02,  1.94batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7712\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  60%|██████    | 3/5 [00:00<00:00, 20.87batch/s]total loss: 1.19\n",
      "recon: 1.09\n",
      "reg: 2.45\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  7.66batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:01,  2.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9154\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  60%|██████    | 3/5 [00:00<00:00, 15.44batch/s]total loss: 0.69\n",
      "recon: 0.66\n",
      "reg: 0.70\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  9.30batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  4.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 19.24batch/s]total loss: 0.69\n",
      "recon: 0.60\n",
      "reg: 2.33\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  8.90batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:01,  3.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7978\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 18.10batch/s]total loss: 0.70\n",
      "recon: 0.61\n",
      "reg: 2.18\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00, 10.14batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7794\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  60%|██████    | 3/5 [00:00<00:00, 15.02batch/s]total loss: 0.73\n",
      "recon: 0.78\n",
      "reg: -1.11\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 11.17batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  6.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7938\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 15.01batch/s]total loss: 1.68\n",
      "recon: 1.47\n",
      "reg: 5.38\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00, 10.86batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  6.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9927\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 16.86batch/s]total loss: 1.00\n",
      "recon: 0.95\n",
      "reg: 1.25\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00, 10.81batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  5.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.892\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  60%|██████    | 3/5 [00:00<00:00, 15.64batch/s]total loss: 0.92\n",
      "recon: 0.74\n",
      "reg: 4.58\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  9.87batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8309\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 17.89batch/s]total loss: 1.16\n",
      "recon: 1.03\n",
      "reg: 3.26\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 10.13batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8381\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  60%|██████    | 3/5 [00:00<00:00, 20.42batch/s]total loss: 0.72\n",
      "recon: 0.65\n",
      "reg: 1.83\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00, 13.27batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  6.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7885\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_02-38-50/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 5.069543099403, Time: 129.31s\n",
      "Epoch 200, Training Loss: 4.500413155556, Time: 249.62s\n",
      "Epoch 300, Training Loss: 4.283363391459, Time: 361.06s\n",
      "Epoch 400, Training Loss: 4.156390762329, Time: 470.15s\n",
      "Epoch 500, Training Loss: 4.059908550978, Time: 582.05s\n",
      "Epoch 600, Training Loss: 4.022175014019, Time: 690.17s\n",
      "Epoch 700, Training Loss: 3.926571804285, Time: 806.52s\n",
      "Epoch 800, Training Loss: 4.083332508802, Time: 915.66s\n",
      "Epoch 900, Training Loss: 3.844046187401, Time: 1026.15s\n",
      "Epoch 1000, Training Loss: 3.910877156258, Time: 1139.16s\n",
      "Validation Loss: 3.897108387947\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>3.89711</td></tr><tr><td>val_loss</td><td>3.89711</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stilted-sweep-31</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/qcxahp6z' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/qcxahp6z</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_023849-qcxahp6z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uxt78wvs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009615060000866586\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_025909-uxt78wvs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/uxt78wvs' target=\"_blank\">playful-sweep-32</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/uxt78wvs' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/uxt78wvs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_02-59-10. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 12.57batch/s]total loss: 2.12\n",
      "recon: 1.87\n",
      "reg: 6.44\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  8.54batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:00,  4.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 6.6176\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  60%|██████    | 3/5 [00:00<00:00, 13.75batch/s]total loss: 0.96\n",
      "recon: 0.79\n",
      "reg: 4.11\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00,  8.22batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:01,  3.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.3888\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 12.24batch/s]total loss: 0.97\n",
      "recon: 0.93\n",
      "reg: 0.96\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  8.36batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  4.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.1104\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 17.56batch/s]total loss: 0.92\n",
      "recon: 0.88\n",
      "reg: 0.87\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 10.97batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.4861\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  60%|██████    | 3/5 [00:00<00:00, 12.46batch/s]total loss: 0.81\n",
      "recon: 0.78\n",
      "reg: 0.65\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  9.26batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  5.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.962\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 16.43batch/s]total loss: 0.97\n",
      "recon: 0.80\n",
      "reg: 4.17\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 10.70batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  5.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9488\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 15.27batch/s]total loss: 0.64\n",
      "recon: 0.63\n",
      "reg: 0.19\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 10.01batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8647\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 16.53batch/s]total loss: 0.61\n",
      "recon: 0.62\n",
      "reg: -0.17\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00,  9.67batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  5.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8624\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 15.61batch/s]total loss: 0.99\n",
      "recon: 0.82\n",
      "reg: 4.29\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 10.27batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  5.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 14.46batch/s]total loss: 0.73\n",
      "recon: 0.58\n",
      "reg: 3.68\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  9.77batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  4.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8341\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 17.46batch/s]total loss: 0.94\n",
      "recon: 0.78\n",
      "reg: 4.15\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00,  8.98batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:01,  3.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.888\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 17.73batch/s]total loss: 0.87\n",
      "recon: 0.78\n",
      "reg: 2.05\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  9.65batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:01,  3.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0064\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 16.06batch/s]total loss: 0.95\n",
      "recon: 0.92\n",
      "reg: 0.75\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 10.57batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  5.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9231\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 16.04batch/s]total loss: 0.61\n",
      "recon: 0.56\n",
      "reg: 1.30\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00,  9.56batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  4.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9228\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 13.65batch/s]total loss: 0.73\n",
      "recon: 0.72\n",
      "reg: 0.31\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  9.99batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  5.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8989\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 15.16batch/s]total loss: 0.89\n",
      "recon: 0.93\n",
      "reg: -0.89\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 10.28batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  5.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9269\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 16.61batch/s]total loss: 1.02\n",
      "recon: 0.94\n",
      "reg: 1.94\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00, 10.73batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  5.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9247\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  60%|██████    | 3/5 [00:00<00:00, 13.64batch/s]total loss: 0.72\n",
      "recon: 0.62\n",
      "reg: 2.60\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00,  9.31batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  4.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8406\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 17.56batch/s]total loss: 0.40\n",
      "recon: 0.51\n",
      "reg: -2.80\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 10.57batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.778\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 17.79batch/s]total loss: 0.97\n",
      "recon: 1.01\n",
      "reg: -0.84\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 10.56batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  4.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8746\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  60%|██████    | 3/5 [00:00<00:00, 13.73batch/s]total loss: 1.24\n",
      "recon: 1.16\n",
      "reg: 1.90\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00,  8.40batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:01,  3.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9301\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 17.67batch/s]total loss: 0.50\n",
      "recon: 0.59\n",
      "reg: -2.11\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 11.26batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7739\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 17.19batch/s]total loss: 0.95\n",
      "recon: 0.90\n",
      "reg: 1.26\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  9.45batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:01,  3.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8674\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  60%|██████    | 3/5 [00:00<00:00, 12.82batch/s]total loss: 1.03\n",
      "recon: 1.00\n",
      "reg: 0.77\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00,  9.29batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9205\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 15.41batch/s]total loss: 0.85\n",
      "recon: 0.79\n",
      "reg: 1.33\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 10.30batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.852\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 15.30batch/s]total loss: 1.20\n",
      "recon: 1.08\n",
      "reg: 3.14\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 10.19batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  5.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9106\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 12.44batch/s]total loss: 0.95\n",
      "recon: 0.77\n",
      "reg: 4.51\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00,  9.07batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8631\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00,  8.93batch/s]total loss: 0.62\n",
      "recon: 0.59\n",
      "reg: 0.77\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  7.68batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  5.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8302\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 15.50batch/s]total loss: 0.92\n",
      "recon: 0.88\n",
      "reg: 0.94\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 10.43batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  5.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8679\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:00<00:00, 16.69batch/s]total loss: 0.62\n",
      "recon: 0.56\n",
      "reg: 1.63\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  8.23batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  2.97batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7998\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 17.55batch/s]total loss: 0.82\n",
      "recon: 0.86\n",
      "reg: -1.08\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 10.96batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  5.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8644\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 16.65batch/s]total loss: 0.92\n",
      "recon: 0.96\n",
      "reg: -1.03\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  9.66batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9851\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 10.64batch/s]total loss: 0.69\n",
      "recon: 0.70\n",
      "reg: -0.18\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  7.84batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  5.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.875\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 15.07batch/s]total loss: 0.77\n",
      "recon: 0.82\n",
      "reg: -1.38\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00, 10.24batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  5.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8348\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 13.02batch/s]total loss: 1.21\n",
      "recon: 1.16\n",
      "reg: 1.40\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  8.70batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  4.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9021\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  60%|██████    | 3/5 [00:00<00:00, 14.29batch/s]total loss: 0.58\n",
      "recon: 0.63\n",
      "reg: -1.11\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  9.86batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  5.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8036\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 16.85batch/s]total loss: 0.76\n",
      "recon: 0.77\n",
      "reg: -0.41\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 10.87batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  5.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8348\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 15.93batch/s]total loss: 0.69\n",
      "recon: 0.64\n",
      "reg: 1.26\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 10.45batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  5.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8543\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 16.03batch/s]total loss: 0.99\n",
      "recon: 0.91\n",
      "reg: 1.90\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00, 10.61batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  5.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8937\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 15.04batch/s]total loss: 1.40\n",
      "recon: 1.33\n",
      "reg: 1.83\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00,  8.42batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:01,  3.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9569\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 10.03batch/s]total loss: 1.14\n",
      "recon: 0.98\n",
      "reg: 4.03\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00,  7.68batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  5.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9592\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 16.59batch/s]total loss: 1.33\n",
      "recon: 1.32\n",
      "reg: 0.24\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  8.76batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:01,  3.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9546\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 16.76batch/s]total loss: 1.05\n",
      "recon: 1.04\n",
      "reg: 0.16\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00,  9.85batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  4.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.897\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 16.35batch/s]total loss: 0.71\n",
      "recon: 0.71\n",
      "reg: -0.08\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 10.69batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  5.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8159\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  60%|██████    | 3/5 [00:00<00:00, 12.16batch/s]total loss: 0.90\n",
      "recon: 0.85\n",
      "reg: 1.24\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  9.14batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  5.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8555\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 14.70batch/s]total loss: 0.95\n",
      "recon: 0.87\n",
      "reg: 2.08\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00, 10.21batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  5.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8517\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 15.10batch/s]total loss: 0.93\n",
      "recon: 0.95\n",
      "reg: -0.28\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  9.10batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:01,  3.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8455\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  60%|██████    | 3/5 [00:00<00:00, 13.60batch/s]total loss: 0.97\n",
      "recon: 0.95\n",
      "reg: 0.62\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  9.37batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  5.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8559\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 16.91batch/s]total loss: 0.36\n",
      "recon: 0.55\n",
      "reg: -4.76\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 10.79batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  5.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7429\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 16.53batch/s]total loss: 1.04\n",
      "recon: 1.02\n",
      "reg: 0.51\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 10.62batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9185\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  60%|██████    | 3/5 [00:00<00:00, 13.48batch/s]total loss: 1.06\n",
      "recon: 0.99\n",
      "reg: 1.81\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  5.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9252\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 16.33batch/s]total loss: 0.73\n",
      "recon: 0.74\n",
      "reg: -0.09\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00, 10.21batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  4.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8296\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 16.77batch/s]total loss: 0.60\n",
      "recon: 0.59\n",
      "reg: 0.35\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 10.87batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  5.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7883\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 12.96batch/s]total loss: 0.62\n",
      "recon: 0.74\n",
      "reg: -2.96\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00,  8.14batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:01,  3.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7878\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 15.14batch/s]total loss: 1.06\n",
      "recon: 1.10\n",
      "reg: -0.92\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  8.00batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:01,  3.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9051\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 16.69batch/s]total loss: 0.81\n",
      "recon: 0.78\n",
      "reg: 0.63\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00,  9.96batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8301\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 13.07batch/s]total loss: 0.90\n",
      "recon: 0.73\n",
      "reg: 4.29\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00,  9.07batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  4.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8385\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 14.87batch/s]total loss: 0.89\n",
      "recon: 0.94\n",
      "reg: -1.20\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  9.18batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:01,  3.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8338\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 11.79batch/s]total loss: 0.73\n",
      "recon: 0.64\n",
      "reg: 2.15\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00,  8.24batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  5.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.811\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 16.35batch/s]total loss: 0.29\n",
      "recon: 0.42\n",
      "reg: -3.25\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:01<00:00,  2.60batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:01<00:06,  1.65s/batch]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7159\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 16.00batch/s]total loss: 0.57\n",
      "recon: 0.55\n",
      "reg: 0.48\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  9.79batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7711\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 13.28batch/s]total loss: 0.91\n",
      "recon: 0.95\n",
      "reg: -1.05\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00,  7.25batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:01,  3.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8262\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 15.92batch/s]total loss: 0.60\n",
      "recon: 0.68\n",
      "reg: -1.92\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  9.96batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  4.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7619\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  60%|██████    | 3/5 [00:00<00:00, 12.62batch/s]total loss: 1.11\n",
      "recon: 1.00\n",
      "reg: 2.82\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  8.22batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:01,  3.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8874\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 16.67batch/s]total loss: 0.74\n",
      "recon: 0.78\n",
      "reg: -1.11\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 10.71batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  5.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8103\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 16.06batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.34\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 10.17batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  4.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9481\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00,  9.60batch/s]total loss: 0.73\n",
      "recon: 0.70\n",
      "reg: 0.82\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00,  6.97batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  5.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8449\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 13.17batch/s]total loss: 0.88\n",
      "recon: 0.78\n",
      "reg: 2.43\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  9.38batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  5.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8673\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  60%|██████    | 3/5 [00:00<00:00, 11.03batch/s]total loss: 0.87\n",
      "recon: 0.84\n",
      "reg: 0.87\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  8.60batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  4.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8545\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 15.09batch/s]total loss: 0.81\n",
      "recon: 0.92\n",
      "reg: -2.81\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00,  9.22batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:01,  3.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8265\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 16.29batch/s]total loss: 0.57\n",
      "recon: 0.68\n",
      "reg: -2.78\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 10.90batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  5.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8049\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 15.97batch/s]total loss: 0.60\n",
      "recon: 0.59\n",
      "reg: 0.32\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00, 10.07batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  4.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8207\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 17.04batch/s]total loss: 0.77\n",
      "recon: 0.80\n",
      "reg: -0.63\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  9.98batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  5.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8235\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 16.09batch/s]total loss: 0.45\n",
      "recon: 0.43\n",
      "reg: 0.46\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 10.41batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  4.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 17.20batch/s]total loss: 0.75\n",
      "recon: 0.73\n",
      "reg: 0.36\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 10.64batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8275\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 14.89batch/s]total loss: 1.00\n",
      "recon: 1.01\n",
      "reg: -0.16\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00,  8.88batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  4.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8855\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  80%|████████  | 4/5 [00:00<00:00, 17.29batch/s]total loss: 1.09\n",
      "recon: 1.04\n",
      "reg: 1.21\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  9.36batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  4.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8844\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 16.94batch/s]total loss: 0.51\n",
      "recon: 0.55\n",
      "reg: -0.91\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:01,  3.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7738\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 17.92batch/s]total loss: 0.27\n",
      "recon: 0.36\n",
      "reg: -2.27\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00,  9.44batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  4.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7107\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 15.61batch/s]total loss: 0.75\n",
      "recon: 0.61\n",
      "reg: 3.64\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 10.54batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  5.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7904\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 16.73batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.49\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 10.52batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  4.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7913\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  60%|██████    | 3/5 [00:00<00:00, 13.07batch/s]total loss: 0.50\n",
      "recon: 0.46\n",
      "reg: 0.94\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  7.91batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:01,  3.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.769\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 13.40batch/s]total loss: 0.75\n",
      "recon: 0.71\n",
      "reg: 1.05\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  8.39batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:01,  3.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8256\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 14.02batch/s]total loss: 0.98\n",
      "recon: 0.97\n",
      "reg: 0.23\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  9.58batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8768\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  60%|██████    | 3/5 [00:00<00:00,  6.42batch/s]total loss: 1.07\n",
      "recon: 0.98\n",
      "reg: 2.06\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  6.35batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  4.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8774\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 14.79batch/s]total loss: 0.98\n",
      "recon: 0.85\n",
      "reg: 3.21\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  7.03batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:01,  3.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8504\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 17.15batch/s]total loss: 0.68\n",
      "recon: 0.76\n",
      "reg: -2.02\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  9.67batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:01,  3.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 15.52batch/s]total loss: 1.10\n",
      "recon: 1.02\n",
      "reg: 1.89\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  7.95batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8633\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 13.57batch/s]total loss: 0.92\n",
      "recon: 0.92\n",
      "reg: 0.15\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  9.37batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8268\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 12.80batch/s]total loss: 0.67\n",
      "recon: 0.62\n",
      "reg: 1.22\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  7.07batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  3.08batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7777\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 17.41batch/s]total loss: 1.01\n",
      "recon: 0.94\n",
      "reg: 1.59\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00, 10.90batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8538\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 15.93batch/s]total loss: 0.64\n",
      "recon: 0.60\n",
      "reg: 0.96\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  9.97batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7813\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  60%|██████    | 3/5 [00:00<00:00, 14.46batch/s]total loss: 0.67\n",
      "recon: 0.61\n",
      "reg: 1.31\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  9.71batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  4.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7875\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 17.63batch/s]total loss: 0.68\n",
      "recon: 0.63\n",
      "reg: 1.24\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00, 10.89batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7752\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  60%|██████    | 3/5 [00:00<00:00,  8.14batch/s]total loss: 0.79\n",
      "recon: 0.83\n",
      "reg: -1.03\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  7.03batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:01,  3.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8103\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 16.65batch/s]total loss: 1.67\n",
      "recon: 1.57\n",
      "reg: 2.63\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00, 11.05batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  5.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9874\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 16.74batch/s]total loss: 0.83\n",
      "recon: 0.84\n",
      "reg: -0.21\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00, 10.96batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  5.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8051\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 16.71batch/s]total loss: 0.89\n",
      "recon: 0.78\n",
      "reg: 2.67\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  9.75batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  5.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8288\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 15.66batch/s]total loss: 1.60\n",
      "recon: 1.57\n",
      "reg: 0.78\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 10.72batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  5.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9818\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 12.51batch/s]total loss: 0.67\n",
      "recon: 0.65\n",
      "reg: 0.51\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  9.43batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  5.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7946\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_02-59-10/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 2.193674236536, Time: 108.59s\n",
      "Epoch 200, Training Loss: 1.060906301625, Time: 219.51s\n",
      "Epoch 300, Training Loss: 0.644999486580, Time: 330.88s\n",
      "Epoch 400, Training Loss: 0.478699377365, Time: 443.40s\n",
      "Epoch 500, Training Loss: 0.362178700051, Time: 563.99s\n",
      "Epoch 600, Training Loss: 0.327802059054, Time: 686.71s\n",
      "Epoch 700, Training Loss: 0.299878383242, Time: 803.87s\n",
      "Epoch 800, Training Loss: 0.282054470474, Time: 917.28s\n",
      "Epoch 900, Training Loss: 0.265868064854, Time: 1027.56s\n",
      "Epoch 1000, Training Loss: 0.265819237521, Time: 1131.15s\n",
      "Validation Loss: 1.399520571530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>1.39952</td></tr><tr><td>val_loss</td><td>1.39952</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">playful-sweep-32</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/uxt78wvs' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/uxt78wvs</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_025909-uxt78wvs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9mfb5o2c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009686086315069405\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_031916-9mfb5o2c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/9mfb5o2c' target=\"_blank\">worthy-sweep-33</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/9mfb5o2c' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/9mfb5o2c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_03-19-17. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00, 23.75batch/s]total loss: 4.51\n",
      "recon: 4.39\n",
      "reg: 3.19\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00, 11.28batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:00,  4.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 7.4157\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 20.95batch/s]total loss: 1.84\n",
      "recon: 1.81\n",
      "reg: 0.75\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 11.69batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  5.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 2.5322\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00, 23.91batch/s]total loss: 0.96\n",
      "recon: 0.95\n",
      "reg: 0.44\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00, 12.93batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  6.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.6528\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  60%|██████    | 3/5 [00:00<00:00, 21.00batch/s]total loss: 1.17\n",
      "recon: 1.17\n",
      "reg: 0.02\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 13.08batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  5.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.548\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  60%|██████    | 3/5 [00:00<00:00, 22.76batch/s]total loss: 1.07\n",
      "recon: 1.06\n",
      "reg: 0.23\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00, 12.02batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  4.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.1917\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  60%|██████    | 3/5 [00:00<00:00, 23.98batch/s]total loss: 0.89\n",
      "recon: 0.76\n",
      "reg: 3.21\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 13.64batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  6.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0067\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  60%|██████    | 3/5 [00:00<00:00, 23.69batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.75\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 13.94batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  6.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8516\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  60%|██████    | 3/5 [00:00<00:00, 21.48batch/s]total loss: 0.63\n",
      "recon: 0.66\n",
      "reg: -0.56\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 13.20batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  5.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 23.26batch/s]total loss: 1.01\n",
      "recon: 0.86\n",
      "reg: 3.72\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 12.22batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  5.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9014\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  60%|██████    | 3/5 [00:00<00:00, 21.39batch/s]total loss: 0.64\n",
      "recon: 0.53\n",
      "reg: 2.67\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00, 13.85batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  6.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8144\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  60%|██████    | 3/5 [00:00<00:00, 21.36batch/s]total loss: 1.02\n",
      "recon: 0.89\n",
      "reg: 3.05\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 13.23batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  5.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9054\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  60%|██████    | 3/5 [00:00<00:00, 22.54batch/s]total loss: 0.72\n",
      "recon: 0.66\n",
      "reg: 1.72\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00, 12.12batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  6.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8954\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  60%|██████    | 3/5 [00:00<00:00, 21.55batch/s]total loss: 1.15\n",
      "recon: 1.13\n",
      "reg: 0.43\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 13.14batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  5.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9612\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  60%|██████    | 3/5 [00:00<00:00, 23.02batch/s]total loss: 0.47\n",
      "recon: 0.45\n",
      "reg: 0.54\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 13.34batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  5.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8024\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  60%|██████    | 3/5 [00:00<00:00, 23.17batch/s]total loss: 0.79\n",
      "recon: 0.80\n",
      "reg: -0.28\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00, 11.82batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  4.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8406\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  60%|██████    | 3/5 [00:00<00:00, 23.60batch/s]total loss: 0.78\n",
      "recon: 0.83\n",
      "reg: -1.23\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 13.73batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  5.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.826\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  60%|██████    | 3/5 [00:00<00:00, 23.35batch/s]total loss: 0.86\n",
      "recon: 0.78\n",
      "reg: 2.19\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00, 13.86batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  5.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8476\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00, 16.25batch/s]total loss: 0.77\n",
      "recon: 0.66\n",
      "reg: 2.76\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00, 11.21batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  5.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8322\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  60%|██████    | 3/5 [00:00<00:00, 15.27batch/s]total loss: 0.36\n",
      "recon: 0.47\n",
      "reg: -2.72\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 10.99batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  5.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7567\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  60%|██████    | 3/5 [00:00<00:00, 22.12batch/s]total loss: 1.00\n",
      "recon: 1.02\n",
      "reg: -0.57\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 13.44batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8815\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  60%|██████    | 3/5 [00:00<00:00, 21.97batch/s]total loss: 1.21\n",
      "recon: 1.15\n",
      "reg: 1.45\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 13.21batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  5.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9036\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 23.81batch/s]total loss: 0.54\n",
      "recon: 0.63\n",
      "reg: -2.22\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 11.41batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  4.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7696\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  60%|██████    | 3/5 [00:00<00:00, 22.58batch/s]total loss: 0.88\n",
      "recon: 0.85\n",
      "reg: 0.68\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00, 10.97batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:01,  3.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  60%|██████    | 3/5 [00:00<00:00, 21.97batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.39\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 13.26batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  5.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8985\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  60%|██████    | 3/5 [00:00<00:00, 22.82batch/s]total loss: 0.82\n",
      "recon: 0.78\n",
      "reg: 0.94\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 13.24batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  5.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8337\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 17.93batch/s]total loss: 1.18\n",
      "recon: 1.06\n",
      "reg: 3.01\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 11.34batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  5.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9003\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  60%|██████    | 3/5 [00:00<00:00, 22.64batch/s]total loss: 0.95\n",
      "recon: 0.79\n",
      "reg: 4.13\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 13.34batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  5.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8583\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  60%|██████    | 3/5 [00:00<00:00, 23.01batch/s]total loss: 0.76\n",
      "recon: 0.72\n",
      "reg: 1.00\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00, 13.31batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  5.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.875\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  60%|██████    | 3/5 [00:00<00:00, 22.60batch/s]total loss: 0.88\n",
      "recon: 0.85\n",
      "reg: 0.77\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 11.74batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  4.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8631\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  60%|██████    | 3/5 [00:00<00:00, 23.03batch/s]total loss: 0.59\n",
      "recon: 0.54\n",
      "reg: 1.34\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00, 10.69batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  3.67batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.783\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  60%|██████    | 3/5 [00:00<00:00, 23.81batch/s]total loss: 0.88\n",
      "recon: 0.93\n",
      "reg: -1.16\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 14.23batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  6.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.864\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  60%|██████    | 3/5 [00:00<00:00, 23.12batch/s]total loss: 0.87\n",
      "recon: 0.89\n",
      "reg: -0.46\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00, 11.31batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9144\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  60%|██████    | 3/5 [00:00<00:00, 21.56batch/s]total loss: 0.64\n",
      "recon: 0.67\n",
      "reg: -0.51\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00, 13.36batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  6.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8281\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  60%|██████    | 3/5 [00:00<00:00, 23.50batch/s]total loss: 0.84\n",
      "recon: 0.89\n",
      "reg: -1.27\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00, 13.46batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  5.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8405\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  60%|██████    | 3/5 [00:00<00:00, 21.26batch/s]total loss: 1.29\n",
      "recon: 1.23\n",
      "reg: 1.27\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00, 12.91batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  5.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9368\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 17.92batch/s]total loss: 0.54\n",
      "recon: 0.61\n",
      "reg: -1.93\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00, 10.86batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  5.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7786\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  60%|██████    | 3/5 [00:00<00:00, 22.52batch/s]total loss: 0.74\n",
      "recon: 0.77\n",
      "reg: -0.73\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 13.23batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  5.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8277\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 23.50batch/s]total loss: 0.70\n",
      "recon: 0.65\n",
      "reg: 1.26\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 12.67batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  5.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00, 21.79batch/s]total loss: 0.82\n",
      "recon: 0.76\n",
      "reg: 1.62\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00, 11.93batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  5.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  60%|██████    | 3/5 [00:00<00:00, 21.64batch/s]total loss: 1.32\n",
      "recon: 1.27\n",
      "reg: 1.28\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 13.13batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  5.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9308\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  60%|██████    | 3/5 [00:00<00:00, 21.62batch/s]total loss: 1.17\n",
      "recon: 1.03\n",
      "reg: 3.50\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 13.25batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  5.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.945\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  60%|██████    | 3/5 [00:00<00:00, 22.46batch/s]total loss: 1.31\n",
      "recon: 1.33\n",
      "reg: -0.61\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00, 11.80batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  4.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9402\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  60%|██████    | 3/5 [00:00<00:00, 22.71batch/s]total loss: 0.94\n",
      "recon: 0.93\n",
      "reg: 0.27\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 13.27batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  5.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8386\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  60%|██████    | 3/5 [00:00<00:00, 23.81batch/s]total loss: 0.89\n",
      "recon: 0.90\n",
      "reg: -0.15\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 13.65batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  5.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8388\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  60%|██████    | 3/5 [00:00<00:00, 21.20batch/s]total loss: 0.94\n",
      "recon: 0.88\n",
      "reg: 1.31\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00, 13.66batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  6.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8986\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00, 24.22batch/s]total loss: 0.96\n",
      "recon: 0.87\n",
      "reg: 2.06\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00, 12.81batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  5.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8585\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  60%|██████    | 3/5 [00:00<00:00, 22.09batch/s]total loss: 0.91\n",
      "recon: 0.94\n",
      "reg: -0.67\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 11.62batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  4.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8456\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  60%|██████    | 3/5 [00:00<00:00, 21.77batch/s]total loss: 1.01\n",
      "recon: 1.00\n",
      "reg: 0.39\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00, 12.74batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  5.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8724\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  60%|██████    | 3/5 [00:00<00:00, 14.79batch/s]total loss: 0.32\n",
      "recon: 0.53\n",
      "reg: -5.06\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 11.22batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  6.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7311\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  60%|██████    | 3/5 [00:00<00:00, 20.77batch/s]total loss: 1.08\n",
      "recon: 1.07\n",
      "reg: 0.19\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 12.94batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  5.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9476\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  60%|██████    | 3/5 [00:00<00:00, 22.80batch/s]total loss: 1.03\n",
      "recon: 0.97\n",
      "reg: 1.48\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 13.51batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  5.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9188\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 18.12batch/s]total loss: 0.70\n",
      "recon: 0.71\n",
      "reg: -0.15\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00, 11.78batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  6.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8173\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  60%|██████    | 3/5 [00:00<00:00, 21.45batch/s]total loss: 0.59\n",
      "recon: 0.57\n",
      "reg: 0.34\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 13.41batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  6.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7735\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  60%|██████    | 3/5 [00:00<00:00, 21.48batch/s]total loss: 0.63\n",
      "recon: 0.76\n",
      "reg: -3.06\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 13.42batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  6.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7683\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 21.42batch/s]total loss: 1.01\n",
      "recon: 1.06\n",
      "reg: -1.11\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 11.66batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  5.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8539\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  60%|██████    | 3/5 [00:00<00:00, 22.82batch/s]total loss: 0.78\n",
      "recon: 0.76\n",
      "reg: 0.34\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 13.43batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  5.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7999\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  60%|██████    | 3/5 [00:00<00:00, 23.19batch/s]total loss: 0.87\n",
      "recon: 0.71\n",
      "reg: 4.00\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 13.10batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  5.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8169\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 17.99batch/s]total loss: 0.90\n",
      "recon: 0.93\n",
      "reg: -0.84\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00, 11.66batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  5.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8261\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  60%|██████    | 3/5 [00:00<00:00, 22.79batch/s]total loss: 0.72\n",
      "recon: 0.64\n",
      "reg: 1.95\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 12.93batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  5.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7965\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00, 23.31batch/s]total loss: 0.27\n",
      "recon: 0.40\n",
      "reg: -3.34\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  9.69batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  3.48batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.6986\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 18.16batch/s]total loss: 0.53\n",
      "recon: 0.53\n",
      "reg: -0.02\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 11.23batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  5.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.758\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  60%|██████    | 3/5 [00:00<00:00, 22.55batch/s]total loss: 0.94\n",
      "recon: 0.99\n",
      "reg: -1.27\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 13.08batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  5.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8304\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  60%|██████    | 3/5 [00:00<00:00, 21.52batch/s]total loss: 0.64\n",
      "recon: 0.72\n",
      "reg: -1.93\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00, 11.25batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  5.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.764\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  60%|██████    | 3/5 [00:00<00:00, 22.27batch/s]total loss: 1.15\n",
      "recon: 1.02\n",
      "reg: 3.18\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00, 13.54batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  5.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8969\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  60%|██████    | 3/5 [00:00<00:00, 22.77batch/s]total loss: 0.79\n",
      "recon: 0.84\n",
      "reg: -1.17\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 13.34batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  5.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 20.64batch/s]total loss: 1.39\n",
      "recon: 1.31\n",
      "reg: 2.01\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 11.55batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  5.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9855\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  60%|██████    | 3/5 [00:00<00:00, 23.04batch/s]total loss: 0.75\n",
      "recon: 0.73\n",
      "reg: 0.63\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 13.57batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  5.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8467\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  60%|██████    | 3/5 [00:00<00:00, 21.28batch/s]total loss: 0.90\n",
      "recon: 0.81\n",
      "reg: 2.21\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00, 12.87batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  5.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8719\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 18.13batch/s]total loss: 0.83\n",
      "recon: 0.80\n",
      "reg: 0.72\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  9.99batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  4.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  60%|██████    | 3/5 [00:00<00:00, 21.57batch/s]total loss: 0.98\n",
      "recon: 1.10\n",
      "reg: -2.83\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 12.26batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  5.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8434\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  60%|██████    | 3/5 [00:00<00:00, 21.39batch/s]total loss: 0.56\n",
      "recon: 0.67\n",
      "reg: -2.76\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 13.33batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  5.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7928\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 17.47batch/s]total loss: 0.59\n",
      "recon: 0.59\n",
      "reg: 0.17\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00, 11.54batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  6.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8179\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  60%|██████    | 3/5 [00:00<00:00, 19.73batch/s]total loss: 0.74\n",
      "recon: 0.76\n",
      "reg: -0.45\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00, 13.11batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  6.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8241\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  60%|██████    | 3/5 [00:00<00:00, 22.21batch/s]total loss: 0.39\n",
      "recon: 0.38\n",
      "reg: 0.19\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 12.90batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  5.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7625\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 24.94batch/s]total loss: 0.74\n",
      "recon: 0.69\n",
      "reg: 1.08\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 12.88batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  5.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8117\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  60%|██████    | 3/5 [00:00<00:00, 21.53batch/s]total loss: 0.86\n",
      "recon: 0.87\n",
      "reg: -0.31\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 13.49batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  5.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8307\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  60%|██████    | 3/5 [00:00<00:00, 22.87batch/s]total loss: 1.05\n",
      "recon: 1.02\n",
      "reg: 0.84\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  9.37batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:01,  3.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9059\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 18.07batch/s]total loss: 0.72\n",
      "recon: 0.76\n",
      "reg: -0.88\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 11.67batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  5.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 23.58batch/s]total loss: 0.29\n",
      "recon: 0.39\n",
      "reg: -2.67\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 12.52batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  5.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  60%|██████    | 3/5 [00:00<00:00, 22.68batch/s]total loss: 0.75\n",
      "recon: 0.62\n",
      "reg: 3.38\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 13.41batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  5.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8195\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 21.49batch/s]total loss: 0.72\n",
      "recon: 0.73\n",
      "reg: -0.30\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 11.84batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  5.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8209\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  60%|██████    | 3/5 [00:00<00:00, 21.83batch/s]total loss: 0.48\n",
      "recon: 0.43\n",
      "reg: 1.26\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00, 12.84batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  5.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7822\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  60%|██████    | 3/5 [00:00<00:00, 22.01batch/s]total loss: 0.80\n",
      "recon: 0.74\n",
      "reg: 1.41\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00, 13.05batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  5.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8103\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 17.73batch/s]total loss: 0.87\n",
      "recon: 0.86\n",
      "reg: 0.21\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00, 11.59batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  5.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8218\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  60%|██████    | 3/5 [00:00<00:00, 22.08batch/s]total loss: 0.94\n",
      "recon: 0.84\n",
      "reg: 2.33\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 13.18batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  5.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8266\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  60%|██████    | 3/5 [00:00<00:00, 21.52batch/s]total loss: 0.95\n",
      "recon: 0.82\n",
      "reg: 3.14\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 11.57batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.841\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  60%|██████    | 3/5 [00:00<00:00, 22.90batch/s]total loss: 0.67\n",
      "recon: 0.76\n",
      "reg: -2.20\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 13.47batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  5.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7911\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  60%|██████    | 3/5 [00:00<00:00, 22.61batch/s]total loss: 1.15\n",
      "recon: 1.08\n",
      "reg: 1.95\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00, 13.71batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  6.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8897\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  60%|██████    | 3/5 [00:00<00:00, 22.16batch/s]total loss: 0.91\n",
      "recon: 0.92\n",
      "reg: -0.20\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00, 10.78batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8295\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  60%|██████    | 3/5 [00:00<00:00, 22.38batch/s]total loss: 0.71\n",
      "recon: 0.63\n",
      "reg: 1.79\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00, 10.27batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  3.49batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7831\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  60%|██████    | 3/5 [00:00<00:00, 21.72batch/s]total loss: 1.10\n",
      "recon: 1.04\n",
      "reg: 1.68\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00, 13.44batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  6.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8858\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 18.10batch/s]total loss: 0.65\n",
      "recon: 0.61\n",
      "reg: 0.84\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00, 11.63batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  5.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7896\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00, 24.71batch/s]total loss: 0.73\n",
      "recon: 0.63\n",
      "reg: 2.38\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00, 12.65batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  5.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8153\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  60%|██████    | 3/5 [00:00<00:00, 22.00batch/s]total loss: 0.69\n",
      "recon: 0.63\n",
      "reg: 1.54\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00, 12.92batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  5.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7791\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 19.81batch/s]total loss: 0.77\n",
      "recon: 0.84\n",
      "reg: -1.75\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 10.98batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  5.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  60%|██████    | 3/5 [00:00<00:00, 22.45batch/s]total loss: 1.78\n",
      "recon: 1.64\n",
      "reg: 3.51\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00, 13.29batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  5.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0121\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  60%|██████    | 3/5 [00:00<00:00, 21.87batch/s]total loss: 0.89\n",
      "recon: 0.90\n",
      "reg: -0.09\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00, 13.56batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  6.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.838\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  60%|██████    | 3/5 [00:00<00:00, 11.96batch/s]total loss: 0.91\n",
      "recon: 0.82\n",
      "reg: 2.32\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  9.53batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  5.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8429\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  60%|██████    | 3/5 [00:00<00:00, 23.68batch/s]total loss: 1.61\n",
      "recon: 1.56\n",
      "reg: 1.14\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 14.25batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  6.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9772\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  60%|██████    | 3/5 [00:00<00:00, 22.29batch/s]total loss: 0.62\n",
      "recon: 0.61\n",
      "reg: 0.21\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00, 11.44batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8091\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_03-19-17/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 1.353561456501, Time: 102.43s\n",
      "Epoch 200, Training Loss: 0.688020602986, Time: 205.35s\n",
      "Epoch 300, Training Loss: 0.489828195050, Time: 308.02s\n",
      "Epoch 400, Training Loss: 0.455650882050, Time: 421.05s\n",
      "Epoch 500, Training Loss: 0.397172904434, Time: 535.15s\n",
      "Epoch 600, Training Loss: 0.290367744374, Time: 644.56s\n",
      "Epoch 700, Training Loss: 0.251834271476, Time: 755.10s\n",
      "Epoch 800, Training Loss: 0.241532545444, Time: 865.71s\n",
      "Epoch 900, Training Loss: 0.229648999497, Time: 978.71s\n",
      "Epoch 1000, Training Loss: 0.214828629233, Time: 1092.41s\n",
      "Validation Loss: 0.343854852021\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.34385</td></tr><tr><td>val_loss</td><td>0.34385</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worthy-sweep-33</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/9mfb5o2c' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/9mfb5o2c</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_031916-9mfb5o2c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n986zwe0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008402959041283744\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_033830-n986zwe0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/n986zwe0' target=\"_blank\">charmed-sweep-34</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/n986zwe0' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/n986zwe0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_03-38-31. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 18.17batch/s]total loss: 4.22\n",
      "recon: 3.77\n",
      "reg: 11.31\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00, 10.70batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:00,  4.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 5.8681\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 16.98batch/s]total loss: 1.65\n",
      "recon: 1.54\n",
      "reg: 2.77\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00,  9.45batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:01,  3.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 2.0765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 16.36batch/s]total loss: 1.12\n",
      "recon: 1.00\n",
      "reg: 3.06\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  7.48batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:01,  2.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.3569\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 19.03batch/s]total loss: 0.75\n",
      "recon: 0.73\n",
      "reg: 0.54\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 11.48batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.3297\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  60%|██████    | 3/5 [00:00<00:00, 15.62batch/s]total loss: 0.75\n",
      "recon: 0.72\n",
      "reg: 0.86\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  9.57batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  5.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9718\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 12.25batch/s]total loss: 0.86\n",
      "recon: 0.67\n",
      "reg: 4.65\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00,  9.44batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  5.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 14.93batch/s]total loss: 0.58\n",
      "recon: 0.62\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00,  9.18batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  5.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8504\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 18.57batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.41\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00,  9.99batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:01,  3.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8605\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  60%|██████    | 3/5 [00:00<00:00, 15.08batch/s]total loss: 1.01\n",
      "recon: 0.83\n",
      "reg: 4.63\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  9.96batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  4.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8974\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 17.94batch/s]total loss: 0.63\n",
      "recon: 0.53\n",
      "reg: 2.50\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00, 11.63batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  5.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8088\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  60%|██████    | 3/5 [00:00<00:00, 14.26batch/s]total loss: 0.84\n",
      "recon: 0.68\n",
      "reg: 4.15\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 10.84batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  6.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8563\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00, 14.58batch/s]total loss: 0.83\n",
      "recon: 0.70\n",
      "reg: 3.16\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  8.79batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0289\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 17.66batch/s]total loss: 0.90\n",
      "recon: 0.87\n",
      "reg: 0.61\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00,  9.85batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:01,  3.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 14.46batch/s]total loss: 0.50\n",
      "recon: 0.48\n",
      "reg: 0.51\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 10.19batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  5.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8685\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  60%|██████    | 3/5 [00:00<00:00, 13.58batch/s]total loss: 0.73\n",
      "recon: 0.74\n",
      "reg: -0.29\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00, 10.34batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  5.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.945\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  60%|██████    | 3/5 [00:00<00:00, 14.21batch/s]total loss: 0.84\n",
      "recon: 0.88\n",
      "reg: -0.84\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 10.16batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  5.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9212\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 18.09batch/s]total loss: 1.04\n",
      "recon: 0.98\n",
      "reg: 1.45\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00,  9.97batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:01,  3.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9489\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00, 17.92batch/s]total loss: 0.80\n",
      "recon: 0.66\n",
      "reg: 3.54\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00,  8.21batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:01,  2.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 18.34batch/s]total loss: 0.41\n",
      "recon: 0.50\n",
      "reg: -2.36\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 10.28batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  4.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7855\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 18.11batch/s]total loss: 1.01\n",
      "recon: 1.02\n",
      "reg: -0.26\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 11.47batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9014\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 15.48batch/s]total loss: 1.25\n",
      "recon: 1.16\n",
      "reg: 2.12\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 10.90batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  5.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9263\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 12.42batch/s]total loss: 0.56\n",
      "recon: 0.64\n",
      "reg: -2.12\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00,  9.09batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  4.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.792\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 16.82batch/s]total loss: 0.90\n",
      "recon: 0.86\n",
      "reg: 0.97\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  9.67batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  4.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8642\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 18.94batch/s]total loss: 1.04\n",
      "recon: 1.03\n",
      "reg: 0.46\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 11.20batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  60%|██████    | 3/5 [00:00<00:00, 14.64batch/s]total loss: 0.85\n",
      "recon: 0.80\n",
      "reg: 1.07\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 10.66batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  5.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8486\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 13.18batch/s]total loss: 1.23\n",
      "recon: 1.09\n",
      "reg: 3.67\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 10.12batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  5.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 18.87batch/s]total loss: 0.90\n",
      "recon: 0.72\n",
      "reg: 4.61\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 10.23batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:01,  3.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8568\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 14.21batch/s]total loss: 0.67\n",
      "recon: 0.62\n",
      "reg: 1.08\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  8.23batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:01,  3.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8687\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 15.88batch/s]total loss: 0.96\n",
      "recon: 0.90\n",
      "reg: 1.38\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 10.17batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  4.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8994\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:00<00:00, 16.32batch/s]total loss: 0.66\n",
      "recon: 0.59\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  8.49batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  3.26batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.821\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  60%|██████    | 3/5 [00:00<00:00,  8.19batch/s]total loss: 0.99\n",
      "recon: 1.01\n",
      "reg: -0.54\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00,  6.94batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9282\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 18.64batch/s]total loss: 0.90\n",
      "recon: 0.92\n",
      "reg: -0.43\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  9.21batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:01,  3.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9571\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 18.39batch/s]total loss: 0.69\n",
      "recon: 0.72\n",
      "reg: -0.65\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  9.44batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:01,  3.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  60%|██████    | 3/5 [00:00<00:00, 12.42batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  8.26batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:01,  3.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8364\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 19.15batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.17\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  9.87batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:01,  3.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9152\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 16.30batch/s]total loss: 0.61\n",
      "recon: 0.66\n",
      "reg: -1.35\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00, 10.26batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  60%|██████    | 3/5 [00:00<00:00, 14.45batch/s]total loss: 0.67\n",
      "recon: 0.71\n",
      "reg: -0.88\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00,  9.16batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8229\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 22.68batch/s]total loss: 0.75\n",
      "recon: 0.71\n",
      "reg: 1.01\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00,  9.27batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:01,  3.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8788\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  60%|██████    | 3/5 [00:00<00:00, 15.05batch/s]total loss: 0.86\n",
      "recon: 0.79\n",
      "reg: 1.79\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00, 10.03batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8673\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  60%|██████    | 3/5 [00:00<00:00, 14.61batch/s]total loss: 1.31\n",
      "recon: 1.27\n",
      "reg: 1.05\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 10.63batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  5.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 12.91batch/s]total loss: 1.20\n",
      "recon: 1.07\n",
      "reg: 3.32\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00,  9.66batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  5.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9633\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 14.81batch/s]total loss: 1.30\n",
      "recon: 1.31\n",
      "reg: -0.36\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  4.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9496\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 16.34batch/s]total loss: 0.93\n",
      "recon: 0.93\n",
      "reg: 0.17\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00,  8.39batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:01,  3.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  60%|██████    | 3/5 [00:00<00:00, 19.48batch/s]total loss: 0.94\n",
      "recon: 0.92\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00,  9.46batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:01,  3.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8562\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 18.61batch/s]total loss: 0.93\n",
      "recon: 0.88\n",
      "reg: 1.24\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  9.10batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:01,  3.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  60%|██████    | 3/5 [00:00<00:00, 13.31batch/s]total loss: 0.97\n",
      "recon: 0.88\n",
      "reg: 2.09\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00,  9.85batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  5.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8641\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 18.74batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.15\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  8.75batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  4.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8433\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 16.84batch/s]total loss: 1.01\n",
      "recon: 0.98\n",
      "reg: 0.77\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  9.78batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  4.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  60%|██████    | 3/5 [00:00<00:00, 14.61batch/s]total loss: 0.34\n",
      "recon: 0.52\n",
      "reg: -4.56\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 10.02batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  5.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 16.10batch/s]total loss: 1.08\n",
      "recon: 1.06\n",
      "reg: 0.47\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 10.68batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  5.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9505\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 11.91batch/s]total loss: 1.03\n",
      "recon: 0.97\n",
      "reg: 1.44\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00,  8.44batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  4.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9209\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 16.88batch/s]total loss: 0.71\n",
      "recon: 0.72\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  9.99batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  5.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8215\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 18.13batch/s]total loss: 0.61\n",
      "recon: 0.59\n",
      "reg: 0.44\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00,  9.16batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:01,  3.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.779\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 16.78batch/s]total loss: 0.64\n",
      "recon: 0.76\n",
      "reg: -2.85\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 10.52batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7735\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 14.59batch/s]total loss: 0.98\n",
      "recon: 1.03\n",
      "reg: -1.16\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  9.24batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  5.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 13.57batch/s]total loss: 0.81\n",
      "recon: 0.78\n",
      "reg: 0.95\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00,  9.16batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8081\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 12.04batch/s]total loss: 0.88\n",
      "recon: 0.72\n",
      "reg: 3.95\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00,  9.43batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  5.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8261\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 19.61batch/s]total loss: 0.86\n",
      "recon: 0.93\n",
      "reg: -1.69\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00, 10.26batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  4.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8217\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 18.80batch/s]total loss: 0.74\n",
      "recon: 0.65\n",
      "reg: 2.22\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 10.74batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8079\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  60%|██████    | 3/5 [00:00<00:00, 15.42batch/s]total loss: 0.30\n",
      "recon: 0.42\n",
      "reg: -2.93\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  8.48batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  3.24batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.714\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 12.15batch/s]total loss: 0.57\n",
      "recon: 0.56\n",
      "reg: 0.40\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00,  8.96batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  5.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7736\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 17.48batch/s]total loss: 0.92\n",
      "recon: 0.96\n",
      "reg: -0.93\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00,  9.41batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:01,  3.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8327\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  60%|██████    | 3/5 [00:00<00:00, 12.91batch/s]total loss: 0.62\n",
      "recon: 0.68\n",
      "reg: -1.56\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  8.15batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:01,  3.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7675\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  60%|██████    | 3/5 [00:00<00:00, 14.15batch/s]total loss: 1.13\n",
      "recon: 1.00\n",
      "reg: 3.27\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  8.30batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:01,  3.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8851\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 18.11batch/s]total loss: 0.75\n",
      "recon: 0.79\n",
      "reg: -0.97\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 11.21batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  5.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7985\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 15.22batch/s]total loss: 1.36\n",
      "recon: 1.28\n",
      "reg: 2.04\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00,  9.31batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  4.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9811\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 14.10batch/s]total loss: 0.80\n",
      "recon: 0.78\n",
      "reg: 0.62\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 10.38batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  5.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9199\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 19.61batch/s]total loss: 0.96\n",
      "recon: 0.86\n",
      "reg: 2.54\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00, 10.54batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  4.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9219\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 19.16batch/s]total loss: 0.86\n",
      "recon: 0.83\n",
      "reg: 0.78\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  9.36batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:01,  3.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8767\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 17.67batch/s]total loss: 0.94\n",
      "recon: 1.05\n",
      "reg: -2.69\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 10.15batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  4.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 17.31batch/s]total loss: 0.60\n",
      "recon: 0.70\n",
      "reg: -2.41\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 11.54batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  5.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7882\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 15.42batch/s]total loss: 0.58\n",
      "recon: 0.57\n",
      "reg: 0.32\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  9.80batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  5.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.799\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 14.53batch/s]total loss: 0.73\n",
      "recon: 0.74\n",
      "reg: -0.11\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  9.65batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  4.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8149\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 18.80batch/s]total loss: 0.38\n",
      "recon: 0.38\n",
      "reg: 0.15\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00,  9.84batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:01,  3.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.753\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  60%|██████    | 3/5 [00:00<00:00, 13.52batch/s]total loss: 0.71\n",
      "recon: 0.69\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00,  9.08batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  4.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.795\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 11.01batch/s]total loss: 0.83\n",
      "recon: 0.84\n",
      "reg: -0.28\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00,  8.95batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  5.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8184\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  80%|████████  | 4/5 [00:00<00:00, 11.61batch/s]total loss: 1.08\n",
      "recon: 1.03\n",
      "reg: 1.25\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  8.34batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8889\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 13.25batch/s]total loss: 0.58\n",
      "recon: 0.61\n",
      "reg: -0.67\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 10.05batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  5.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7991\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 18.97batch/s]total loss: 0.37\n",
      "recon: 0.47\n",
      "reg: -2.28\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 10.03batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:01,  3.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7713\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 17.82batch/s]total loss: 0.75\n",
      "recon: 0.62\n",
      "reg: 3.28\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  8.57batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:01,  3.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8041\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 19.20batch/s]total loss: 0.73\n",
      "recon: 0.75\n",
      "reg: -0.57\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 12.17batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  5.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7942\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 14.62batch/s]total loss: 0.50\n",
      "recon: 0.45\n",
      "reg: 1.35\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00, 13.35batch/s]total loss: 0.76\n",
      "recon: 0.73\n",
      "reg: 0.81\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  8.22batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  5.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 13.32batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.12\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  9.76batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  5.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 11.76batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.13\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  9.21batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  5.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8398\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  60%|██████    | 3/5 [00:00<00:00, 14.67batch/s]total loss: 0.97\n",
      "recon: 0.86\n",
      "reg: 2.88\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  9.16batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:01,  3.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8718\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 18.50batch/s]total loss: 0.64\n",
      "recon: 0.73\n",
      "reg: -2.26\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 10.99batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 17.22batch/s]total loss: 1.19\n",
      "recon: 1.11\n",
      "reg: 1.96\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00, 10.30batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9163\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 11.82batch/s]total loss: 0.93\n",
      "recon: 0.92\n",
      "reg: 0.26\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  8.78batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  5.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8425\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 11.50batch/s]total loss: 0.65\n",
      "recon: 0.60\n",
      "reg: 1.23\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  7.40batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  3.26batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7892\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  60%|██████    | 3/5 [00:00<00:00, 20.34batch/s]total loss: 1.10\n",
      "recon: 1.01\n",
      "reg: 2.28\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  9.31batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:01,  3.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8862\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 18.04batch/s]total loss: 0.61\n",
      "recon: 0.58\n",
      "reg: 0.67\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  9.92batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:01,  3.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7965\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  60%|██████    | 3/5 [00:00<00:00, 13.02batch/s]total loss: 0.78\n",
      "recon: 0.71\n",
      "reg: 1.69\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  9.84batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  60%|██████    | 3/5 [00:00<00:00, 11.12batch/s]total loss: 0.71\n",
      "recon: 0.65\n",
      "reg: 1.51\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  8.92batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  5.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 15.04batch/s]total loss: 0.81\n",
      "recon: 0.86\n",
      "reg: -1.24\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 10.71batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  5.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 18.63batch/s]total loss: 1.77\n",
      "recon: 1.65\n",
      "reg: 2.95\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  9.05batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:01,  3.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 16.31batch/s]total loss: 0.87\n",
      "recon: 0.87\n",
      "reg: 0.02\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  8.97batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:01,  3.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8254\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 18.76batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.28\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00, 11.22batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8351\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 16.56batch/s]total loss: 1.59\n",
      "recon: 1.55\n",
      "reg: 1.00\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 11.13batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  5.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9762\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 11.02batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.61\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  8.41batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  5.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8294\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_03-38-31/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.255701720901, Time: 125.82s\n",
      "Epoch 200, Training Loss: 0.131409470923, Time: 271.59s\n",
      "Epoch 300, Training Loss: 0.067633039749, Time: 388.09s\n",
      "Epoch 400, Training Loss: 0.039594843505, Time: 499.14s\n",
      "Epoch 500, Training Loss: 0.012818424488, Time: 611.52s\n",
      "Epoch 600, Training Loss: 0.007906403818, Time: 723.07s\n",
      "Epoch 700, Training Loss: 0.006631630821, Time: 834.83s\n",
      "Epoch 800, Training Loss: 0.003244960273, Time: 945.47s\n",
      "Epoch 900, Training Loss: 0.002754969009, Time: 1059.28s\n",
      "Epoch 1000, Training Loss: 0.002386060804, Time: 1175.11s\n",
      "Validation Loss: 0.070456305779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.07046</td></tr><tr><td>val_loss</td><td>0.07046</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">charmed-sweep-34</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/n986zwe0' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/n986zwe0</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_033830-n986zwe0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0d2v5sk7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.009484692176425105\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_035921-0d2v5sk7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/0d2v5sk7' target=\"_blank\">fine-sweep-35</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/0d2v5sk7' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/0d2v5sk7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_03-59-22. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  80%|████████  | 4/5 [00:00<00:00, 17.46batch/s]total loss: 4.22\n",
      "recon: 3.77\n",
      "reg: 11.31\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  9.79batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:01,  3.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 5.8681\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 18.57batch/s]total loss: 1.65\n",
      "recon: 1.54\n",
      "reg: 2.77\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 12.19batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  6.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 2.0765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  60%|██████    | 3/5 [00:00<00:00, 21.30batch/s]total loss: 1.12\n",
      "recon: 1.00\n",
      "reg: 3.06\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00, 10.51batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:01,  3.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.3569\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  60%|██████    | 3/5 [00:00<00:00, 19.92batch/s]total loss: 0.75\n",
      "recon: 0.73\n",
      "reg: 0.54\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 12.31batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  5.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.3297\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  60%|██████    | 3/5 [00:00<00:00, 11.72batch/s]total loss: 0.75\n",
      "recon: 0.72\n",
      "reg: 0.86\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  8.88batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  4.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9718\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 22.75batch/s]total loss: 0.86\n",
      "recon: 0.67\n",
      "reg: 4.65\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 11.50batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 21.15batch/s]total loss: 0.58\n",
      "recon: 0.62\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 11.49batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  5.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8504\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 18.62batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.41\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 10.53batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  4.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8605\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 17.24batch/s]total loss: 1.01\n",
      "recon: 0.83\n",
      "reg: 4.63\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 11.76batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  5.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8974\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 18.46batch/s]total loss: 0.63\n",
      "recon: 0.53\n",
      "reg: 2.50\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00, 12.12batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  5.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8088\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 19.69batch/s]total loss: 0.84\n",
      "recon: 0.68\n",
      "reg: 4.15\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 11.97batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  5.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8563\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  60%|██████    | 3/5 [00:00<00:00, 13.71batch/s]total loss: 0.83\n",
      "recon: 0.70\n",
      "reg: 3.16\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00, 10.60batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  5.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0289\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 16.86batch/s]total loss: 0.90\n",
      "recon: 0.87\n",
      "reg: 0.61\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00,  9.99batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  5.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 18.05batch/s]total loss: 0.50\n",
      "recon: 0.48\n",
      "reg: 0.51\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 11.93batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  5.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8685\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 14.94batch/s]total loss: 0.73\n",
      "recon: 0.74\n",
      "reg: -0.29\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00, 10.10batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  5.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.945\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 19.01batch/s]total loss: 0.84\n",
      "recon: 0.88\n",
      "reg: -0.84\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 10.59batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9212\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  60%|██████    | 3/5 [00:00<00:00, 20.72batch/s]total loss: 1.04\n",
      "recon: 0.98\n",
      "reg: 1.45\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00, 12.80batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  5.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9489\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  60%|██████    | 3/5 [00:00<00:00, 12.37batch/s]total loss: 0.80\n",
      "recon: 0.66\n",
      "reg: 3.54\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00,  8.43batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  5.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 17.95batch/s]total loss: 0.41\n",
      "recon: 0.50\n",
      "reg: -2.36\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 11.61batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  5.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7855\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 13.99batch/s]total loss: 1.01\n",
      "recon: 1.02\n",
      "reg: -0.26\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 10.03batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9014\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 17.41batch/s]total loss: 1.25\n",
      "recon: 1.16\n",
      "reg: 2.12\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 10.39batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  4.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9263\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 14.78batch/s]total loss: 0.56\n",
      "recon: 0.64\n",
      "reg: -2.12\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00,  7.17batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:01,  2.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.792\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  60%|██████    | 3/5 [00:00<00:00, 20.01batch/s]total loss: 0.90\n",
      "recon: 0.86\n",
      "reg: 0.97\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00, 11.92batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  5.12batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8642\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 19.11batch/s]total loss: 1.04\n",
      "recon: 1.03\n",
      "reg: 0.46\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 11.57batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  5.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  60%|██████    | 3/5 [00:00<00:00, 15.20batch/s]total loss: 0.85\n",
      "recon: 0.80\n",
      "reg: 1.07\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 10.90batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  6.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8486\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 16.68batch/s]total loss: 1.23\n",
      "recon: 1.09\n",
      "reg: 3.67\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 11.44batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  5.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 18.00batch/s]total loss: 0.90\n",
      "recon: 0.72\n",
      "reg: 4.61\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 12.06batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  5.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8568\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  60%|██████    | 3/5 [00:00<00:00, 14.61batch/s]total loss: 0.67\n",
      "recon: 0.62\n",
      "reg: 1.08\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  9.92batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  5.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8687\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 15.26batch/s]total loss: 0.96\n",
      "recon: 0.90\n",
      "reg: 1.38\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 10.36batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  4.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8994\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00, 23.26batch/s]total loss: 0.66\n",
      "recon: 0.59\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  9.40batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  3.26batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.821\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 23.35batch/s]total loss: 0.99\n",
      "recon: 1.01\n",
      "reg: -0.54\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 11.76batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9282\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00,  9.14batch/s]total loss: 0.90\n",
      "recon: 0.92\n",
      "reg: -0.43\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  7.40batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9571\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 16.72batch/s]total loss: 0.69\n",
      "recon: 0.72\n",
      "reg: -0.65\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00, 10.46batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  4.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 17.26batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00, 11.31batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  5.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8364\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 17.93batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.17\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00, 11.83batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  5.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9152\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 18.62batch/s]total loss: 0.61\n",
      "recon: 0.66\n",
      "reg: -1.35\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00, 11.70batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  5.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 17.40batch/s]total loss: 0.67\n",
      "recon: 0.71\n",
      "reg: -0.88\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 11.01batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  5.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8229\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 19.70batch/s]total loss: 0.75\n",
      "recon: 0.71\n",
      "reg: 1.01\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 11.72batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  5.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8788\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 19.61batch/s]total loss: 0.86\n",
      "recon: 0.79\n",
      "reg: 1.79\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00, 10.46batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  4.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8673\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 17.60batch/s]total loss: 1.31\n",
      "recon: 1.27\n",
      "reg: 1.05\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 11.56batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  5.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 16.49batch/s]total loss: 1.20\n",
      "recon: 1.07\n",
      "reg: 3.32\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 10.92batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  5.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9633\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 17.43batch/s]total loss: 1.30\n",
      "recon: 1.31\n",
      "reg: -0.36\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00, 11.22batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  5.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9496\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 17.66batch/s]total loss: 0.93\n",
      "recon: 0.93\n",
      "reg: 0.17\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 11.40batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  5.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 19.20batch/s]total loss: 0.94\n",
      "recon: 0.92\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 10.94batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8562\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 18.15batch/s]total loss: 0.93\n",
      "recon: 0.88\n",
      "reg: 1.24\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00, 11.51batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  60%|██████    | 3/5 [00:00<00:00, 13.90batch/s]total loss: 0.97\n",
      "recon: 0.88\n",
      "reg: 2.09\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00, 10.53batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  5.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8641\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 16.96batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.15\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 11.32batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  5.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8433\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 19.81batch/s]total loss: 1.01\n",
      "recon: 0.98\n",
      "reg: 0.77\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00, 11.70batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  5.02batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 14.58batch/s]total loss: 0.34\n",
      "recon: 0.52\n",
      "reg: -4.56\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00,  9.60batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  4.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 18.60batch/s]total loss: 1.08\n",
      "recon: 1.06\n",
      "reg: 0.47\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 11.04batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9505\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 18.77batch/s]total loss: 1.03\n",
      "recon: 0.97\n",
      "reg: 1.44\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 11.84batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  5.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9209\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  60%|██████    | 3/5 [00:00<00:00, 15.30batch/s]total loss: 0.71\n",
      "recon: 0.72\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00, 10.58batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  5.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8215\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 11.20batch/s]total loss: 0.61\n",
      "recon: 0.59\n",
      "reg: 0.44\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00,  9.20batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  5.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.779\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 18.83batch/s]total loss: 0.64\n",
      "recon: 0.76\n",
      "reg: -2.85\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 11.57batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  5.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7735\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  60%|██████    | 3/5 [00:00<00:00, 12.15batch/s]total loss: 0.98\n",
      "recon: 1.03\n",
      "reg: -1.16\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  7.52batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:01,  3.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 11.86batch/s]total loss: 0.81\n",
      "recon: 0.78\n",
      "reg: 0.95\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00,  6.38batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:01,  2.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8081\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00,  5.55batch/s]total loss: 0.88\n",
      "recon: 0.72\n",
      "reg: 3.95\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:01<00:00,  3.83batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:01,  3.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8261\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 15.60batch/s]total loss: 0.86\n",
      "recon: 0.93\n",
      "reg: -1.69\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  8.39batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:01,  3.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8217\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 18.57batch/s]total loss: 0.74\n",
      "recon: 0.65\n",
      "reg: 2.22\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 10.13batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:01,  3.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8079\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00,  8.65batch/s]total loss: 0.30\n",
      "recon: 0.42\n",
      "reg: -2.93\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  6.36batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  2.97batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.714\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  60%|██████    | 3/5 [00:00<00:00, 20.36batch/s]total loss: 0.57\n",
      "recon: 0.56\n",
      "reg: 0.40\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 11.12batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7736\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 14.28batch/s]total loss: 0.92\n",
      "recon: 0.96\n",
      "reg: -0.93\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00,  8.90batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:01,  3.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8327\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 12.09batch/s]total loss: 0.62\n",
      "recon: 0.68\n",
      "reg: -1.56\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  8.70batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  4.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7675\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 15.26batch/s]total loss: 1.13\n",
      "recon: 1.00\n",
      "reg: 3.27\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00, 10.63batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  5.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8851\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 14.84batch/s]total loss: 0.75\n",
      "recon: 0.79\n",
      "reg: -0.97\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00,  9.59batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  4.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7985\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 18.76batch/s]total loss: 1.36\n",
      "recon: 1.28\n",
      "reg: 2.04\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 11.53batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  5.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9811\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 16.81batch/s]total loss: 0.80\n",
      "recon: 0.78\n",
      "reg: 0.62\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00,  9.94batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  5.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9199\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  60%|██████    | 3/5 [00:00<00:00, 14.36batch/s]total loss: 0.96\n",
      "recon: 0.86\n",
      "reg: 2.54\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  9.09batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  4.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9219\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  60%|██████    | 3/5 [00:00<00:00, 13.90batch/s]total loss: 0.86\n",
      "recon: 0.83\n",
      "reg: 0.78\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00, 10.19batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  5.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8767\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 17.91batch/s]total loss: 0.94\n",
      "recon: 1.05\n",
      "reg: -2.69\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 10.23batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  4.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 17.24batch/s]total loss: 0.60\n",
      "recon: 0.70\n",
      "reg: -2.41\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 11.68batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  5.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7882\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 19.22batch/s]total loss: 0.58\n",
      "recon: 0.57\n",
      "reg: 0.32\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00, 10.38batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  4.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.799\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00, 12.73batch/s]total loss: 0.73\n",
      "recon: 0.74\n",
      "reg: -0.11\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  7.59batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  4.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8149\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 17.84batch/s]total loss: 0.38\n",
      "recon: 0.38\n",
      "reg: 0.15\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 11.48batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  5.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.753\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 18.10batch/s]total loss: 0.71\n",
      "recon: 0.69\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 12.04batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  5.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.795\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 16.46batch/s]total loss: 0.83\n",
      "recon: 0.84\n",
      "reg: -0.28\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00,  9.89batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  5.65batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8184\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  80%|████████  | 4/5 [00:00<00:00, 18.31batch/s]total loss: 1.08\n",
      "recon: 1.03\n",
      "reg: 1.25\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00, 11.08batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8889\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 17.58batch/s]total loss: 0.58\n",
      "recon: 0.61\n",
      "reg: -0.67\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 11.44batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  5.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7991\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  60%|██████    | 3/5 [00:00<00:00, 13.23batch/s]total loss: 0.37\n",
      "recon: 0.47\n",
      "reg: -2.28\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00,  9.76batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7713\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  60%|██████    | 3/5 [00:00<00:00, 13.99batch/s]total loss: 0.75\n",
      "recon: 0.62\n",
      "reg: 3.28\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 10.29batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  5.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8041\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 16.91batch/s]total loss: 0.73\n",
      "recon: 0.75\n",
      "reg: -0.57\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 10.94batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  5.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7942\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 11.30batch/s]total loss: 0.50\n",
      "recon: 0.45\n",
      "reg: 1.35\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  7.43batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:01,  3.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 17.43batch/s]total loss: 0.76\n",
      "recon: 0.73\n",
      "reg: 0.81\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00, 11.90batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  5.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 17.89batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.12\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  9.76batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:01,  3.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 18.69batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.13\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 10.66batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  4.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8398\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 19.22batch/s]total loss: 0.97\n",
      "recon: 0.86\n",
      "reg: 2.88\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 11.83batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  5.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8718\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 16.56batch/s]total loss: 0.64\n",
      "recon: 0.73\n",
      "reg: -2.26\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  9.98batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 18.26batch/s]total loss: 1.19\n",
      "recon: 1.11\n",
      "reg: 1.96\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00, 10.65batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9163\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 15.61batch/s]total loss: 0.93\n",
      "recon: 0.92\n",
      "reg: 0.26\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  9.50batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8425\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  60%|██████    | 3/5 [00:00<00:00, 15.00batch/s]total loss: 0.65\n",
      "recon: 0.60\n",
      "reg: 1.23\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  7.11batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.51batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7892\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00, 22.99batch/s]total loss: 1.10\n",
      "recon: 1.01\n",
      "reg: 2.28\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00, 11.34batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  4.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8862\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 18.46batch/s]total loss: 0.61\n",
      "recon: 0.58\n",
      "reg: 0.67\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00, 10.31batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  5.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7965\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 19.03batch/s]total loss: 0.78\n",
      "recon: 0.71\n",
      "reg: 1.69\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00, 10.80batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 18.23batch/s]total loss: 0.71\n",
      "recon: 0.65\n",
      "reg: 1.51\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00, 10.63batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 13.65batch/s]total loss: 0.81\n",
      "recon: 0.86\n",
      "reg: -1.24\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  9.64batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 16.98batch/s]total loss: 1.77\n",
      "recon: 1.65\n",
      "reg: 2.95\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  9.01batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:01,  3.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 18.47batch/s]total loss: 0.87\n",
      "recon: 0.87\n",
      "reg: 0.02\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  9.90batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:01,  3.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8254\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 16.34batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.28\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00, 10.83batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  5.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8351\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 15.80batch/s]total loss: 1.59\n",
      "recon: 1.55\n",
      "reg: 1.00\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 10.84batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  5.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9762\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 18.47batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.61\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00, 10.62batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  5.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8294\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_03-59-22/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.255701720901, Time: 111.94s\n",
      "Epoch 200, Training Loss: 0.131409470923, Time: 224.51s\n",
      "Epoch 300, Training Loss: 0.067633039749, Time: 337.89s\n",
      "Epoch 400, Training Loss: 0.039594843505, Time: 451.09s\n",
      "Epoch 500, Training Loss: 0.012818424488, Time: 564.45s\n",
      "Epoch 600, Training Loss: 0.007906403818, Time: 677.74s\n",
      "Epoch 700, Training Loss: 0.006631630821, Time: 792.94s\n",
      "Epoch 800, Training Loss: 0.003244960273, Time: 908.74s\n",
      "Epoch 900, Training Loss: 0.002754969009, Time: 1027.13s\n",
      "Epoch 1000, Training Loss: 0.002386060804, Time: 1142.06s\n",
      "Validation Loss: 0.070456305779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.07046</td></tr><tr><td>val_loss</td><td>0.07046</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-sweep-35</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/0d2v5sk7' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/0d2v5sk7</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_035921-0d2v5sk7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v2areq9r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.012472071579617662\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_041942-v2areq9r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/v2areq9r' target=\"_blank\">noble-sweep-36</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/v2areq9r' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/v2areq9r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_04-19-43. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00, 23.04batch/s]total loss: 4.22\n",
      "recon: 3.77\n",
      "reg: 11.31\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00, 10.85batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:00,  4.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 5.8681\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  60%|██████    | 3/5 [00:00<00:00, 14.93batch/s]total loss: 1.65\n",
      "recon: 1.54\n",
      "reg: 2.77\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 10.58batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  5.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 2.0765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 16.10batch/s]total loss: 1.12\n",
      "recon: 1.00\n",
      "reg: 3.06\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00, 11.22batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  5.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.3569\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  60%|██████    | 3/5 [00:00<00:00, 21.71batch/s]total loss: 0.75\n",
      "recon: 0.73\n",
      "reg: 0.54\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 11.68batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  5.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.3297\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 15.23batch/s]total loss: 0.75\n",
      "recon: 0.72\n",
      "reg: 0.86\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  9.04batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:01,  3.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9718\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  60%|██████    | 3/5 [00:00<00:00, 19.52batch/s]total loss: 0.86\n",
      "recon: 0.67\n",
      "reg: 4.65\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 10.87batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  4.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 19.37batch/s]total loss: 0.58\n",
      "recon: 0.62\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 10.26batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:01,  3.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8504\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  60%|██████    | 3/5 [00:00<00:00, 20.45batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.41\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 10.30batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:01,  3.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8605\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  60%|██████    | 3/5 [00:00<00:00, 20.85batch/s]total loss: 1.01\n",
      "recon: 0.83\n",
      "reg: 4.63\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 12.49batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  5.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8974\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  60%|██████    | 3/5 [00:00<00:00, 12.20batch/s]total loss: 0.63\n",
      "recon: 0.53\n",
      "reg: 2.50\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  9.75batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  5.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8088\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 14.51batch/s]total loss: 0.84\n",
      "recon: 0.68\n",
      "reg: 4.15\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00,  8.89batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  5.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8563\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 15.79batch/s]total loss: 0.83\n",
      "recon: 0.70\n",
      "reg: 3.16\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  9.83batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  5.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0289\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00,  8.82batch/s]total loss: 0.90\n",
      "recon: 0.87\n",
      "reg: 0.61\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00,  6.92batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:01,  4.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 14.49batch/s]total loss: 0.50\n",
      "recon: 0.48\n",
      "reg: 0.51\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 10.43batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  5.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8685\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 19.26batch/s]total loss: 0.73\n",
      "recon: 0.74\n",
      "reg: -0.29\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  9.29batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:01,  3.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.945\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 19.59batch/s]total loss: 0.84\n",
      "recon: 0.88\n",
      "reg: -0.84\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 10.50batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9212\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 18.44batch/s]total loss: 1.04\n",
      "recon: 0.98\n",
      "reg: 1.45\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00, 11.56batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9489\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00, 17.69batch/s]total loss: 0.80\n",
      "recon: 0.66\n",
      "reg: 3.54\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00, 10.26batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  4.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 12.99batch/s]total loss: 0.41\n",
      "recon: 0.50\n",
      "reg: -2.36\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00,  9.23batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  5.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7855\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 12.89batch/s]total loss: 1.01\n",
      "recon: 1.02\n",
      "reg: -0.26\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00,  9.30batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9014\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 11.79batch/s]total loss: 1.25\n",
      "recon: 1.16\n",
      "reg: 2.12\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00,  8.87batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  5.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9263\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  60%|██████    | 3/5 [00:00<00:00, 11.42batch/s]total loss: 0.56\n",
      "recon: 0.64\n",
      "reg: -2.12\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00,  9.33batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  5.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.792\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 12.81batch/s]total loss: 0.90\n",
      "recon: 0.86\n",
      "reg: 0.97\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00, 10.04batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  5.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8642\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 15.43batch/s]total loss: 1.04\n",
      "recon: 1.03\n",
      "reg: 0.46\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 10.04batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 18.23batch/s]total loss: 0.85\n",
      "recon: 0.80\n",
      "reg: 1.07\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00,  9.18batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:01,  3.97batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8486\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 17.70batch/s]total loss: 1.23\n",
      "recon: 1.09\n",
      "reg: 3.67\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00,  8.64batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:01,  3.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 13.12batch/s]total loss: 0.90\n",
      "recon: 0.72\n",
      "reg: 4.61\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00,  7.92batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:01,  3.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8568\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 18.95batch/s]total loss: 0.67\n",
      "recon: 0.62\n",
      "reg: 1.08\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  7.59batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:01,  2.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8687\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 18.64batch/s]total loss: 0.96\n",
      "recon: 0.90\n",
      "reg: 1.38\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00,  8.89batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:01,  3.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8994\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:00<00:00, 17.04batch/s]total loss: 0.66\n",
      "recon: 0.59\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  6.43batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:02,  1.92batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.821\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  60%|██████    | 3/5 [00:00<00:00, 12.55batch/s]total loss: 0.99\n",
      "recon: 1.01\n",
      "reg: -0.54\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00,  8.65batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9282\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 16.62batch/s]total loss: 0.90\n",
      "recon: 0.92\n",
      "reg: -0.43\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00,  9.13batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:01,  3.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9571\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  80%|████████  | 4/5 [00:00<00:00, 17.22batch/s]total loss: 0.69\n",
      "recon: 0.72\n",
      "reg: -0.65\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  8.36batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:01,  2.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  60%|██████    | 3/5 [00:00<00:00, 14.63batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  9.82batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8364\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 18.97batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.17\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00, 10.56batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  4.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9152\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  80%|████████  | 4/5 [00:00<00:00, 18.50batch/s]total loss: 0.61\n",
      "recon: 0.66\n",
      "reg: -1.35\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  9.83batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:01,  3.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  60%|██████    | 3/5 [00:00<00:00, 14.31batch/s]total loss: 0.67\n",
      "recon: 0.71\n",
      "reg: -0.88\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00,  8.18batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:01,  3.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8229\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 18.38batch/s]total loss: 0.75\n",
      "recon: 0.71\n",
      "reg: 1.01\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 10.48batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  4.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8788\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 18.46batch/s]total loss: 0.86\n",
      "recon: 0.79\n",
      "reg: 1.79\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00, 11.65batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  5.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8673\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  60%|██████    | 3/5 [00:00<00:00, 11.16batch/s]total loss: 1.31\n",
      "recon: 1.27\n",
      "reg: 1.05\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00,  7.46batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:01,  3.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  60%|██████    | 3/5 [00:00<00:00, 12.31batch/s]total loss: 1.20\n",
      "recon: 1.07\n",
      "reg: 3.32\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00,  9.88batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  5.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9633\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 14.13batch/s]total loss: 1.30\n",
      "recon: 1.31\n",
      "reg: -0.36\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  9.76batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  5.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9496\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 13.88batch/s]total loss: 0.93\n",
      "recon: 0.93\n",
      "reg: 0.17\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00,  9.85batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 13.05batch/s]total loss: 0.94\n",
      "recon: 0.92\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00,  9.96batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  5.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8562\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 18.35batch/s]total loss: 0.93\n",
      "recon: 0.88\n",
      "reg: 1.24\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  8.50batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:01,  2.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 11.84batch/s]total loss: 0.97\n",
      "recon: 0.88\n",
      "reg: 2.09\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00,  9.24batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  5.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8641\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 18.98batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.15\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  9.71batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:01,  3.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8433\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 17.27batch/s]total loss: 1.01\n",
      "recon: 0.98\n",
      "reg: 0.77\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  9.29batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:01,  3.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  60%|██████    | 3/5 [00:00<00:00, 14.76batch/s]total loss: 0.34\n",
      "recon: 0.52\n",
      "reg: -4.56\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00,  9.58batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  4.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 17.13batch/s]total loss: 1.08\n",
      "recon: 1.06\n",
      "reg: 0.47\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 11.31batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  5.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9505\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 16.34batch/s]total loss: 1.03\n",
      "recon: 0.97\n",
      "reg: 1.44\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 10.79batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  5.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9209\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 11.10batch/s]total loss: 0.71\n",
      "recon: 0.72\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  7.68batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  4.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8215\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 14.62batch/s]total loss: 0.61\n",
      "recon: 0.59\n",
      "reg: 0.44\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 10.11batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.779\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 12.62batch/s]total loss: 0.64\n",
      "recon: 0.76\n",
      "reg: -2.85\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00,  9.70batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7735\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  60%|██████    | 3/5 [00:00<00:00,  9.39batch/s]total loss: 0.98\n",
      "recon: 1.03\n",
      "reg: -1.16\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  8.36batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  5.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 13.53batch/s]total loss: 0.81\n",
      "recon: 0.78\n",
      "reg: 0.95\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00,  9.96batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  5.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8081\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 14.84batch/s]total loss: 0.88\n",
      "recon: 0.72\n",
      "reg: 3.95\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00,  8.99batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:01,  3.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8261\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 17.16batch/s]total loss: 0.86\n",
      "recon: 0.93\n",
      "reg: -1.69\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00, 10.57batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  4.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8217\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 18.41batch/s]total loss: 0.74\n",
      "recon: 0.65\n",
      "reg: 2.22\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 10.24batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  4.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8079\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 18.21batch/s]total loss: 0.30\n",
      "recon: 0.42\n",
      "reg: -2.93\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  7.37batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  2.31batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.714\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 18.88batch/s]total loss: 0.57\n",
      "recon: 0.56\n",
      "reg: 0.40\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 11.25batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7736\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 15.41batch/s]total loss: 0.92\n",
      "recon: 0.96\n",
      "reg: -0.93\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 10.52batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  5.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8327\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 11.83batch/s]total loss: 0.62\n",
      "recon: 0.68\n",
      "reg: -1.56\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00,  8.49batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  5.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7675\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 10.53batch/s]total loss: 1.13\n",
      "recon: 1.00\n",
      "reg: 3.27\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  8.05batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  5.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8851\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 15.01batch/s]total loss: 0.75\n",
      "recon: 0.79\n",
      "reg: -0.97\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 10.45batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  5.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7985\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  60%|██████    | 3/5 [00:00<00:00, 12.37batch/s]total loss: 1.36\n",
      "recon: 1.28\n",
      "reg: 2.04\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00,  9.65batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  5.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9811\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 13.93batch/s]total loss: 0.80\n",
      "recon: 0.78\n",
      "reg: 0.62\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00,  9.74batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  4.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9199\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 12.26batch/s]total loss: 0.96\n",
      "recon: 0.86\n",
      "reg: 2.54\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  9.51batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  5.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9219\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00, 15.24batch/s]total loss: 0.86\n",
      "recon: 0.83\n",
      "reg: 0.78\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00,  8.75batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  4.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8767\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 14.19batch/s]total loss: 0.94\n",
      "recon: 1.05\n",
      "reg: -2.69\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00,  9.44batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  4.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 17.60batch/s]total loss: 0.60\n",
      "recon: 0.70\n",
      "reg: -2.41\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00,  8.67batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:01,  3.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7882\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 12.49batch/s]total loss: 0.58\n",
      "recon: 0.57\n",
      "reg: 0.32\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  8.50batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  4.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.799\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 12.54batch/s]total loss: 0.73\n",
      "recon: 0.74\n",
      "reg: -0.11\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  8.77batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  4.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8149\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 18.40batch/s]total loss: 0.38\n",
      "recon: 0.38\n",
      "reg: 0.15\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 10.27batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  4.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.753\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  60%|██████    | 3/5 [00:00<00:00, 13.56batch/s]total loss: 0.71\n",
      "recon: 0.69\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00,  9.57batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.795\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 17.17batch/s]total loss: 0.83\n",
      "recon: 0.84\n",
      "reg: -0.28\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 10.40batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  4.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8184\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  60%|██████    | 3/5 [00:00<00:00, 13.98batch/s]total loss: 1.08\n",
      "recon: 1.03\n",
      "reg: 1.25\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00, 10.03batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  5.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8889\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  60%|██████    | 3/5 [00:00<00:00, 10.82batch/s]total loss: 0.58\n",
      "recon: 0.61\n",
      "reg: -0.67\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00,  8.63batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  5.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7991\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 12.43batch/s]total loss: 0.37\n",
      "recon: 0.47\n",
      "reg: -2.28\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00,  9.05batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  5.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7713\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 17.44batch/s]total loss: 0.75\n",
      "recon: 0.62\n",
      "reg: 3.28\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  9.95batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:01,  3.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8041\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 12.68batch/s]total loss: 0.73\n",
      "recon: 0.75\n",
      "reg: -0.57\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00,  9.37batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  4.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7942\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 12.89batch/s]total loss: 0.50\n",
      "recon: 0.45\n",
      "reg: 1.35\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00,  9.10batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 13.02batch/s]total loss: 0.76\n",
      "recon: 0.73\n",
      "reg: 0.81\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  8.67batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:01,  3.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 18.39batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.12\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  7.83batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:01,  2.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 18.46batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.13\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  9.27batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:01,  3.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8398\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 18.66batch/s]total loss: 0.97\n",
      "recon: 0.86\n",
      "reg: 2.88\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 10.65batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8718\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 14.96batch/s]total loss: 0.64\n",
      "recon: 0.73\n",
      "reg: -2.26\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00,  9.27batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  60%|██████    | 3/5 [00:00<00:00, 11.23batch/s]total loss: 1.19\n",
      "recon: 1.11\n",
      "reg: 1.96\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00,  7.23batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:01,  3.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9163\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 10.84batch/s]total loss: 0.93\n",
      "recon: 0.92\n",
      "reg: 0.26\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  8.36batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  4.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8425\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 12.53batch/s]total loss: 0.65\n",
      "recon: 0.60\n",
      "reg: 1.23\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  7.10batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.87batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7892\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 10.43batch/s]total loss: 1.10\n",
      "recon: 1.01\n",
      "reg: 2.28\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  8.49batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  4.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8862\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 13.77batch/s]total loss: 0.61\n",
      "recon: 0.58\n",
      "reg: 0.67\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  9.64batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7965\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 17.22batch/s]total loss: 0.78\n",
      "recon: 0.71\n",
      "reg: 1.69\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  8.86batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  4.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 18.91batch/s]total loss: 0.71\n",
      "recon: 0.65\n",
      "reg: 1.51\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  9.62batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:01,  3.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 16.67batch/s]total loss: 0.81\n",
      "recon: 0.86\n",
      "reg: -1.24\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 10.28batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  60%|██████    | 3/5 [00:00<00:00, 13.76batch/s]total loss: 1.77\n",
      "recon: 1.65\n",
      "reg: 2.95\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  9.86batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  5.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 18.14batch/s]total loss: 0.87\n",
      "recon: 0.87\n",
      "reg: 0.02\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  9.23batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:01,  3.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8254\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 17.21batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.28\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  8.33batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:01,  2.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8351\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 17.61batch/s]total loss: 1.59\n",
      "recon: 1.55\n",
      "reg: 1.00\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 10.51batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9762\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 18.44batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.61\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00, 11.69batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  5.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8294\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_04-19-43/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.255701720901, Time: 111.47s\n",
      "Epoch 200, Training Loss: 0.131409470923, Time: 222.18s\n",
      "Epoch 300, Training Loss: 0.067633039749, Time: 330.80s\n",
      "Epoch 400, Training Loss: 0.039594843505, Time: 431.23s\n",
      "Epoch 500, Training Loss: 0.012818424488, Time: 537.27s\n",
      "Epoch 600, Training Loss: 0.007906403818, Time: 649.92s\n",
      "Epoch 700, Training Loss: 0.006631630821, Time: 759.96s\n",
      "Epoch 800, Training Loss: 0.003244960273, Time: 870.26s\n",
      "Epoch 900, Training Loss: 0.002754969009, Time: 981.96s\n",
      "Epoch 1000, Training Loss: 0.002386060804, Time: 1106.16s\n",
      "Validation Loss: 0.070456305779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.07046</td></tr><tr><td>val_loss</td><td>0.07046</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">noble-sweep-36</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/v2areq9r' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/v2areq9r</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_041942-v2areq9r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hg1b6pxp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008124510170024034\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_043924-hg1b6pxp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/hg1b6pxp' target=\"_blank\">stellar-sweep-37</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/hg1b6pxp' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/hg1b6pxp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_04-39-25. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00, 22.59batch/s]total loss: 4.22\n",
      "recon: 3.77\n",
      "reg: 11.31\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00, 10.90batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 5.8681\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 17.84batch/s]total loss: 1.65\n",
      "recon: 1.54\n",
      "reg: 2.77\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00,  9.67batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:01,  3.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 2.0765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  80%|████████  | 4/5 [00:00<00:00, 15.37batch/s]total loss: 1.12\n",
      "recon: 1.00\n",
      "reg: 3.06\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00, 10.51batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.3569\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  60%|██████    | 3/5 [00:00<00:00, 10.43batch/s]total loss: 0.75\n",
      "recon: 0.73\n",
      "reg: 0.54\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00,  8.35batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  5.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.3297\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 15.49batch/s]total loss: 0.75\n",
      "recon: 0.72\n",
      "reg: 0.86\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00, 10.81batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  5.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9718\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 15.01batch/s]total loss: 0.86\n",
      "recon: 0.67\n",
      "reg: 4.65\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 10.34batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  5.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 19.04batch/s]total loss: 0.58\n",
      "recon: 0.62\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00,  9.67batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8504\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  80%|████████  | 4/5 [00:00<00:00, 18.77batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.41\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 11.49batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  5.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8605\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 16.59batch/s]total loss: 1.01\n",
      "recon: 0.83\n",
      "reg: 4.63\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 11.18batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  5.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8974\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00, 22.28batch/s]total loss: 0.63\n",
      "recon: 0.53\n",
      "reg: 2.50\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  9.93batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8088\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 19.51batch/s]total loss: 0.84\n",
      "recon: 0.68\n",
      "reg: 4.15\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 12.09batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  5.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8563\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 18.31batch/s]total loss: 0.83\n",
      "recon: 0.70\n",
      "reg: 3.16\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00, 11.21batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  4.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0289\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 18.97batch/s]total loss: 0.90\n",
      "recon: 0.87\n",
      "reg: 0.61\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 10.57batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  4.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  80%|████████  | 4/5 [00:00<00:00, 16.75batch/s]total loss: 0.50\n",
      "recon: 0.48\n",
      "reg: 0.51\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 11.05batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  5.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8685\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 17.58batch/s]total loss: 0.73\n",
      "recon: 0.74\n",
      "reg: -0.29\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00, 10.42batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  4.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.945\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 17.63batch/s]total loss: 0.84\n",
      "recon: 0.88\n",
      "reg: -0.84\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 10.06batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  4.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9212\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 13.94batch/s]total loss: 1.04\n",
      "recon: 0.98\n",
      "reg: 1.45\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00,  9.94batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  5.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9489\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00, 18.22batch/s]total loss: 0.80\n",
      "recon: 0.66\n",
      "reg: 3.54\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00, 11.28batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  5.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 18.84batch/s]total loss: 0.41\n",
      "recon: 0.50\n",
      "reg: -2.36\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 11.71batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  5.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7855\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  60%|██████    | 3/5 [00:00<00:00, 12.65batch/s]total loss: 1.01\n",
      "recon: 1.02\n",
      "reg: -0.26\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00,  9.27batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9014\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  60%|██████    | 3/5 [00:00<00:00, 19.54batch/s]total loss: 1.25\n",
      "recon: 1.16\n",
      "reg: 2.12\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 11.80batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  5.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9263\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 17.94batch/s]total loss: 0.56\n",
      "recon: 0.64\n",
      "reg: -2.12\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 11.41batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  5.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.792\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 16.75batch/s]total loss: 0.90\n",
      "recon: 0.86\n",
      "reg: 0.97\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00,  9.77batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  4.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8642\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  80%|████████  | 4/5 [00:00<00:00, 18.37batch/s]total loss: 1.04\n",
      "recon: 1.03\n",
      "reg: 0.46\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 11.25batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  5.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 19.15batch/s]total loss: 0.85\n",
      "recon: 0.80\n",
      "reg: 1.07\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 11.76batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  5.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8486\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 17.53batch/s]total loss: 1.23\n",
      "recon: 1.09\n",
      "reg: 3.67\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 10.15batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  4.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 13.89batch/s]total loss: 0.90\n",
      "recon: 0.72\n",
      "reg: 4.61\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00,  9.47batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  4.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8568\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 18.20batch/s]total loss: 0.67\n",
      "recon: 0.62\n",
      "reg: 1.08\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00, 11.40batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  5.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8687\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 17.25batch/s]total loss: 0.96\n",
      "recon: 0.90\n",
      "reg: 1.38\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 11.32batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  5.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8994\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  60%|██████    | 3/5 [00:00<00:00, 15.12batch/s]total loss: 0.66\n",
      "recon: 0.59\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  8.15batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  3.06batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.821\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  60%|██████    | 3/5 [00:00<00:00, 18.05batch/s]total loss: 0.99\n",
      "recon: 1.01\n",
      "reg: -0.54\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 11.38batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  5.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9282\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  60%|██████    | 3/5 [00:00<00:00, 20.52batch/s]total loss: 0.90\n",
      "recon: 0.92\n",
      "reg: -0.43\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00, 12.04batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  5.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9571\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  60%|██████    | 3/5 [00:00<00:00, 12.46batch/s]total loss: 0.69\n",
      "recon: 0.72\n",
      "reg: -0.65\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00,  9.61batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  5.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 16.33batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00, 10.49batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  5.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8364\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 18.72batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.17\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00, 11.25batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9152\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  60%|██████    | 3/5 [00:00<00:00, 13.49batch/s]total loss: 0.61\n",
      "recon: 0.66\n",
      "reg: -1.35\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  9.77batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  5.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  80%|████████  | 4/5 [00:00<00:00, 18.76batch/s]total loss: 0.67\n",
      "recon: 0.71\n",
      "reg: -0.88\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 11.72batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  5.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8229\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 16.35batch/s]total loss: 0.75\n",
      "recon: 0.71\n",
      "reg: 1.01\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 11.16batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  5.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8788\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 18.27batch/s]total loss: 0.86\n",
      "recon: 0.79\n",
      "reg: 1.79\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00, 10.84batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  4.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8673\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 19.13batch/s]total loss: 1.31\n",
      "recon: 1.27\n",
      "reg: 1.05\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 11.94batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  5.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 10.78batch/s]total loss: 1.20\n",
      "recon: 1.07\n",
      "reg: 3.32\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00,  8.13batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  4.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9633\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  60%|██████    | 3/5 [00:00<00:00, 14.39batch/s]total loss: 1.30\n",
      "recon: 1.31\n",
      "reg: -0.36\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00,  9.75batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  4.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9496\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 18.60batch/s]total loss: 0.93\n",
      "recon: 0.93\n",
      "reg: 0.17\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 11.73batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  5.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 15.64batch/s]total loss: 0.94\n",
      "recon: 0.92\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 10.68batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  5.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8562\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 14.36batch/s]total loss: 0.93\n",
      "recon: 0.88\n",
      "reg: 1.24\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  9.65batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  4.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 17.09batch/s]total loss: 0.97\n",
      "recon: 0.88\n",
      "reg: 2.09\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00, 11.60batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  5.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8641\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 14.52batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.15\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 10.16batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  5.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8433\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  60%|██████    | 3/5 [00:00<00:00, 13.90batch/s]total loss: 1.01\n",
      "recon: 0.98\n",
      "reg: 0.77\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  9.36batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  4.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  80%|████████  | 4/5 [00:00<00:00, 18.63batch/s]total loss: 0.34\n",
      "recon: 0.52\n",
      "reg: -4.56\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 11.65batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  5.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 16.14batch/s]total loss: 1.08\n",
      "recon: 1.06\n",
      "reg: 0.47\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 11.12batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  5.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9505\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 17.95batch/s]total loss: 1.03\n",
      "recon: 0.97\n",
      "reg: 1.44\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 11.05batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  5.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9209\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 18.69batch/s]total loss: 0.71\n",
      "recon: 0.72\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00, 11.99batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  5.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8215\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 16.26batch/s]total loss: 0.61\n",
      "recon: 0.59\n",
      "reg: 0.44\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 11.02batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  5.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.779\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  60%|██████    | 3/5 [00:00<00:00, 14.73batch/s]total loss: 0.64\n",
      "recon: 0.76\n",
      "reg: -2.85\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00,  8.38batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:01,  3.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7735\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 19.09batch/s]total loss: 0.98\n",
      "recon: 1.03\n",
      "reg: -1.16\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 12.05batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  5.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 13.70batch/s]total loss: 0.81\n",
      "recon: 0.78\n",
      "reg: 0.95\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00,  9.52batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  4.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8081\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  80%|████████  | 4/5 [00:00<00:00, 19.51batch/s]total loss: 0.88\n",
      "recon: 0.72\n",
      "reg: 3.95\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 10.28batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:01,  3.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8261\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 19.65batch/s]total loss: 0.86\n",
      "recon: 0.93\n",
      "reg: -1.69\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00, 12.36batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  5.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8217\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 13.81batch/s]total loss: 0.74\n",
      "recon: 0.65\n",
      "reg: 2.22\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00,  9.90batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  5.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8079\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 19.43batch/s]total loss: 0.30\n",
      "recon: 0.42\n",
      "reg: -2.93\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  7.55batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  2.32batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.714\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  60%|██████    | 3/5 [00:00<00:00, 20.45batch/s]total loss: 0.57\n",
      "recon: 0.56\n",
      "reg: 0.40\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 11.77batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7736\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 19.01batch/s]total loss: 0.92\n",
      "recon: 0.96\n",
      "reg: -0.93\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 11.77batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  5.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8327\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 17.61batch/s]total loss: 0.62\n",
      "recon: 0.68\n",
      "reg: -1.56\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00, 10.12batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  4.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7675\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  60%|██████    | 3/5 [00:00<00:00, 19.47batch/s]total loss: 1.13\n",
      "recon: 1.00\n",
      "reg: 3.27\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  9.96batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:01,  3.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8851\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 17.95batch/s]total loss: 0.75\n",
      "recon: 0.79\n",
      "reg: -0.97\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 11.83batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  5.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7985\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 16.98batch/s]total loss: 1.36\n",
      "recon: 1.28\n",
      "reg: 2.04\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 10.10batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  5.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9811\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 16.55batch/s]total loss: 0.80\n",
      "recon: 0.78\n",
      "reg: 0.62\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 11.15batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  5.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9199\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 19.35batch/s]total loss: 0.96\n",
      "recon: 0.86\n",
      "reg: 2.54\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00, 10.47batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  4.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9219\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  60%|██████    | 3/5 [00:00<00:00, 13.92batch/s]total loss: 0.86\n",
      "recon: 0.83\n",
      "reg: 0.78\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00, 10.29batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  5.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8767\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 16.08batch/s]total loss: 0.94\n",
      "recon: 1.05\n",
      "reg: -2.69\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 10.35batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 18.84batch/s]total loss: 0.60\n",
      "recon: 0.70\n",
      "reg: -2.41\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 11.80batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  5.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7882\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 14.87batch/s]total loss: 0.58\n",
      "recon: 0.57\n",
      "reg: 0.32\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00,  9.98batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  5.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.799\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 17.49batch/s]total loss: 0.73\n",
      "recon: 0.74\n",
      "reg: -0.11\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00, 11.25batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  5.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8149\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  80%|████████  | 4/5 [00:00<00:00, 19.29batch/s]total loss: 0.38\n",
      "recon: 0.38\n",
      "reg: 0.15\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 10.51batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.753\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 17.85batch/s]total loss: 0.71\n",
      "recon: 0.69\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 11.69batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  5.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.795\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 16.14batch/s]total loss: 0.83\n",
      "recon: 0.84\n",
      "reg: -0.28\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 10.12batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  4.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8184\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  60%|██████    | 3/5 [00:00<00:00, 15.09batch/s]total loss: 1.08\n",
      "recon: 1.03\n",
      "reg: 1.25\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  9.88batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  4.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8889\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 16.87batch/s]total loss: 0.58\n",
      "recon: 0.61\n",
      "reg: -0.67\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 11.04batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  5.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7991\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 18.76batch/s]total loss: 0.37\n",
      "recon: 0.47\n",
      "reg: -2.28\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 11.19batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  5.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7713\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  60%|██████    | 3/5 [00:00<00:00, 15.12batch/s]total loss: 0.75\n",
      "recon: 0.62\n",
      "reg: 3.28\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00,  7.74batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:01,  2.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8041\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 19.79batch/s]total loss: 0.73\n",
      "recon: 0.75\n",
      "reg: -0.57\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 12.42batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  5.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7942\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  80%|████████  | 4/5 [00:00<00:00, 18.91batch/s]total loss: 0.50\n",
      "recon: 0.45\n",
      "reg: 1.35\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00, 11.87batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  5.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  80%|████████  | 4/5 [00:00<00:00, 18.78batch/s]total loss: 0.76\n",
      "recon: 0.73\n",
      "reg: 0.81\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00, 11.70batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  5.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 17.61batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.12\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00, 11.06batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  5.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 17.32batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.13\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 11.35batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  5.50batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8398\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 16.45batch/s]total loss: 0.97\n",
      "recon: 0.86\n",
      "reg: 2.88\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00,  8.65batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:01,  3.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8718\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 15.96batch/s]total loss: 0.64\n",
      "recon: 0.73\n",
      "reg: -2.26\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 10.32batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  5.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 17.96batch/s]total loss: 1.19\n",
      "recon: 1.11\n",
      "reg: 1.96\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00, 11.39batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  5.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9163\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  60%|██████    | 3/5 [00:00<00:00, 14.02batch/s]total loss: 0.93\n",
      "recon: 0.92\n",
      "reg: 0.26\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00, 10.16batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  5.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8425\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 17.46batch/s]total loss: 0.65\n",
      "recon: 0.60\n",
      "reg: 1.23\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  8.80batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  3.22batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7892\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 15.04batch/s]total loss: 1.10\n",
      "recon: 1.01\n",
      "reg: 2.28\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  9.45batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  5.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8862\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 19.11batch/s]total loss: 0.61\n",
      "recon: 0.58\n",
      "reg: 0.67\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00,  9.90batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:01,  3.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7965\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  60%|██████    | 3/5 [00:00<00:00, 13.17batch/s]total loss: 0.78\n",
      "recon: 0.71\n",
      "reg: 1.69\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  9.77batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  5.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 11.07batch/s]total loss: 0.71\n",
      "recon: 0.65\n",
      "reg: 1.51\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  8.84batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  5.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 15.56batch/s]total loss: 0.81\n",
      "recon: 0.86\n",
      "reg: -1.24\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00,  7.57batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:01,  2.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 14.54batch/s]total loss: 1.77\n",
      "recon: 1.65\n",
      "reg: 2.95\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00,  7.80batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:01,  3.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  60%|██████    | 3/5 [00:00<00:00, 14.18batch/s]total loss: 0.87\n",
      "recon: 0.87\n",
      "reg: 0.02\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  9.42batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  4.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8254\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  60%|██████    | 3/5 [00:00<00:00, 13.56batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.28\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00, 10.06batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  5.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8351\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 18.38batch/s]total loss: 1.59\n",
      "recon: 1.55\n",
      "reg: 1.00\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 10.51batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  4.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9762\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  60%|██████    | 3/5 [00:00<00:00, 12.66batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.61\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00,  9.12batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  4.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8294\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_04-39-25/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.255701720901, Time: 129.48s\n",
      "Epoch 200, Training Loss: 0.131409470923, Time: 245.76s\n",
      "Epoch 300, Training Loss: 0.067633039749, Time: 362.62s\n",
      "Epoch 400, Training Loss: 0.039594843505, Time: 472.71s\n",
      "Epoch 500, Training Loss: 0.012818424488, Time: 582.03s\n",
      "Epoch 600, Training Loss: 0.007906403818, Time: 693.33s\n",
      "Epoch 700, Training Loss: 0.006631630821, Time: 801.79s\n",
      "Epoch 800, Training Loss: 0.003244960273, Time: 912.35s\n",
      "Epoch 900, Training Loss: 0.002754969009, Time: 1024.54s\n",
      "Epoch 1000, Training Loss: 0.002386060804, Time: 1135.02s\n",
      "Validation Loss: 0.070456305779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.07046</td></tr><tr><td>val_loss</td><td>0.07046</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-sweep-37</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/hg1b6pxp' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/hg1b6pxp</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_043924-hg1b6pxp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 19qxvglz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00922750170642564\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_045934-19qxvglz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/19qxvglz' target=\"_blank\">apricot-sweep-38</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/19qxvglz' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/19qxvglz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_04-59-35. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  60%|██████    | 3/5 [00:00<00:00, 23.56batch/s]total loss: 6.57\n",
      "recon: 6.04\n",
      "reg: 13.33\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00, 13.41batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:00,  5.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 9.618\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  60%|██████    | 3/5 [00:00<00:00, 24.68batch/s]total loss: 3.78\n",
      "recon: 3.69\n",
      "reg: 2.27\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 14.69batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  6.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 4.3731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  60%|██████    | 3/5 [00:00<00:00, 13.87batch/s]total loss: 1.66\n",
      "recon: 1.47\n",
      "reg: 4.55\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00, 11.18batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  6.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 2.5129\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  60%|██████    | 3/5 [00:00<00:00, 24.94batch/s]total loss: 1.25\n",
      "recon: 1.17\n",
      "reg: 2.03\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 11.54batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  6.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.6694\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  60%|██████    | 3/5 [00:00<00:00, 26.74batch/s]total loss: 0.99\n",
      "recon: 0.93\n",
      "reg: 1.68\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00, 16.23batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  7.19batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2335\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  60%|██████    | 3/5 [00:00<00:00, 24.33batch/s]total loss: 1.15\n",
      "recon: 1.00\n",
      "reg: 3.74\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 12.78batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  6.36batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  60%|██████    | 3/5 [00:00<00:00, 25.76batch/s]total loss: 0.73\n",
      "recon: 0.77\n",
      "reg: -0.92\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 13.65batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  5.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9913\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  60%|██████    | 3/5 [00:00<00:00, 22.75batch/s]total loss: 0.72\n",
      "recon: 0.72\n",
      "reg: 0.03\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 14.67batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  6.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9148\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 23.82batch/s]total loss: 1.03\n",
      "recon: 0.89\n",
      "reg: 3.49\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 12.85batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  5.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9637\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  40%|████      | 2/5 [00:00<00:00, 14.81batch/s]total loss: 0.73\n",
      "recon: 0.63\n",
      "reg: 2.36\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00, 12.91batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  6.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8591\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  60%|██████    | 3/5 [00:00<00:00, 23.48batch/s]total loss: 0.96\n",
      "recon: 0.83\n",
      "reg: 3.26\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 14.75batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  6.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9028\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00, 23.13batch/s]total loss: 0.90\n",
      "recon: 0.82\n",
      "reg: 2.14\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00, 12.96batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  6.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.1281\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  60%|██████    | 3/5 [00:00<00:00, 24.32batch/s]total loss: 1.00\n",
      "recon: 0.96\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 12.90batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  6.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9531\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  60%|██████    | 3/5 [00:00<00:00, 23.09batch/s]total loss: 0.54\n",
      "recon: 0.49\n",
      "reg: 1.14\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 14.75batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  6.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9048\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  60%|██████    | 3/5 [00:00<00:00, 24.61batch/s]total loss: 0.74\n",
      "recon: 0.74\n",
      "reg: -0.01\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00, 14.58batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  6.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9273\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  60%|██████    | 3/5 [00:00<00:00, 26.53batch/s]total loss: 0.88\n",
      "recon: 0.89\n",
      "reg: -0.28\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 15.31batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  6.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  60%|██████    | 3/5 [00:00<00:00, 25.40batch/s]total loss: 1.05\n",
      "recon: 0.97\n",
      "reg: 1.81\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00, 13.05batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  5.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9335\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  60%|██████    | 3/5 [00:00<00:00, 24.12batch/s]total loss: 0.82\n",
      "recon: 0.68\n",
      "reg: 3.54\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00, 10.69batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  6.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8611\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  60%|██████    | 3/5 [00:00<00:00, 25.65batch/s]total loss: 0.40\n",
      "recon: 0.49\n",
      "reg: -2.44\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 14.97batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  6.52batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7805\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  60%|██████    | 3/5 [00:00<00:00, 24.54batch/s]total loss: 0.99\n",
      "recon: 1.02\n",
      "reg: -0.85\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 15.09batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  6.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8923\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 14.51batch/s]total loss: 1.26\n",
      "recon: 1.19\n",
      "reg: 1.64\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 11.27batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  6.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9339\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  60%|██████    | 3/5 [00:00<00:00, 25.37batch/s]total loss: 0.57\n",
      "recon: 0.64\n",
      "reg: -1.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 15.09batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  6.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7958\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  60%|██████    | 3/5 [00:00<00:00, 22.21batch/s]total loss: 0.92\n",
      "recon: 0.88\n",
      "reg: 0.98\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00, 14.44batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  6.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8633\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  60%|██████    | 3/5 [00:00<00:00, 22.41batch/s]total loss: 1.03\n",
      "recon: 1.00\n",
      "reg: 0.64\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 14.19batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  6.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9341\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  60%|██████    | 3/5 [00:00<00:00, 22.39batch/s]total loss: 0.84\n",
      "recon: 0.80\n",
      "reg: 1.13\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00,  7.19batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:01,  2.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8531\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  60%|██████    | 3/5 [00:00<00:00, 21.87batch/s]total loss: 1.20\n",
      "recon: 1.06\n",
      "reg: 3.54\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 12.75batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  5.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9188\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 19.72batch/s]total loss: 0.97\n",
      "recon: 0.80\n",
      "reg: 4.13\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 12.89batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:00,  6.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  60%|██████    | 3/5 [00:00<00:00, 22.88batch/s]total loss: 0.72\n",
      "recon: 0.65\n",
      "reg: 1.62\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00, 12.04batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8762\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  60%|██████    | 3/5 [00:00<00:00, 24.20batch/s]total loss: 0.97\n",
      "recon: 0.94\n",
      "reg: 0.74\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 15.12batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  7.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8947\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  60%|██████    | 3/5 [00:00<00:00, 22.74batch/s]total loss: 0.64\n",
      "recon: 0.58\n",
      "reg: 1.52\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00, 10.37batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  3.66batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8136\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  60%|██████    | 3/5 [00:00<00:00, 23.47batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.80\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 12.68batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8989\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  40%|████      | 2/5 [00:00<00:00, 18.54batch/s]total loss: 0.95\n",
      "recon: 0.98\n",
      "reg: -0.69\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00, 13.17batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  5.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0023\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  60%|██████    | 3/5 [00:00<00:00, 23.02batch/s]total loss: 0.68\n",
      "recon: 0.70\n",
      "reg: -0.74\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00, 13.78batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  6.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8839\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  60%|██████    | 3/5 [00:00<00:00, 22.29batch/s]total loss: 0.87\n",
      "recon: 0.92\n",
      "reg: -1.02\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00, 13.20batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  5.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  60%|██████    | 3/5 [00:00<00:00, 21.54batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.31\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00,  9.43batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  6.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9198\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  60%|██████    | 3/5 [00:00<00:00, 24.81batch/s]total loss: 0.59\n",
      "recon: 0.64\n",
      "reg: -1.16\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00, 15.56batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  7.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  60%|██████    | 3/5 [00:00<00:00, 23.12batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.72\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 14.87batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  6.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8328\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 16.09batch/s]total loss: 0.70\n",
      "recon: 0.64\n",
      "reg: 1.45\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 11.63batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  7.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  60%|██████    | 3/5 [00:00<00:00, 22.25batch/s]total loss: 0.85\n",
      "recon: 0.80\n",
      "reg: 1.47\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00, 14.17batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  6.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8568\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  60%|██████    | 3/5 [00:00<00:00, 23.93batch/s]total loss: 1.34\n",
      "recon: 1.29\n",
      "reg: 1.44\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 13.11batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  5.59batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9474\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  60%|██████    | 3/5 [00:00<00:00, 22.83batch/s]total loss: 1.21\n",
      "recon: 1.05\n",
      "reg: 3.86\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 12.70batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9591\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  60%|██████    | 3/5 [00:00<00:00, 21.49batch/s]total loss: 1.30\n",
      "recon: 1.30\n",
      "reg: -0.01\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00, 14.30batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  6.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.955\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  60%|██████    | 3/5 [00:00<00:00, 25.63batch/s]total loss: 0.96\n",
      "recon: 0.96\n",
      "reg: 0.15\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 14.77batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  6.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8643\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  60%|██████    | 3/5 [00:00<00:00, 22.47batch/s]total loss: 0.86\n",
      "recon: 0.85\n",
      "reg: 0.35\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 10.83batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:01,  3.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.85\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  60%|██████    | 3/5 [00:00<00:00, 21.19batch/s]total loss: 0.95\n",
      "recon: 0.91\n",
      "reg: 1.00\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00, 14.02batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  6.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8873\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  60%|██████    | 3/5 [00:00<00:00, 23.43batch/s]total loss: 1.00\n",
      "recon: 0.90\n",
      "reg: 2.39\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00, 14.14batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  6.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8763\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 23.00batch/s]total loss: 0.94\n",
      "recon: 0.95\n",
      "reg: -0.39\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  9.61batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:01,  3.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 17.06batch/s]total loss: 0.99\n",
      "recon: 0.96\n",
      "reg: 0.68\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00, 10.75batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  5.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8696\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  60%|██████    | 3/5 [00:00<00:00, 22.78batch/s]total loss: 0.37\n",
      "recon: 0.57\n",
      "reg: -4.88\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 14.83batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  7.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.756\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  60%|██████    | 3/5 [00:00<00:00, 21.41batch/s]total loss: 1.05\n",
      "recon: 1.03\n",
      "reg: 0.56\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 13.76batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  6.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9286\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  60%|██████    | 3/5 [00:00<00:00, 24.45batch/s]total loss: 1.01\n",
      "recon: 0.95\n",
      "reg: 1.49\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 12.82batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  6.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  60%|██████    | 3/5 [00:00<00:00, 21.83batch/s]total loss: 0.73\n",
      "recon: 0.73\n",
      "reg: 0.11\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00, 14.01batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  6.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8219\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  60%|██████    | 3/5 [00:00<00:00, 23.60batch/s]total loss: 0.63\n",
      "recon: 0.62\n",
      "reg: 0.27\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 14.13batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  6.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7857\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  60%|██████    | 3/5 [00:00<00:00, 24.06batch/s]total loss: 0.67\n",
      "recon: 0.78\n",
      "reg: -2.80\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 14.70batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  6.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7882\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  60%|██████    | 3/5 [00:00<00:00, 20.58batch/s]total loss: 1.01\n",
      "recon: 1.05\n",
      "reg: -1.00\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 14.09batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  6.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8625\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 23.11batch/s]total loss: 0.82\n",
      "recon: 0.79\n",
      "reg: 0.95\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 11.66batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  5.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8205\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  60%|██████    | 3/5 [00:00<00:00, 22.58batch/s]total loss: 0.92\n",
      "recon: 0.76\n",
      "reg: 3.99\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 14.59batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  7.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  40%|████      | 2/5 [00:00<00:00, 15.30batch/s]total loss: 0.88\n",
      "recon: 0.94\n",
      "reg: -1.60\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00, 13.17batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  6.77batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8338\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  60%|██████    | 3/5 [00:00<00:00, 24.14batch/s]total loss: 0.73\n",
      "recon: 0.65\n",
      "reg: 2.04\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 15.13batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  6.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8135\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00, 23.17batch/s]total loss: 0.29\n",
      "recon: 0.41\n",
      "reg: -3.13\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  9.61batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  3.48batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7155\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 18.07batch/s]total loss: 0.57\n",
      "recon: 0.57\n",
      "reg: 0.04\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 12.31batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  6.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7851\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  60%|██████    | 3/5 [00:00<00:00, 23.42batch/s]total loss: 0.95\n",
      "recon: 0.99\n",
      "reg: -0.94\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 14.84batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  6.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8465\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  60%|██████    | 3/5 [00:00<00:00, 22.76batch/s]total loss: 0.65\n",
      "recon: 0.72\n",
      "reg: -1.85\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00, 14.21batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  6.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7768\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00, 25.26batch/s]total loss: 1.13\n",
      "recon: 1.01\n",
      "reg: 3.17\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00, 13.64batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  6.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8888\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  60%|██████    | 3/5 [00:00<00:00, 25.52batch/s]total loss: 0.76\n",
      "recon: 0.80\n",
      "reg: -0.98\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 14.69batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  6.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8045\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  60%|██████    | 3/5 [00:00<00:00, 22.93batch/s]total loss: 1.35\n",
      "recon: 1.28\n",
      "reg: 1.65\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 14.28batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  6.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9959\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 18.75batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.61\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 12.41batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  6.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9093\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  60%|██████    | 3/5 [00:00<00:00, 25.49batch/s]total loss: 0.91\n",
      "recon: 0.81\n",
      "reg: 2.62\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00, 15.49batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  6.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9013\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00, 16.75batch/s]total loss: 0.87\n",
      "recon: 0.83\n",
      "reg: 0.84\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00, 10.11batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  6.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8714\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 20.99batch/s]total loss: 0.87\n",
      "recon: 0.98\n",
      "reg: -2.71\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 12.06batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  6.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8445\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  60%|██████    | 3/5 [00:00<00:00, 23.05batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.76\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 12.47batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7994\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  60%|██████    | 3/5 [00:00<00:00, 22.21batch/s]total loss: 0.59\n",
      "recon: 0.58\n",
      "reg: 0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00, 14.81batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  7.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8111\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  60%|██████    | 3/5 [00:00<00:00, 23.62batch/s]total loss: 0.79\n",
      "recon: 0.80\n",
      "reg: -0.39\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00, 10.73batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:00,  4.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8246\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  60%|██████    | 3/5 [00:00<00:00, 24.24batch/s]total loss: 0.43\n",
      "recon: 0.40\n",
      "reg: 0.55\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 14.65batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  6.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  60%|██████    | 3/5 [00:00<00:00, 21.49batch/s]total loss: 0.75\n",
      "recon: 0.73\n",
      "reg: 0.48\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 14.25batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  6.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8145\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 21.57batch/s]total loss: 0.95\n",
      "recon: 0.95\n",
      "reg: -0.01\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 12.29batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  6.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8654\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  60%|██████    | 3/5 [00:00<00:00, 24.25batch/s]total loss: 1.06\n",
      "recon: 1.01\n",
      "reg: 1.35\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00, 12.91batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8969\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  60%|██████    | 3/5 [00:00<00:00, 22.61batch/s]total loss: 0.68\n",
      "recon: 0.71\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 14.02batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  6.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8474\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  60%|██████    | 3/5 [00:00<00:00, 23.15batch/s]total loss: 0.32\n",
      "recon: 0.42\n",
      "reg: -2.41\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 12.49batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  6.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.745\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  60%|██████    | 3/5 [00:00<00:00, 23.76batch/s]total loss: 0.76\n",
      "recon: 0.62\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 13.18batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  5.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.816\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  60%|██████    | 3/5 [00:00<00:00, 24.31batch/s]total loss: 0.71\n",
      "recon: 0.74\n",
      "reg: -0.67\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 14.26batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  6.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.817\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  60%|██████    | 3/5 [00:00<00:00, 22.39batch/s]total loss: 0.52\n",
      "recon: 0.46\n",
      "reg: 1.53\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00, 11.36batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7839\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  60%|██████    | 3/5 [00:00<00:00, 24.26batch/s]total loss: 0.73\n",
      "recon: 0.69\n",
      "reg: 0.84\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00, 14.09batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  5.99batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8012\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  60%|██████    | 3/5 [00:00<00:00, 23.77batch/s]total loss: 0.90\n",
      "recon: 0.88\n",
      "reg: 0.29\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00, 14.67batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  6.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8352\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  60%|██████    | 3/5 [00:00<00:00, 21.09batch/s]total loss: 0.96\n",
      "recon: 0.88\n",
      "reg: 2.14\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 11.92batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  4.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8412\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  60%|██████    | 3/5 [00:00<00:00, 23.80batch/s]total loss: 0.93\n",
      "recon: 0.81\n",
      "reg: 2.97\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 11.72batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8484\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  60%|██████    | 3/5 [00:00<00:00, 23.38batch/s]total loss: 0.70\n",
      "recon: 0.78\n",
      "reg: -2.07\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 12.34batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8034\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  60%|██████    | 3/5 [00:00<00:00, 22.31batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.76\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00, 12.12batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8877\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  60%|██████    | 3/5 [00:00<00:00, 22.57batch/s]total loss: 0.92\n",
      "recon: 0.92\n",
      "reg: -0.03\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00, 14.70batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  7.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8281\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  60%|██████    | 3/5 [00:00<00:00, 24.84batch/s]total loss: 0.70\n",
      "recon: 0.66\n",
      "reg: 1.03\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00, 10.82batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  3.58batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7832\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  60%|██████    | 3/5 [00:00<00:00, 20.87batch/s]total loss: 1.03\n",
      "recon: 0.94\n",
      "reg: 2.21\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00, 11.98batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  6.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8713\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  60%|██████    | 3/5 [00:00<00:00, 24.21batch/s]total loss: 0.65\n",
      "recon: 0.62\n",
      "reg: 0.82\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00, 12.78batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7852\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  60%|██████    | 3/5 [00:00<00:00, 21.50batch/s]total loss: 0.69\n",
      "recon: 0.63\n",
      "reg: 1.59\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00, 10.84batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  4.17batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8002\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  40%|████      | 2/5 [00:00<00:00, 14.94batch/s]total loss: 0.72\n",
      "recon: 0.64\n",
      "reg: 2.07\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00, 11.87batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  5.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7891\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  60%|██████    | 3/5 [00:00<00:00, 22.18batch/s]total loss: 0.74\n",
      "recon: 0.80\n",
      "reg: -1.38\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 14.30batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  6.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8048\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  60%|██████    | 3/5 [00:00<00:00, 24.59batch/s]total loss: 1.69\n",
      "recon: 1.57\n",
      "reg: 2.98\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00, 12.83batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  5.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  60%|██████    | 3/5 [00:00<00:00, 16.74batch/s]total loss: 0.86\n",
      "recon: 0.87\n",
      "reg: -0.21\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00, 12.44batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  6.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8329\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  60%|██████    | 3/5 [00:00<00:00, 21.70batch/s]total loss: 0.89\n",
      "recon: 0.78\n",
      "reg: 2.58\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00, 14.37batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  6.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8424\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  60%|██████    | 3/5 [00:00<00:00, 24.15batch/s]total loss: 1.66\n",
      "recon: 1.62\n",
      "reg: 1.08\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 14.56batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  6.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0069\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  40%|████      | 2/5 [00:00<00:00, 14.37batch/s]total loss: 0.66\n",
      "recon: 0.64\n",
      "reg: 0.45\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00, 12.58batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  6.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8068\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_04-59-35/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 1.221418838575, Time: 113.35s\n",
      "Epoch 200, Training Loss: 0.491538102739, Time: 222.58s\n",
      "Epoch 300, Training Loss: 0.332566187717, Time: 337.78s\n",
      "Epoch 400, Training Loss: 0.260381536372, Time: 453.96s\n",
      "Epoch 500, Training Loss: 0.238699528901, Time: 564.38s\n",
      "Epoch 600, Training Loss: 0.214160446264, Time: 677.37s\n",
      "Epoch 700, Training Loss: 0.182535452335, Time: 792.87s\n",
      "Epoch 800, Training Loss: 0.158908702491, Time: 906.75s\n",
      "Epoch 900, Training Loss: 0.154207809153, Time: 1024.03s\n",
      "Epoch 1000, Training Loss: 0.136691391849, Time: 1137.99s\n",
      "Validation Loss: 0.177810805943\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.17781</td></tr><tr><td>val_loss</td><td>0.17781</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">apricot-sweep-38</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/19qxvglz' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/19qxvglz</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_045934-19qxvglz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1d1f4yy0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002817461524786971\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_051936-1d1f4yy0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/1d1f4yy0' target=\"_blank\">generous-sweep-39</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/1d1f4yy0' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/1d1f4yy0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_05-19-37. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  60%|██████    | 3/5 [00:00<00:00, 22.93batch/s]total loss: 6.57\n",
      "recon: 6.04\n",
      "reg: 13.33\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00, 13.63batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:00,  5.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 9.618\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 22.22batch/s]total loss: 3.78\n",
      "recon: 3.69\n",
      "reg: 2.27\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00, 13.69batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:00,  8.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 4.3731\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  60%|██████    | 3/5 [00:00<00:00, 25.09batch/s]total loss: 1.66\n",
      "recon: 1.47\n",
      "reg: 4.55\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00, 16.80batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:00,  8.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 2.5129\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  60%|██████    | 3/5 [00:00<00:00, 15.78batch/s]total loss: 1.25\n",
      "recon: 1.17\n",
      "reg: 2.03\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00, 12.43batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:00,  7.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.6694\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  60%|██████    | 3/5 [00:00<00:00, 26.31batch/s]total loss: 0.99\n",
      "recon: 0.93\n",
      "reg: 1.68\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00, 14.16batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:00,  5.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.2335\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 18.09batch/s]total loss: 1.15\n",
      "recon: 1.00\n",
      "reg: 3.74\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 12.18batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  6.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.158\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  60%|██████    | 3/5 [00:00<00:00, 25.44batch/s]total loss: 0.73\n",
      "recon: 0.77\n",
      "reg: -0.92\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 15.12batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  7.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9913\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  60%|██████    | 3/5 [00:00<00:00, 25.52batch/s]total loss: 0.72\n",
      "recon: 0.72\n",
      "reg: 0.03\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00, 14.45batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  6.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9148\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  60%|██████    | 3/5 [00:00<00:00, 25.96batch/s]total loss: 1.03\n",
      "recon: 0.89\n",
      "reg: 3.49\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00, 16.22batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  7.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9637\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  60%|██████    | 3/5 [00:00<00:00, 13.94batch/s]total loss: 0.73\n",
      "recon: 0.63\n",
      "reg: 2.36\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00, 12.18batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  8.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8591\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  60%|██████    | 3/5 [00:00<00:00, 26.83batch/s]total loss: 0.96\n",
      "recon: 0.83\n",
      "reg: 3.26\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 13.32batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  5.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9028\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  60%|██████    | 3/5 [00:00<00:00, 25.43batch/s]total loss: 0.90\n",
      "recon: 0.82\n",
      "reg: 2.14\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00, 15.29batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:00,  6.63batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.1281\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  60%|██████    | 3/5 [00:00<00:00, 21.28batch/s]total loss: 1.00\n",
      "recon: 0.96\n",
      "reg: 0.84\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 12.77batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  5.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9531\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  60%|██████    | 3/5 [00:00<00:00, 20.90batch/s]total loss: 0.54\n",
      "recon: 0.49\n",
      "reg: 1.14\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00, 13.27batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  5.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9048\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 16.30batch/s]total loss: 0.74\n",
      "recon: 0.74\n",
      "reg: -0.01\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00, 11.61batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  7.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9273\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 17.88batch/s]total loss: 0.88\n",
      "recon: 0.89\n",
      "reg: -0.28\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00, 12.78batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:00,  7.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  60%|██████    | 3/5 [00:00<00:00, 24.13batch/s]total loss: 1.05\n",
      "recon: 0.97\n",
      "reg: 1.81\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00, 12.24batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  4.55batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9335\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  60%|██████    | 3/5 [00:00<00:00, 25.97batch/s]total loss: 0.82\n",
      "recon: 0.68\n",
      "reg: 3.54\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00, 15.69batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  6.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8611\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 20.51batch/s]total loss: 0.40\n",
      "recon: 0.49\n",
      "reg: -2.44\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00, 12.35batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  7.20batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7805\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  60%|██████    | 3/5 [00:00<00:00, 25.94batch/s]total loss: 0.99\n",
      "recon: 1.02\n",
      "reg: -0.85\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00, 13.70batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.30batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8923\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  60%|██████    | 3/5 [00:00<00:00, 22.50batch/s]total loss: 1.26\n",
      "recon: 1.19\n",
      "reg: 1.64\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00, 14.60batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:00,  7.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9339\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  40%|████      | 2/5 [00:00<00:00, 10.13batch/s]total loss: 0.57\n",
      "recon: 0.64\n",
      "reg: -1.70\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00, 11.97batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:00,  8.04batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7958\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  60%|██████    | 3/5 [00:00<00:00, 24.90batch/s]total loss: 0.92\n",
      "recon: 0.88\n",
      "reg: 0.98\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00, 13.34batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  5.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8633\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  60%|██████    | 3/5 [00:00<00:00, 25.86batch/s]total loss: 1.03\n",
      "recon: 1.00\n",
      "reg: 0.64\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00, 13.66batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  5.25batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9341\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  80%|████████  | 4/5 [00:00<00:00, 16.15batch/s]total loss: 0.84\n",
      "recon: 0.80\n",
      "reg: 1.13\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00, 11.57batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:00,  7.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8531\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  60%|██████    | 3/5 [00:00<00:00, 25.80batch/s]total loss: 1.20\n",
      "recon: 1.06\n",
      "reg: 3.54\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00, 13.50batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:00,  6.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9188\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  60%|██████    | 3/5 [00:00<00:00, 23.97batch/s]total loss: 0.97\n",
      "recon: 0.80\n",
      "reg: 4.13\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00, 10.94batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:01,  3.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8748\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00, 21.11batch/s]total loss: 0.72\n",
      "recon: 0.65\n",
      "reg: 1.62\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00, 12.47batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  6.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8762\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  40%|████      | 2/5 [00:00<00:00, 16.77batch/s]total loss: 0.97\n",
      "recon: 0.94\n",
      "reg: 0.74\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 14.08batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  7.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8947\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  60%|██████    | 3/5 [00:00<00:00, 24.15batch/s]total loss: 0.64\n",
      "recon: 0.58\n",
      "reg: 1.52\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00, 10.58batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  3.54batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8136\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  60%|██████    | 3/5 [00:00<00:00, 12.85batch/s]total loss: 0.88\n",
      "recon: 0.91\n",
      "reg: -0.80\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 10.36batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  7.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8989\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  60%|██████    | 3/5 [00:00<00:00, 24.68batch/s]total loss: 0.95\n",
      "recon: 0.98\n",
      "reg: -0.69\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00, 12.35batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:00,  4.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0023\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  60%|██████    | 3/5 [00:00<00:00, 22.28batch/s]total loss: 0.68\n",
      "recon: 0.70\n",
      "reg: -0.74\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00, 14.62batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  6.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8839\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100:  80%|████████  | 4/5 [00:00<00:00, 17.74batch/s]total loss: 0.87\n",
      "recon: 0.92\n",
      "reg: -1.02\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  9.89batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  4.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8715\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  60%|██████    | 3/5 [00:00<00:00, 26.27batch/s]total loss: 1.25\n",
      "recon: 1.20\n",
      "reg: 1.31\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00, 12.64batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  4.83batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9198\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  60%|██████    | 3/5 [00:00<00:00, 24.64batch/s]total loss: 0.59\n",
      "recon: 0.64\n",
      "reg: -1.16\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00, 13.58batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  5.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8087\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  60%|██████    | 3/5 [00:00<00:00, 24.32batch/s]total loss: 0.72\n",
      "recon: 0.74\n",
      "reg: -0.72\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00, 12.13batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  4.46batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8328\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  60%|██████    | 3/5 [00:00<00:00, 25.18batch/s]total loss: 0.70\n",
      "recon: 0.64\n",
      "reg: 1.45\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 13.46batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 16.39batch/s]total loss: 0.85\n",
      "recon: 0.80\n",
      "reg: 1.47\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00, 11.91batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:00,  6.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8568\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  60%|██████    | 3/5 [00:00<00:00, 24.58batch/s]total loss: 1.34\n",
      "recon: 1.29\n",
      "reg: 1.44\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 13.09batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  5.11batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9474\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  60%|██████    | 3/5 [00:00<00:00, 22.33batch/s]total loss: 1.21\n",
      "recon: 1.05\n",
      "reg: 3.86\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 14.13batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  6.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9591\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00, 21.30batch/s]total loss: 1.30\n",
      "recon: 1.30\n",
      "reg: -0.01\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00, 12.75batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  7.13batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.955\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  60%|██████    | 3/5 [00:00<00:00, 23.20batch/s]total loss: 0.96\n",
      "recon: 0.96\n",
      "reg: 0.15\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00, 12.55batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  5.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8643\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  40%|████      | 2/5 [00:00<00:00, 15.39batch/s]total loss: 0.86\n",
      "recon: 0.85\n",
      "reg: 0.35\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 13.63batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  7.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.85\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  80%|████████  | 4/5 [00:00<00:00, 16.64batch/s]total loss: 0.95\n",
      "recon: 0.91\n",
      "reg: 1.00\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00, 11.97batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  7.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8873\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  80%|████████  | 4/5 [00:00<00:00, 15.83batch/s]total loss: 1.00\n",
      "recon: 0.90\n",
      "reg: 2.39\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00, 11.72batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  6.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8763\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  60%|██████    | 3/5 [00:00<00:00, 24.36batch/s]total loss: 0.94\n",
      "recon: 0.95\n",
      "reg: -0.39\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00, 12.42batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  4.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8607\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  60%|██████    | 3/5 [00:00<00:00, 21.25batch/s]total loss: 0.99\n",
      "recon: 0.96\n",
      "reg: 0.68\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00, 14.68batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:00,  7.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8696\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  60%|██████    | 3/5 [00:00<00:00, 23.88batch/s]total loss: 0.37\n",
      "recon: 0.57\n",
      "reg: -4.88\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00, 12.10batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:00,  7.24batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.756\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 21.25batch/s]total loss: 1.05\n",
      "recon: 1.03\n",
      "reg: 0.56\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 10.14batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  4.26batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9286\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  40%|████      | 2/5 [00:00<00:00, 13.96batch/s]total loss: 1.01\n",
      "recon: 0.95\n",
      "reg: 1.49\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 12.85batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  6.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9115\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 16.69batch/s]total loss: 0.73\n",
      "recon: 0.73\n",
      "reg: 0.11\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00, 11.73batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  6.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8219\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  60%|██████    | 3/5 [00:00<00:00, 24.73batch/s]total loss: 0.63\n",
      "recon: 0.62\n",
      "reg: 0.27\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00, 13.13batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  6.15batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7857\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 23.85batch/s]total loss: 0.67\n",
      "recon: 0.78\n",
      "reg: -2.80\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00, 12.07batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7882\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 23.64batch/s]total loss: 1.01\n",
      "recon: 1.05\n",
      "reg: -1.00\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00, 13.71batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:00,  7.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8625\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  60%|██████    | 3/5 [00:00<00:00, 21.87batch/s]total loss: 0.82\n",
      "recon: 0.79\n",
      "reg: 0.95\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 11.99batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  6.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8205\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  40%|████      | 2/5 [00:00<00:00, 14.54batch/s]total loss: 0.92\n",
      "recon: 0.76\n",
      "reg: 3.99\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00, 10.28batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  4.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8448\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  60%|██████    | 3/5 [00:00<00:00, 25.20batch/s]total loss: 0.88\n",
      "recon: 0.94\n",
      "reg: -1.60\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00, 15.64batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  7.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8338\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 18.47batch/s]total loss: 0.73\n",
      "recon: 0.65\n",
      "reg: 2.04\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00, 13.09batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:00,  7.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8135\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00, 22.24batch/s]total loss: 0.29\n",
      "recon: 0.41\n",
      "reg: -3.13\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  8.18batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  2.73batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7155\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  60%|██████    | 3/5 [00:00<00:00, 26.18batch/s]total loss: 0.57\n",
      "recon: 0.57\n",
      "reg: 0.04\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 12.68batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  5.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7851\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 20.60batch/s]total loss: 0.95\n",
      "recon: 0.99\n",
      "reg: -0.94\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 10.94batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  5.10batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8465\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  60%|██████    | 3/5 [00:00<00:00, 22.23batch/s]total loss: 0.65\n",
      "recon: 0.72\n",
      "reg: -1.85\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00, 11.73batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  4.40batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7768\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  60%|██████    | 3/5 [00:00<00:00, 22.63batch/s]total loss: 1.13\n",
      "recon: 1.01\n",
      "reg: 3.17\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00, 14.56batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  6.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8888\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 22.67batch/s]total loss: 0.76\n",
      "recon: 0.80\n",
      "reg: -0.98\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 11.44batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8045\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  60%|██████    | 3/5 [00:00<00:00, 22.18batch/s]total loss: 1.35\n",
      "recon: 1.28\n",
      "reg: 1.65\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 12.30batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  4.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9959\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  60%|██████    | 3/5 [00:00<00:00, 23.87batch/s]total loss: 0.79\n",
      "recon: 0.77\n",
      "reg: 0.61\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00, 15.53batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  7.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9093\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00, 24.24batch/s]total loss: 0.91\n",
      "recon: 0.81\n",
      "reg: 2.62\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00, 13.52batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:00,  6.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9013\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 16.34batch/s]total loss: 0.87\n",
      "recon: 0.83\n",
      "reg: 0.84\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00, 11.54batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  6.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8714\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  60%|██████    | 3/5 [00:00<00:00, 24.69batch/s]total loss: 0.87\n",
      "recon: 0.98\n",
      "reg: -2.71\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 14.21batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  5.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8445\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  40%|████      | 2/5 [00:00<00:00, 17.12batch/s]total loss: 0.58\n",
      "recon: 0.69\n",
      "reg: -2.76\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00, 13.75batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:00,  6.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7994\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 12.50batch/s]total loss: 0.59\n",
      "recon: 0.58\n",
      "reg: 0.29\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00, 10.35batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  6.79batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8111\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  60%|██████    | 3/5 [00:00<00:00, 25.14batch/s]total loss: 0.79\n",
      "recon: 0.80\n",
      "reg: -0.39\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00,  8.94batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:01,  2.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8246\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 25.12batch/s]total loss: 0.43\n",
      "recon: 0.40\n",
      "reg: 0.55\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00, 14.66batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:00,  7.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7533\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 15.54batch/s]total loss: 0.75\n",
      "recon: 0.73\n",
      "reg: 0.48\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 11.30batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  7.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8145\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  60%|██████    | 3/5 [00:00<00:00, 21.14batch/s]total loss: 0.95\n",
      "recon: 0.95\n",
      "reg: -0.01\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00, 10.82batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  5.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8654\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  60%|██████    | 3/5 [00:00<00:00, 23.36batch/s]total loss: 1.06\n",
      "recon: 1.01\n",
      "reg: 1.35\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00, 11.23batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:01,  3.96batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8969\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 24.14batch/s]total loss: 0.68\n",
      "recon: 0.71\n",
      "reg: -0.81\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00, 13.69batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:00,  6.78batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8474\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  60%|██████    | 3/5 [00:00<00:00, 17.57batch/s]total loss: 0.32\n",
      "recon: 0.42\n",
      "reg: -2.41\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00, 12.66batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  6.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.745\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  60%|██████    | 3/5 [00:00<00:00, 24.40batch/s]total loss: 0.76\n",
      "recon: 0.62\n",
      "reg: 3.58\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 12.83batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  4.93batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.816\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  60%|██████    | 3/5 [00:00<00:00, 21.56batch/s]total loss: 0.71\n",
      "recon: 0.74\n",
      "reg: -0.67\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00, 14.08batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  6.66batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.817\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100:  60%|██████    | 3/5 [00:00<00:00, 25.06batch/s]total loss: 0.52\n",
      "recon: 0.46\n",
      "reg: 1.53\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00, 10.97batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  6.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7839\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  60%|██████    | 3/5 [00:00<00:00, 24.71batch/s]total loss: 0.73\n",
      "recon: 0.69\n",
      "reg: 0.84\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00,  9.12batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:01,  2.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8012\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  60%|██████    | 3/5 [00:00<00:00, 23.02batch/s]total loss: 0.90\n",
      "recon: 0.88\n",
      "reg: 0.29\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00, 13.51batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  5.75batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8352\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 22.60batch/s]total loss: 0.96\n",
      "recon: 0.88\n",
      "reg: 2.14\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00, 12.28batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  6.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8412\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  60%|██████    | 3/5 [00:00<00:00, 24.75batch/s]total loss: 0.93\n",
      "recon: 0.81\n",
      "reg: 2.97\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 11.74batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  6.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8484\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  60%|██████    | 3/5 [00:00<00:00, 22.69batch/s]total loss: 0.70\n",
      "recon: 0.78\n",
      "reg: -2.07\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 13.84batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  6.01batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8034\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  40%|████      | 2/5 [00:00<00:00, 17.56batch/s]total loss: 1.16\n",
      "recon: 1.09\n",
      "reg: 1.76\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00, 13.62batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  6.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8877\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  60%|██████    | 3/5 [00:00<00:00, 12.70batch/s]total loss: 0.92\n",
      "recon: 0.92\n",
      "reg: -0.03\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00, 10.55batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  6.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8281\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  60%|██████    | 3/5 [00:00<00:00, 24.20batch/s]total loss: 0.70\n",
      "recon: 0.66\n",
      "reg: 1.03\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00, 10.37batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  3.37batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7832\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  60%|██████    | 3/5 [00:00<00:00, 20.74batch/s]total loss: 1.03\n",
      "recon: 0.94\n",
      "reg: 2.21\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00, 12.25batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:00,  5.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8713\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  60%|██████    | 3/5 [00:00<00:00, 22.41batch/s]total loss: 0.65\n",
      "recon: 0.62\n",
      "reg: 0.82\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00, 11.48batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  7.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7852\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  60%|██████    | 3/5 [00:00<00:00, 23.42batch/s]total loss: 0.69\n",
      "recon: 0.63\n",
      "reg: 1.59\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00, 10.67batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:01,  3.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8002\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  60%|██████    | 3/5 [00:00<00:00, 24.18batch/s]total loss: 0.72\n",
      "recon: 0.64\n",
      "reg: 2.07\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00, 15.10batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  6.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7891\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 16.12batch/s]total loss: 0.74\n",
      "recon: 0.80\n",
      "reg: -1.38\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 11.30batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  6.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8048\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  60%|██████    | 3/5 [00:00<00:00, 22.99batch/s]total loss: 1.69\n",
      "recon: 1.57\n",
      "reg: 2.98\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00, 11.85batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  4.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  60%|██████    | 3/5 [00:00<00:00, 22.95batch/s]total loss: 0.86\n",
      "recon: 0.87\n",
      "reg: -0.21\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00, 14.39batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  6.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8329\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 16.79batch/s]total loss: 0.89\n",
      "recon: 0.78\n",
      "reg: 2.58\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00, 11.56batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  6.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8424\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  60%|██████    | 3/5 [00:00<00:00, 14.68batch/s]total loss: 1.66\n",
      "recon: 1.62\n",
      "reg: 1.08\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00, 12.03batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:00,  7.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0069\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  60%|██████    | 3/5 [00:00<00:00, 22.91batch/s]total loss: 0.66\n",
      "recon: 0.64\n",
      "reg: 0.45\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00, 11.99batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  4.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8068\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_05-19-37/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 1.221418838575, Time: 111.14s\n",
      "Epoch 200, Training Loss: 0.491538102739, Time: 222.37s\n",
      "Epoch 300, Training Loss: 0.332566187717, Time: 334.19s\n",
      "Epoch 400, Training Loss: 0.260381536372, Time: 450.50s\n",
      "Epoch 500, Training Loss: 0.238699528901, Time: 562.86s\n",
      "Epoch 600, Training Loss: 0.214160446264, Time: 664.81s\n",
      "Epoch 700, Training Loss: 0.182535452335, Time: 770.52s\n",
      "Epoch 800, Training Loss: 0.158908702491, Time: 881.83s\n",
      "Epoch 900, Training Loss: 0.154207809153, Time: 994.91s\n",
      "Epoch 1000, Training Loss: 0.136691391849, Time: 1109.02s\n",
      "Validation Loss: 0.177810805943\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.17781</td></tr><tr><td>val_loss</td><td>0.17781</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">generous-sweep-39</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/1d1f4yy0' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/1d1f4yy0</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_051936-1d1f4yy0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nw5zk7f3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_hidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tD_num_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_hidden_dim: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tE_num_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.006888089480053875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sondrerogde/Dev/master-thesis/src/models/data_generating_models/TimeCausalVAE/notebooks/wandb/run-20250326_053903-nw5zk7f3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/nw5zk7f3' target=\"_blank\">blooming-sweep-40</a></strong> to <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/sweeps/xrvotxdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/nw5zk7f3' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/nw5zk7f3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment results saved to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Saving experiment config to ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test\n",
      "Setting ramdom seed: 0\n",
      "Base dataset initialized\n",
      "Path Visualization of data\n",
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_05-39-04. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 100\n",
      " - per_device_train_batch_size: 256\n",
      " - per_device_eval_batch_size: 256\n",
      " - checkpoint saving every: 30\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler: None\n",
      "Device: cpu\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/100:  60%|██████    | 3/5 [00:00<00:00, 11.39batch/s]total loss: 4.22\n",
      "recon: 3.77\n",
      "reg: 11.31\n",
      "Training of epoch 1/100: 100%|██████████| 5/5 [00:00<00:00,  8.09batch/s]\n",
      "Eval of epoch 1/100:  20%|██        | 1/5 [00:00<00:00,  4.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 5.8681\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/100:  80%|████████  | 4/5 [00:00<00:00, 17.62batch/s]total loss: 1.65\n",
      "recon: 1.54\n",
      "reg: 2.77\n",
      "Training of epoch 2/100: 100%|██████████| 5/5 [00:00<00:00,  6.46batch/s]\n",
      "Eval of epoch 2/100:  20%|██        | 1/5 [00:00<00:02,  1.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 2.0765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/100:  60%|██████    | 3/5 [00:00<00:00, 10.82batch/s]total loss: 1.12\n",
      "recon: 1.00\n",
      "reg: 3.06\n",
      "Training of epoch 3/100: 100%|██████████| 5/5 [00:00<00:00,  6.43batch/s]\n",
      "Eval of epoch 3/100:  20%|██        | 1/5 [00:00<00:01,  2.47batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.3569\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/100:  80%|████████  | 4/5 [00:00<00:00, 15.44batch/s]total loss: 0.75\n",
      "recon: 0.73\n",
      "reg: 0.54\n",
      "Training of epoch 4/100: 100%|██████████| 5/5 [00:00<00:00,  8.43batch/s]\n",
      "Eval of epoch 4/100:  20%|██        | 1/5 [00:00<00:01,  3.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.3297\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/100:  80%|████████  | 4/5 [00:00<00:00, 12.56batch/s]total loss: 0.75\n",
      "recon: 0.72\n",
      "reg: 0.86\n",
      "Training of epoch 5/100: 100%|██████████| 5/5 [00:00<00:00,  7.15batch/s]\n",
      "Eval of epoch 5/100:  20%|██        | 1/5 [00:00<00:01,  2.90batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9718\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/100:  80%|████████  | 4/5 [00:00<00:00, 17.42batch/s]total loss: 0.86\n",
      "recon: 0.67\n",
      "reg: 4.65\n",
      "Training of epoch 6/100: 100%|██████████| 5/5 [00:00<00:00, 10.71batch/s]\n",
      "Eval of epoch 6/100:  20%|██        | 1/5 [00:00<00:00,  4.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9357\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/100:  80%|████████  | 4/5 [00:00<00:00, 15.93batch/s]total loss: 0.58\n",
      "recon: 0.62\n",
      "reg: -0.89\n",
      "Training of epoch 7/100: 100%|██████████| 5/5 [00:00<00:00, 10.72batch/s]\n",
      "Eval of epoch 7/100:  20%|██        | 1/5 [00:00<00:00,  5.42batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8504\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/100:  60%|██████    | 3/5 [00:00<00:00, 13.46batch/s]total loss: 0.70\n",
      "recon: 0.68\n",
      "reg: 0.41\n",
      "Training of epoch 8/100: 100%|██████████| 5/5 [00:00<00:00,  9.85batch/s]\n",
      "Eval of epoch 8/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8605\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/100:  80%|████████  | 4/5 [00:00<00:00, 12.25batch/s]total loss: 1.01\n",
      "recon: 0.83\n",
      "reg: 4.63\n",
      "Training of epoch 9/100: 100%|██████████| 5/5 [00:00<00:00,  8.99batch/s]\n",
      "Eval of epoch 9/100:  20%|██        | 1/5 [00:00<00:00,  5.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8974\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/100:  80%|████████  | 4/5 [00:00<00:00, 11.35batch/s]total loss: 0.63\n",
      "recon: 0.53\n",
      "reg: 2.50\n",
      "Training of epoch 10/100: 100%|██████████| 5/5 [00:00<00:00,  8.98batch/s]\n",
      "Eval of epoch 10/100:  20%|██        | 1/5 [00:00<00:00,  5.05batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8088\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 11/100:  80%|████████  | 4/5 [00:00<00:00, 18.81batch/s]total loss: 0.84\n",
      "recon: 0.68\n",
      "reg: 4.15\n",
      "Training of epoch 11/100: 100%|██████████| 5/5 [00:00<00:00, 10.00batch/s]\n",
      "Eval of epoch 11/100:  20%|██        | 1/5 [00:00<00:00,  4.57batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8563\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 12/100:  80%|████████  | 4/5 [00:00<00:00, 15.91batch/s]total loss: 0.83\n",
      "recon: 0.70\n",
      "reg: 3.16\n",
      "Training of epoch 12/100: 100%|██████████| 5/5 [00:00<00:00,  8.99batch/s]\n",
      "Eval of epoch 12/100:  20%|██        | 1/5 [00:00<00:01,  3.71batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0289\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 13/100:  80%|████████  | 4/5 [00:00<00:00, 17.38batch/s]total loss: 0.90\n",
      "recon: 0.87\n",
      "reg: 0.61\n",
      "Training of epoch 13/100: 100%|██████████| 5/5 [00:00<00:00, 11.01batch/s]\n",
      "Eval of epoch 13/100:  20%|██        | 1/5 [00:00<00:00,  5.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8983\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 14/100:  60%|██████    | 3/5 [00:00<00:00, 13.02batch/s]total loss: 0.50\n",
      "recon: 0.48\n",
      "reg: 0.51\n",
      "Training of epoch 14/100: 100%|██████████| 5/5 [00:00<00:00,  9.64batch/s]\n",
      "Eval of epoch 14/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8685\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 15/100:  80%|████████  | 4/5 [00:00<00:00, 13.32batch/s]total loss: 0.73\n",
      "recon: 0.74\n",
      "reg: -0.29\n",
      "Training of epoch 15/100: 100%|██████████| 5/5 [00:00<00:00,  9.04batch/s]\n",
      "Eval of epoch 15/100:  20%|██        | 1/5 [00:00<00:00,  5.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.945\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 16/100:  80%|████████  | 4/5 [00:00<00:00, 19.48batch/s]total loss: 0.84\n",
      "recon: 0.88\n",
      "reg: -0.84\n",
      "Training of epoch 16/100: 100%|██████████| 5/5 [00:00<00:00,  9.32batch/s]\n",
      "Eval of epoch 16/100:  20%|██        | 1/5 [00:00<00:01,  3.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9212\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 17/100:  80%|████████  | 4/5 [00:00<00:00, 17.34batch/s]total loss: 1.04\n",
      "recon: 0.98\n",
      "reg: 1.45\n",
      "Training of epoch 17/100: 100%|██████████| 5/5 [00:00<00:00, 10.24batch/s]\n",
      "Eval of epoch 17/100:  20%|██        | 1/5 [00:00<00:00,  4.37batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9489\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 18/100:  80%|████████  | 4/5 [00:00<00:00, 18.10batch/s]total loss: 0.80\n",
      "recon: 0.66\n",
      "reg: 3.54\n",
      "Training of epoch 18/100: 100%|██████████| 5/5 [00:00<00:00,  9.92batch/s]\n",
      "Eval of epoch 18/100:  20%|██        | 1/5 [00:00<00:00,  4.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.868\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 19/100:  80%|████████  | 4/5 [00:00<00:00, 14.51batch/s]total loss: 0.41\n",
      "recon: 0.50\n",
      "reg: -2.36\n",
      "Training of epoch 19/100: 100%|██████████| 5/5 [00:00<00:00,  9.83batch/s]\n",
      "Eval of epoch 19/100:  20%|██        | 1/5 [00:00<00:00,  5.03batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7855\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 20/100:  80%|████████  | 4/5 [00:00<00:00, 13.03batch/s]total loss: 1.01\n",
      "recon: 1.02\n",
      "reg: -0.26\n",
      "Training of epoch 20/100: 100%|██████████| 5/5 [00:00<00:00,  9.81batch/s]\n",
      "Eval of epoch 20/100:  20%|██        | 1/5 [00:00<00:00,  5.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9014\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 21/100:  80%|████████  | 4/5 [00:00<00:00, 18.86batch/s]total loss: 1.25\n",
      "recon: 1.16\n",
      "reg: 2.12\n",
      "Training of epoch 21/100: 100%|██████████| 5/5 [00:00<00:00,  8.99batch/s]\n",
      "Eval of epoch 21/100:  20%|██        | 1/5 [00:00<00:01,  3.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9263\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 22/100:  80%|████████  | 4/5 [00:00<00:00, 16.31batch/s]total loss: 0.56\n",
      "recon: 0.64\n",
      "reg: -2.12\n",
      "Training of epoch 22/100: 100%|██████████| 5/5 [00:00<00:00,  8.71batch/s]\n",
      "Eval of epoch 22/100:  20%|██        | 1/5 [00:00<00:01,  3.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.792\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 23/100:  80%|████████  | 4/5 [00:00<00:00, 19.22batch/s]total loss: 0.90\n",
      "recon: 0.86\n",
      "reg: 0.97\n",
      "Training of epoch 23/100: 100%|██████████| 5/5 [00:00<00:00, 11.78batch/s]\n",
      "Eval of epoch 23/100:  20%|██        | 1/5 [00:00<00:00,  5.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8642\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 24/100:  60%|██████    | 3/5 [00:00<00:00, 13.08batch/s]total loss: 1.04\n",
      "recon: 1.03\n",
      "reg: 0.46\n",
      "Training of epoch 24/100: 100%|██████████| 5/5 [00:00<00:00,  9.26batch/s]\n",
      "Eval of epoch 24/100:  20%|██        | 1/5 [00:00<00:00,  4.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9214\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 25/100:  60%|██████    | 3/5 [00:00<00:00, 10.09batch/s]total loss: 0.85\n",
      "recon: 0.80\n",
      "reg: 1.07\n",
      "Training of epoch 25/100: 100%|██████████| 5/5 [00:00<00:00,  7.47batch/s]\n",
      "Eval of epoch 25/100:  20%|██        | 1/5 [00:00<00:01,  3.60batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8486\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 26/100:  80%|████████  | 4/5 [00:00<00:00, 17.43batch/s]total loss: 1.23\n",
      "recon: 1.09\n",
      "reg: 3.67\n",
      "Training of epoch 26/100: 100%|██████████| 5/5 [00:00<00:00,  8.44batch/s]\n",
      "Eval of epoch 26/100:  20%|██        | 1/5 [00:00<00:01,  3.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9084\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 27/100:  80%|████████  | 4/5 [00:00<00:00, 18.63batch/s]total loss: 0.90\n",
      "recon: 0.72\n",
      "reg: 4.61\n",
      "Training of epoch 27/100: 100%|██████████| 5/5 [00:00<00:00,  9.03batch/s]\n",
      "Eval of epoch 27/100:  20%|██        | 1/5 [00:00<00:01,  3.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8568\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 28/100:  80%|████████  | 4/5 [00:00<00:00, 13.75batch/s]total loss: 0.67\n",
      "recon: 0.62\n",
      "reg: 1.08\n",
      "Training of epoch 28/100: 100%|██████████| 5/5 [00:00<00:00,  9.30batch/s]\n",
      "Eval of epoch 28/100:  20%|██        | 1/5 [00:00<00:00,  4.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8687\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 29/100:  80%|████████  | 4/5 [00:00<00:00, 17.44batch/s]total loss: 0.96\n",
      "recon: 0.90\n",
      "reg: 1.38\n",
      "Training of epoch 29/100: 100%|██████████| 5/5 [00:00<00:00, 11.24batch/s]\n",
      "Eval of epoch 29/100:  20%|██        | 1/5 [00:00<00:00,  5.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8994\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 30/100:  80%|████████  | 4/5 [00:00<00:00, 15.24batch/s]total loss: 0.66\n",
      "recon: 0.59\n",
      "reg: 1.71\n",
      "Training of epoch 30/100: 100%|██████████| 5/5 [00:00<00:00,  8.27batch/s]\n",
      "Eval of epoch 30/100:  20%|██        | 1/5 [00:00<00:01,  3.19batch/s]\n",
      "Saved checkpoint at epoch 30\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.821\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 31/100:  80%|████████  | 4/5 [00:00<00:00, 17.41batch/s]total loss: 0.99\n",
      "recon: 1.01\n",
      "reg: -0.54\n",
      "Training of epoch 31/100: 100%|██████████| 5/5 [00:00<00:00, 10.00batch/s]\n",
      "Eval of epoch 31/100:  20%|██        | 1/5 [00:00<00:00,  4.09batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9282\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 32/100:  80%|████████  | 4/5 [00:00<00:00, 19.25batch/s]total loss: 0.90\n",
      "recon: 0.92\n",
      "reg: -0.43\n",
      "Training of epoch 32/100: 100%|██████████| 5/5 [00:00<00:00, 10.07batch/s]\n",
      "Eval of epoch 32/100:  20%|██        | 1/5 [00:00<00:01,  3.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9571\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 33/100:  60%|██████    | 3/5 [00:00<00:00, 14.10batch/s]total loss: 0.69\n",
      "recon: 0.72\n",
      "reg: -0.65\n",
      "Training of epoch 33/100: 100%|██████████| 5/5 [00:00<00:00, 10.01batch/s]\n",
      "Eval of epoch 33/100:  20%|██        | 1/5 [00:00<00:00,  5.43batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8632\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00, 13.25batch/s]total loss: 0.72\n",
      "recon: 0.75\n",
      "reg: -0.95\n",
      "Training of epoch 34/100: 100%|██████████| 5/5 [00:00<00:00,  8.00batch/s]\n",
      "Eval of epoch 34/100:  20%|██        | 1/5 [00:00<00:00,  4.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8364\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 35/100:  80%|████████  | 4/5 [00:00<00:00, 14.76batch/s]total loss: 1.22\n",
      "recon: 1.17\n",
      "reg: 1.17\n",
      "Training of epoch 35/100: 100%|██████████| 5/5 [00:00<00:00, 10.14batch/s]\n",
      "Eval of epoch 35/100:  20%|██        | 1/5 [00:00<00:00,  4.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9152\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 36/100:  60%|██████    | 3/5 [00:00<00:00, 13.37batch/s]total loss: 0.61\n",
      "recon: 0.66\n",
      "reg: -1.35\n",
      "Training of epoch 36/100: 100%|██████████| 5/5 [00:00<00:00,  9.11batch/s]\n",
      "Eval of epoch 36/100:  20%|██        | 1/5 [00:00<00:00,  4.23batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8131\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 37/100:  60%|██████    | 3/5 [00:00<00:00, 10.62batch/s]total loss: 0.67\n",
      "recon: 0.71\n",
      "reg: -0.88\n",
      "Training of epoch 37/100: 100%|██████████| 5/5 [00:00<00:00,  8.91batch/s]\n",
      "Eval of epoch 37/100:  20%|██        | 1/5 [00:00<00:00,  5.22batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8229\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 38/100:  80%|████████  | 4/5 [00:00<00:00, 18.35batch/s]total loss: 0.75\n",
      "recon: 0.71\n",
      "reg: 1.01\n",
      "Training of epoch 38/100: 100%|██████████| 5/5 [00:00<00:00, 10.70batch/s]\n",
      "Eval of epoch 38/100:  20%|██        | 1/5 [00:00<00:00,  5.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8788\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 39/100:  80%|████████  | 4/5 [00:00<00:00, 14.48batch/s]total loss: 0.86\n",
      "recon: 0.79\n",
      "reg: 1.79\n",
      "Training of epoch 39/100: 100%|██████████| 5/5 [00:00<00:00,  8.90batch/s]\n",
      "Eval of epoch 39/100:  20%|██        | 1/5 [00:00<00:01,  3.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8673\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 40/100:  80%|████████  | 4/5 [00:00<00:00, 18.21batch/s]total loss: 1.31\n",
      "recon: 1.27\n",
      "reg: 1.05\n",
      "Training of epoch 40/100: 100%|██████████| 5/5 [00:00<00:00, 11.76batch/s]\n",
      "Eval of epoch 40/100:  20%|██        | 1/5 [00:00<00:00,  5.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 41/100:  80%|████████  | 4/5 [00:00<00:00, 14.26batch/s]total loss: 1.20\n",
      "recon: 1.07\n",
      "reg: 3.32\n",
      "Training of epoch 41/100: 100%|██████████| 5/5 [00:00<00:00, 10.15batch/s]\n",
      "Eval of epoch 41/100:  20%|██        | 1/5 [00:00<00:00,  5.51batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9633\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 42/100:  80%|████████  | 4/5 [00:00<00:00, 14.20batch/s]total loss: 1.30\n",
      "recon: 1.31\n",
      "reg: -0.36\n",
      "Training of epoch 42/100: 100%|██████████| 5/5 [00:00<00:00, 10.37batch/s]\n",
      "Eval of epoch 42/100:  20%|██        | 1/5 [00:00<00:00,  5.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9496\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 43/100:  80%|████████  | 4/5 [00:00<00:00, 14.69batch/s]total loss: 0.93\n",
      "recon: 0.93\n",
      "reg: 0.17\n",
      "Training of epoch 43/100: 100%|██████████| 5/5 [00:00<00:00,  9.30batch/s]\n",
      "Eval of epoch 43/100:  20%|██        | 1/5 [00:00<00:00,  4.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8446\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 44/100:  80%|████████  | 4/5 [00:00<00:00, 18.69batch/s]total loss: 0.94\n",
      "recon: 0.92\n",
      "reg: 0.39\n",
      "Training of epoch 44/100: 100%|██████████| 5/5 [00:00<00:00, 12.02batch/s]\n",
      "Eval of epoch 44/100:  20%|██        | 1/5 [00:00<00:00,  5.72batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8562\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 45/100:  60%|██████    | 3/5 [00:00<00:00, 11.81batch/s]total loss: 0.93\n",
      "recon: 0.88\n",
      "reg: 1.24\n",
      "Training of epoch 45/100: 100%|██████████| 5/5 [00:00<00:00,  9.26batch/s]\n",
      "Eval of epoch 45/100:  20%|██        | 1/5 [00:00<00:00,  5.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8977\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 46/100:  60%|██████    | 3/5 [00:00<00:00,  9.26batch/s]total loss: 0.97\n",
      "recon: 0.88\n",
      "reg: 2.09\n",
      "Training of epoch 46/100: 100%|██████████| 5/5 [00:00<00:00,  7.87batch/s]\n",
      "Eval of epoch 46/100:  20%|██        | 1/5 [00:00<00:00,  4.34batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8641\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 47/100:  80%|████████  | 4/5 [00:00<00:00, 12.64batch/s]total loss: 0.90\n",
      "recon: 0.94\n",
      "reg: -1.15\n",
      "Training of epoch 47/100: 100%|██████████| 5/5 [00:00<00:00,  9.65batch/s]\n",
      "Eval of epoch 47/100:  20%|██        | 1/5 [00:00<00:00,  5.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8433\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 48/100:  80%|████████  | 4/5 [00:00<00:00, 18.26batch/s]total loss: 1.01\n",
      "recon: 0.98\n",
      "reg: 0.77\n",
      "Training of epoch 48/100: 100%|██████████| 5/5 [00:00<00:00,  9.61batch/s]\n",
      "Eval of epoch 48/100:  20%|██        | 1/5 [00:00<00:01,  3.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8775\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 49/100:  60%|██████    | 3/5 [00:00<00:00, 14.94batch/s]total loss: 0.34\n",
      "recon: 0.52\n",
      "reg: -4.56\n",
      "Training of epoch 49/100: 100%|██████████| 5/5 [00:00<00:00,  8.05batch/s]\n",
      "Eval of epoch 49/100:  20%|██        | 1/5 [00:00<00:01,  3.06batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7418\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 50/100:  80%|████████  | 4/5 [00:00<00:00, 18.50batch/s]total loss: 1.08\n",
      "recon: 1.06\n",
      "reg: 0.47\n",
      "Training of epoch 50/100: 100%|██████████| 5/5 [00:00<00:00, 11.21batch/s]\n",
      "Eval of epoch 50/100:  20%|██        | 1/5 [00:00<00:00,  4.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9505\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 51/100:  80%|████████  | 4/5 [00:00<00:00, 17.10batch/s]total loss: 1.03\n",
      "recon: 0.97\n",
      "reg: 1.44\n",
      "Training of epoch 51/100: 100%|██████████| 5/5 [00:00<00:00, 10.19batch/s]\n",
      "Eval of epoch 51/100:  20%|██        | 1/5 [00:00<00:00,  4.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9209\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 52/100:  80%|████████  | 4/5 [00:00<00:00, 14.24batch/s]total loss: 0.71\n",
      "recon: 0.72\n",
      "reg: -0.06\n",
      "Training of epoch 52/100: 100%|██████████| 5/5 [00:00<00:00,  9.38batch/s]\n",
      "Eval of epoch 52/100:  20%|██        | 1/5 [00:00<00:00,  4.61batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8215\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 53/100:  80%|████████  | 4/5 [00:00<00:00, 15.16batch/s]total loss: 0.61\n",
      "recon: 0.59\n",
      "reg: 0.44\n",
      "Training of epoch 53/100: 100%|██████████| 5/5 [00:00<00:00,  9.50batch/s]\n",
      "Eval of epoch 53/100:  20%|██        | 1/5 [00:00<00:00,  4.08batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.779\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 54/100:  80%|████████  | 4/5 [00:00<00:00, 18.68batch/s]total loss: 0.64\n",
      "recon: 0.76\n",
      "reg: -2.85\n",
      "Training of epoch 54/100: 100%|██████████| 5/5 [00:00<00:00,  8.16batch/s]\n",
      "Eval of epoch 54/100:  20%|██        | 1/5 [00:00<00:01,  2.69batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7735\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 55/100:  80%|████████  | 4/5 [00:00<00:00, 17.83batch/s]total loss: 0.98\n",
      "recon: 1.03\n",
      "reg: -1.16\n",
      "Training of epoch 55/100: 100%|██████████| 5/5 [00:00<00:00,  8.69batch/s]\n",
      "Eval of epoch 55/100:  20%|██        | 1/5 [00:00<00:01,  3.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 56/100:  80%|████████  | 4/5 [00:00<00:00, 18.61batch/s]total loss: 0.81\n",
      "recon: 0.78\n",
      "reg: 0.95\n",
      "Training of epoch 56/100: 100%|██████████| 5/5 [00:00<00:00, 12.03batch/s]\n",
      "Eval of epoch 56/100:  20%|██        | 1/5 [00:00<00:00,  5.84batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8081\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 57/100:  60%|██████    | 3/5 [00:00<00:00, 13.01batch/s]total loss: 0.88\n",
      "recon: 0.72\n",
      "reg: 3.95\n",
      "Training of epoch 57/100: 100%|██████████| 5/5 [00:00<00:00,  9.86batch/s]\n",
      "Eval of epoch 57/100:  20%|██        | 1/5 [00:00<00:00,  5.74batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8261\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 58/100:  80%|████████  | 4/5 [00:00<00:00, 15.06batch/s]total loss: 0.86\n",
      "recon: 0.93\n",
      "reg: -1.69\n",
      "Training of epoch 58/100: 100%|██████████| 5/5 [00:00<00:00,  9.58batch/s]\n",
      "Eval of epoch 58/100:  20%|██        | 1/5 [00:00<00:00,  4.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8217\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 59/100:  80%|████████  | 4/5 [00:00<00:00, 18.94batch/s]total loss: 0.74\n",
      "recon: 0.65\n",
      "reg: 2.22\n",
      "Training of epoch 59/100: 100%|██████████| 5/5 [00:00<00:00,  9.90batch/s]\n",
      "Eval of epoch 59/100:  20%|██        | 1/5 [00:00<00:01,  3.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8079\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 60/100:  80%|████████  | 4/5 [00:00<00:00, 19.06batch/s]total loss: 0.30\n",
      "recon: 0.42\n",
      "reg: -2.93\n",
      "Training of epoch 60/100: 100%|██████████| 5/5 [00:00<00:00,  8.69batch/s]\n",
      "Eval of epoch 60/100:  20%|██        | 1/5 [00:00<00:01,  2.94batch/s]\n",
      "Saved checkpoint at epoch 60\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.714\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 61/100:  80%|████████  | 4/5 [00:00<00:00, 16.16batch/s]total loss: 0.57\n",
      "recon: 0.56\n",
      "reg: 0.40\n",
      "Training of epoch 61/100: 100%|██████████| 5/5 [00:00<00:00, 11.08batch/s]\n",
      "Eval of epoch 61/100:  20%|██        | 1/5 [00:00<00:00,  5.73batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7736\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 62/100:  80%|████████  | 4/5 [00:00<00:00, 15.45batch/s]total loss: 0.92\n",
      "recon: 0.96\n",
      "reg: -0.93\n",
      "Training of epoch 62/100: 100%|██████████| 5/5 [00:00<00:00, 10.60batch/s]\n",
      "Eval of epoch 62/100:  20%|██        | 1/5 [00:00<00:00,  5.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8327\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 63/100:  80%|████████  | 4/5 [00:00<00:00, 18.60batch/s]total loss: 0.62\n",
      "recon: 0.68\n",
      "reg: -1.56\n",
      "Training of epoch 63/100: 100%|██████████| 5/5 [00:00<00:00, 10.44batch/s]\n",
      "Eval of epoch 63/100:  20%|██        | 1/5 [00:00<00:00,  4.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7675\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 64/100:  80%|████████  | 4/5 [00:00<00:00, 13.71batch/s]total loss: 1.13\n",
      "recon: 1.00\n",
      "reg: 3.27\n",
      "Training of epoch 64/100: 100%|██████████| 5/5 [00:00<00:00,  9.00batch/s]\n",
      "Eval of epoch 64/100:  20%|██        | 1/5 [00:00<00:00,  4.27batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8851\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 65/100:  80%|████████  | 4/5 [00:00<00:00, 15.59batch/s]total loss: 0.75\n",
      "recon: 0.79\n",
      "reg: -0.97\n",
      "Training of epoch 65/100: 100%|██████████| 5/5 [00:00<00:00, 10.79batch/s]\n",
      "Eval of epoch 65/100:  20%|██        | 1/5 [00:00<00:00,  5.76batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7985\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 66/100:  80%|████████  | 4/5 [00:00<00:00, 16.01batch/s]total loss: 1.36\n",
      "recon: 1.28\n",
      "reg: 2.04\n",
      "Training of epoch 66/100: 100%|██████████| 5/5 [00:00<00:00, 10.87batch/s]\n",
      "Eval of epoch 66/100:  20%|██        | 1/5 [00:00<00:00,  5.29batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9811\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 67/100:  80%|████████  | 4/5 [00:00<00:00, 14.87batch/s]total loss: 0.80\n",
      "recon: 0.78\n",
      "reg: 0.62\n",
      "Training of epoch 67/100: 100%|██████████| 5/5 [00:00<00:00,  9.76batch/s]\n",
      "Eval of epoch 67/100:  20%|██        | 1/5 [00:00<00:00,  4.45batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9199\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 68/100:  80%|████████  | 4/5 [00:00<00:00, 18.75batch/s]total loss: 0.96\n",
      "recon: 0.86\n",
      "reg: 2.54\n",
      "Training of epoch 68/100: 100%|██████████| 5/5 [00:00<00:00,  9.81batch/s]\n",
      "Eval of epoch 68/100:  20%|██        | 1/5 [00:00<00:01,  3.70batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9219\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 69/100:  80%|████████  | 4/5 [00:00<00:00, 17.88batch/s]total loss: 0.86\n",
      "recon: 0.83\n",
      "reg: 0.78\n",
      "Training of epoch 69/100: 100%|██████████| 5/5 [00:00<00:00, 10.73batch/s]\n",
      "Eval of epoch 69/100:  20%|██        | 1/5 [00:00<00:00,  4.58batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8767\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 70/100:  80%|████████  | 4/5 [00:00<00:00, 15.50batch/s]total loss: 0.94\n",
      "recon: 1.05\n",
      "reg: -2.69\n",
      "Training of epoch 70/100: 100%|██████████| 5/5 [00:00<00:00, 10.63batch/s]\n",
      "Eval of epoch 70/100:  20%|██        | 1/5 [00:00<00:00,  5.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8507\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 71/100:  80%|████████  | 4/5 [00:00<00:00, 11.52batch/s]total loss: 0.60\n",
      "recon: 0.70\n",
      "reg: -2.41\n",
      "Training of epoch 71/100: 100%|██████████| 5/5 [00:00<00:00,  7.06batch/s]\n",
      "Eval of epoch 71/100:  20%|██        | 1/5 [00:00<00:01,  3.21batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7882\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 72/100:  80%|████████  | 4/5 [00:00<00:00, 13.14batch/s]total loss: 0.58\n",
      "recon: 0.57\n",
      "reg: 0.32\n",
      "Training of epoch 72/100: 100%|██████████| 5/5 [00:00<00:00, 10.28batch/s]\n",
      "Eval of epoch 72/100:  20%|██        | 1/5 [00:00<00:00,  5.85batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.799\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 73/100:  80%|████████  | 4/5 [00:00<00:00, 19.04batch/s]total loss: 0.73\n",
      "recon: 0.74\n",
      "reg: -0.11\n",
      "Training of epoch 73/100: 100%|██████████| 5/5 [00:00<00:00, 10.11batch/s]\n",
      "Eval of epoch 73/100:  20%|██        | 1/5 [00:00<00:01,  3.87batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8149\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 74/100:  60%|██████    | 3/5 [00:00<00:00, 10.77batch/s]total loss: 0.38\n",
      "recon: 0.38\n",
      "reg: 0.15\n",
      "Training of epoch 74/100: 100%|██████████| 5/5 [00:00<00:00,  7.33batch/s]\n",
      "Eval of epoch 74/100:  20%|██        | 1/5 [00:00<00:01,  3.41batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.753\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 75/100:  80%|████████  | 4/5 [00:00<00:00, 18.66batch/s]total loss: 0.71\n",
      "recon: 0.69\n",
      "reg: 0.50\n",
      "Training of epoch 75/100: 100%|██████████| 5/5 [00:00<00:00, 11.68batch/s]\n",
      "Eval of epoch 75/100:  20%|██        | 1/5 [00:00<00:00,  5.35batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.795\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 76/100:  80%|████████  | 4/5 [00:00<00:00, 14.16batch/s]total loss: 0.83\n",
      "recon: 0.84\n",
      "reg: -0.28\n",
      "Training of epoch 76/100: 100%|██████████| 5/5 [00:00<00:00,  9.20batch/s]\n",
      "Eval of epoch 76/100:  20%|██        | 1/5 [00:00<00:00,  4.39batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8184\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 77/100:  80%|████████  | 4/5 [00:00<00:00, 13.48batch/s]total loss: 1.08\n",
      "recon: 1.03\n",
      "reg: 1.25\n",
      "Training of epoch 77/100: 100%|██████████| 5/5 [00:00<00:00,  9.83batch/s]\n",
      "Eval of epoch 77/100:  20%|██        | 1/5 [00:00<00:00,  5.18batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8889\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 78/100:  80%|████████  | 4/5 [00:00<00:00, 19.25batch/s]total loss: 0.58\n",
      "recon: 0.61\n",
      "reg: -0.67\n",
      "Training of epoch 78/100: 100%|██████████| 5/5 [00:00<00:00,  9.66batch/s]\n",
      "Eval of epoch 78/100:  20%|██        | 1/5 [00:00<00:01,  3.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7991\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 79/100:  80%|████████  | 4/5 [00:00<00:00, 16.39batch/s]total loss: 0.37\n",
      "recon: 0.47\n",
      "reg: -2.28\n",
      "Training of epoch 79/100: 100%|██████████| 5/5 [00:00<00:00,  9.82batch/s]\n",
      "Eval of epoch 79/100:  20%|██        | 1/5 [00:00<00:00,  4.14batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7713\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 80/100:  80%|████████  | 4/5 [00:00<00:00, 17.46batch/s]total loss: 0.75\n",
      "recon: 0.62\n",
      "reg: 3.28\n",
      "Training of epoch 80/100: 100%|██████████| 5/5 [00:00<00:00, 11.29batch/s]\n",
      "Eval of epoch 80/100:  20%|██        | 1/5 [00:00<00:00,  5.44batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8041\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 81/100:  80%|████████  | 4/5 [00:00<00:00, 12.59batch/s]total loss: 0.73\n",
      "recon: 0.75\n",
      "reg: -0.57\n",
      "Training of epoch 81/100: 100%|██████████| 5/5 [00:00<00:00,  9.41batch/s]\n",
      "Eval of epoch 81/100:  20%|██        | 1/5 [00:00<00:00,  5.00batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7942\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00, 23.12batch/s]total loss: 0.50\n",
      "recon: 0.45\n",
      "reg: 1.35\n",
      "Training of epoch 82/100: 100%|██████████| 5/5 [00:00<00:00, 10.85batch/s]\n",
      "Eval of epoch 82/100:  20%|██        | 1/5 [00:00<00:00,  4.28batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.765\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 83/100:  60%|██████    | 3/5 [00:00<00:00, 14.89batch/s]total loss: 0.76\n",
      "recon: 0.73\n",
      "reg: 0.81\n",
      "Training of epoch 83/100: 100%|██████████| 5/5 [00:00<00:00, 10.02batch/s]\n",
      "Eval of epoch 83/100:  20%|██        | 1/5 [00:00<00:00,  4.98batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 84/100:  80%|████████  | 4/5 [00:00<00:00, 13.60batch/s]total loss: 0.90\n",
      "recon: 0.89\n",
      "reg: 0.12\n",
      "Training of epoch 84/100: 100%|██████████| 5/5 [00:00<00:00,  9.05batch/s]\n",
      "Eval of epoch 84/100:  20%|██        | 1/5 [00:00<00:00,  4.32batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8441\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 85/100:  80%|████████  | 4/5 [00:00<00:00, 12.34batch/s]total loss: 0.94\n",
      "recon: 0.85\n",
      "reg: 2.13\n",
      "Training of epoch 85/100: 100%|██████████| 5/5 [00:00<00:00,  9.58batch/s]\n",
      "Eval of epoch 85/100:  20%|██        | 1/5 [00:00<00:00,  5.31batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8398\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 86/100:  80%|████████  | 4/5 [00:00<00:00, 15.15batch/s]total loss: 0.97\n",
      "recon: 0.86\n",
      "reg: 2.88\n",
      "Training of epoch 86/100: 100%|██████████| 5/5 [00:00<00:00, 10.13batch/s]\n",
      "Eval of epoch 86/100:  20%|██        | 1/5 [00:00<00:00,  4.94batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8718\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 87/100:  80%|████████  | 4/5 [00:00<00:00, 19.29batch/s]total loss: 0.64\n",
      "recon: 0.73\n",
      "reg: -2.26\n",
      "Training of epoch 87/100: 100%|██████████| 5/5 [00:00<00:00, 10.78batch/s]\n",
      "Eval of epoch 87/100:  20%|██        | 1/5 [00:00<00:00,  4.33batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8007\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 88/100:  80%|████████  | 4/5 [00:00<00:00, 17.53batch/s]total loss: 1.19\n",
      "recon: 1.11\n",
      "reg: 1.96\n",
      "Training of epoch 88/100: 100%|██████████| 5/5 [00:00<00:00, 10.53batch/s]\n",
      "Eval of epoch 88/100:  20%|██        | 1/5 [00:00<00:00,  4.56batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9163\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 89/100:  80%|████████  | 4/5 [00:00<00:00, 11.23batch/s]total loss: 0.93\n",
      "recon: 0.92\n",
      "reg: 0.26\n",
      "Training of epoch 89/100: 100%|██████████| 5/5 [00:00<00:00,  8.26batch/s]\n",
      "Eval of epoch 89/100:  20%|██        | 1/5 [00:00<00:00,  5.16batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8425\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 90/100:  80%|████████  | 4/5 [00:00<00:00, 17.14batch/s]total loss: 0.65\n",
      "recon: 0.60\n",
      "reg: 1.23\n",
      "Training of epoch 90/100: 100%|██████████| 5/5 [00:00<00:00,  8.44batch/s]\n",
      "Eval of epoch 90/100:  20%|██        | 1/5 [00:00<00:01,  2.98batch/s]\n",
      "Saved checkpoint at epoch 90\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7892\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 91/100:  80%|████████  | 4/5 [00:00<00:00, 19.41batch/s]total loss: 1.10\n",
      "recon: 1.01\n",
      "reg: 2.28\n",
      "Training of epoch 91/100: 100%|██████████| 5/5 [00:00<00:00,  9.72batch/s]\n",
      "Eval of epoch 91/100:  20%|██        | 1/5 [00:00<00:01,  3.54batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8862\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 92/100:  80%|████████  | 4/5 [00:00<00:00, 17.79batch/s]total loss: 0.61\n",
      "recon: 0.58\n",
      "reg: 0.67\n",
      "Training of epoch 92/100: 100%|██████████| 5/5 [00:00<00:00, 10.37batch/s]\n",
      "Eval of epoch 92/100:  20%|██        | 1/5 [00:00<00:00,  4.38batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7965\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 93/100:  80%|████████  | 4/5 [00:00<00:00, 13.95batch/s]total loss: 0.78\n",
      "recon: 0.71\n",
      "reg: 1.69\n",
      "Training of epoch 93/100: 100%|██████████| 5/5 [00:00<00:00,  9.71batch/s]\n",
      "Eval of epoch 93/100:  20%|██        | 1/5 [00:00<00:00,  5.07batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8512\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 94/100:  80%|████████  | 4/5 [00:00<00:00, 14.79batch/s]total loss: 0.71\n",
      "recon: 0.65\n",
      "reg: 1.51\n",
      "Training of epoch 94/100: 100%|██████████| 5/5 [00:00<00:00,  8.96batch/s]\n",
      "Eval of epoch 94/100:  20%|██        | 1/5 [00:00<00:00,  4.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.7992\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 95/100:  80%|████████  | 4/5 [00:00<00:00, 19.35batch/s]total loss: 0.81\n",
      "recon: 0.86\n",
      "reg: -1.24\n",
      "Training of epoch 95/100: 100%|██████████| 5/5 [00:00<00:00, 11.43batch/s]\n",
      "Eval of epoch 95/100:  20%|██        | 1/5 [00:00<00:00,  4.91batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8108\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 96/100:  80%|████████  | 4/5 [00:00<00:00, 18.22batch/s]total loss: 1.77\n",
      "recon: 1.65\n",
      "reg: 2.95\n",
      "Training of epoch 96/100: 100%|██████████| 5/5 [00:00<00:00, 11.73batch/s]\n",
      "Eval of epoch 96/100:  20%|██        | 1/5 [00:00<00:00,  5.53batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 1.0172\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 97/100:  80%|████████  | 4/5 [00:00<00:00, 11.32batch/s]total loss: 0.87\n",
      "recon: 0.87\n",
      "reg: 0.02\n",
      "Training of epoch 97/100: 100%|██████████| 5/5 [00:00<00:00,  8.44batch/s]\n",
      "Eval of epoch 97/100:  20%|██        | 1/5 [00:00<00:00,  4.86batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8254\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 98/100:  80%|████████  | 4/5 [00:00<00:00, 11.98batch/s]total loss: 0.89\n",
      "recon: 0.80\n",
      "reg: 2.28\n",
      "Training of epoch 98/100: 100%|██████████| 5/5 [00:00<00:00,  9.83batch/s]\n",
      "Eval of epoch 98/100:  20%|██        | 1/5 [00:00<00:00,  5.95batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8351\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 99/100:  80%|████████  | 4/5 [00:00<00:00, 19.04batch/s]total loss: 1.59\n",
      "recon: 1.55\n",
      "reg: 1.00\n",
      "Training of epoch 99/100: 100%|██████████| 5/5 [00:00<00:00,  9.40batch/s]\n",
      "Eval of epoch 99/100:  20%|██        | 1/5 [00:00<00:01,  3.88batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.9762\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 100/100:  80%|████████  | 4/5 [00:00<00:00, 18.61batch/s]total loss: 0.67\n",
      "recon: 0.64\n",
      "reg: 0.61\n",
      "Training of epoch 100/100: 100%|██████████| 5/5 [00:00<00:00, 10.99batch/s]\n",
      "Eval of epoch 100/100:  20%|██        | 1/5 [00:00<00:00,  4.68batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 0.8294\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ../results/Master_timestep_30/model_BetaCVAE_De_CLSTMRes_En_CLSTMRes_Prior_RealNVP_Con_Id_Dis_None_comment_test/BetaCVAE_training_2025-03-26_05-39-04/final_model\n",
      "Base dataset initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Training Loss: 0.255701720901, Time: 121.87s\n",
      "Epoch 200, Training Loss: 0.131409470923, Time: 237.69s\n",
      "Epoch 300, Training Loss: 0.067633039749, Time: 345.63s\n",
      "Epoch 400, Training Loss: 0.039594843505, Time: 454.47s\n",
      "Epoch 500, Training Loss: 0.012818424488, Time: 567.86s\n",
      "Epoch 600, Training Loss: 0.007906403818, Time: 677.21s\n",
      "Epoch 700, Training Loss: 0.006631630821, Time: 784.91s\n",
      "Epoch 800, Training Loss: 0.003244960273, Time: 893.58s\n",
      "Epoch 900, Training Loss: 0.002754969009, Time: 1001.90s\n",
      "Epoch 1000, Training Loss: 0.002386060804, Time: 1113.54s\n",
      "Validation Loss: 0.070456305779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.07046</td></tr><tr><td>val_loss</td><td>0.07046</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">blooming-sweep-40</strong> at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/nw5zk7f3' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt/runs/nw5zk7f3</a><br/> View project at: <a href='https://wandb.ai/sarogde-ntnu/tcvae_hyperopt' target=\"_blank\">https://wandb.ai/sarogde-ntnu/tcvae_hyperopt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250326_053903-nw5zk7f3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=main, count=30, project=\"tcvae_hyperopt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
